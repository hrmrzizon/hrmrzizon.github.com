<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko">
  <generator uri="http://jekyllrb.com" version="3.6.2">Jekyll</generator>
  
  
  <link href="https://hrmrzizon.github.io/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://hrmrzizon.github.io/" rel="alternate" type="text/html" hreflang="ko" />
  <updated>2017-11-22T06:06:44+00:00</updated>
  <id>https://hrmrzizon.github.io//</id>

  
    <title type="html">Appocrypha</title>
  

  
    <subtitle>store limitless knowledges</subtitle>
  

  
    <author>
        <name>Su-Hyeok Kim</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Drawinstanced Vs Merged Instancing</title>
      
      <link href="https://hrmrzizon.github.io/2017/11/18/DrawInstanced-vs-Merged-Instancing/" rel="alternate" type="text/html" title="Drawinstanced Vs Merged Instancing" />
      <published>2017-11-18T00:00:00+00:00</published>
      <updated>2017-11-18T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/11/18/DrawInstanced-vs-Merged-Instancing</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/11/18/DrawInstanced-vs-Merged-Instancing/">&lt;p&gt;&lt;a href=&quot;https://www.gdcvault.com/play/1020624/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDC 2014 : Vertex Sahder Tricks&lt;/a&gt; 슬라이드에 따르면 &lt;em&gt;DrawInstanced&lt;/em&gt; 함수를 사용하여 인스턴싱을 하는것보다 &lt;em&gt;vertexID&lt;/em&gt; 를 사용하여 인스턴싱을 하는것이 빠르다고 한다. &lt;em&gt;vertexID&lt;/em&gt; 를 쓰는 방법은 굉장히 단순하다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;VSOutput VS(uint id : SV_VertexID)
{
    VSOutput output;

    /*
        ...
    */

    return output;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;SV_VertexID&lt;/em&gt; &lt;em&gt;Semantic&lt;/em&gt; 을 사용하여 값을 접근하기만 하면 된다. &lt;em&gt;vertexID&lt;/em&gt; 는 말그대로 버텍스별 인덱스를 뜻한다. &lt;em&gt;SRV&lt;/em&gt; 나 &lt;em&gt;UAV&lt;/em&gt; 와 함께 사용하여 &lt;em&gt;Instancing&lt;/em&gt; 을 하면된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2014_vertexshadertricks_23.png&quot; alt=&quot;Merge Instancing Performance&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.gdcvault.com/play/1020624/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDC 2014 : Vertex Sahder Tricks&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그림을 보면 AMD GPU 에서 확실히 퍼포먼스 차이가 난것을 확인할 수 있다. &lt;del&gt;스피커가 AMD 소속이라는 게 포인트&lt;/del&gt;&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gdcvault.com/play/1020624/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDC 2014 : Vertex Sahder Tricks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">GDC 2014 : Vertex Sahder Tricks 슬라이드에 따르면 DrawInstanced 함수를 사용하여 인스턴싱을 하는것보다 vertexID 를 사용하여 인스턴싱을 하는것이 빠르다고 한다. vertexID 를 쓰는 방법은 굉장히 단순하다. VSOutput VS(uint id : SV_VertexID) { VSOutput output; /* ... */ return output; } SV_VertexID Semantic 을 사용하여 값을 접근하기만 하면 된다. vertexID 는 말그대로 버텍스별 인덱스를 뜻한다. SRV 나 UAV 와 함께 사용하여 Instancing 을 하면된다. 출처 : GDC 2014 : Vertex Sahder Tricks 그림을 보면 AMD GPU 에서 확실히 퍼포먼스 차이가 난것을 확인할 수 있다. 스피커가 AMD 소속이라는 게 포인트 참조 자료 GDC 2014 : Vertex Sahder Tricks</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Hbao Plus Analysis 3</title>
      
      <link href="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-3/" rel="alternate" type="text/html" title="Hbao Plus Analysis 3" />
      <published>2017-11-15T00:00:00+00:00</published>
      <updated>2017-11-15T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-3</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-3/">&lt;p&gt;&lt;strong&gt;HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이전 &lt;a href=&quot;/2017/11/15/hbao-plus-analysis-2/&quot;&gt;hbao plus analysis 2&lt;/a&gt; 글에서 &lt;em&gt;Horizon based ambient occlusion&lt;/em&gt; 와 &lt;em&gt;Cross Bilateral Filter&lt;/em&gt; 대해서 알아보았다. 이번 글에서는 부록의 느낌으로 &lt;em&gt;HLSL&lt;/em&gt; 코드를 읽으면서 생소했던 기타 기법들에 대해서 써볼 것이다.&lt;/p&gt;

&lt;p&gt;첫번째로 &lt;em&gt;Full Screen Triangle&lt;/em&gt; 이라는 기법이다. 알고마면 굉장히 단순한 개념으로, 화면을 모두 덮는 한개의 삼각형을 그려서 모든 픽셀에 쉐이더를 돌릴 수 있게 해주는 기법이다. 아래 슬라이드를 보면 쉽게 이해가 갈것이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/vertex-shader-tricks-by-bill-bilodeau-amd-at-gdc14-14-638.jpg&quot; alt=&quot;Full Screen Triangle&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.gdcvault.com/play/1020624/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDC 2014 : Vertex Sahder Tricks&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;단순하지만 처음 봤을 때는 조금 신박하게 느껴질 수도 있다. 두번째로는 모든 계산에 최대한 &lt;em&gt;HLSL Intrisic&lt;/em&gt; 을 사용한다. 특히 벡터와 벡터사이의 거리를 계산할때 &lt;em&gt;dot product&lt;/em&gt; 를 써서 하는게 정말 많았다. 어셈블리 레벨에서 달라지는것 같긴하나 정확한 이유는 알지 못했다. 추측해보면 GPU 에서 해당 명령어가 있지 않을까.. 라고 생각한다.&lt;/p&gt;

&lt;p&gt;세번째도 위의 것과 비슷하다. 대부분의 데이터에 &lt;em&gt;MAD&lt;/em&gt; 방식을 사용해서 계산한다. 하지만 이는 거의 공식적으로 정해진게 있다. &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471418.aspx&quot;&gt;MSDN : mad  function&lt;/a&gt; 레퍼런스에서도 나오듯이 어떤 GPU 에서는 위에서 추측한대로 하드웨어에서 지원하는 명령어라고 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…
Shaders can then take advantage of potential performance improvements by using a native mad instruction (versus mul + add) on some hardware.
…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;또한 &lt;em&gt;HBAO+&lt;/em&gt; 소스에서 찾은 주석에는 &lt;em&gt;GK104&lt;/em&gt; 부터 특정 구간에서 10% 퍼포먼스 이득이 있다고 쓰여져 있다.&lt;/p&gt;

&lt;p&gt;네번째는 나누기를 절대 쓰지 않는다. 나머지 연산(mod, A % B)는 간혹 쓰이지만 나누기는 절대로 쓰이지 않았었다. 혹시라도 필요하다면 전부 &lt;em&gt;Constant Buffer&lt;/em&gt; 에 CPU 에서 역수를 취해서 넘겨주는 방식으로 되어 있었다. 이도 역시 하드웨어에서 동작하는 부분을 알고 짠듯하다.&lt;/p&gt;

&lt;p&gt;다섯번째는 &lt;em&gt;HLSL&lt;/em&gt; 코드를 &lt;em&gt;cpp&lt;/em&gt; 소스에 &lt;em&gt;include&lt;/em&gt; 하여 &lt;em&gt;Constant Buffer&lt;/em&gt; 값을 갱신하는 코드였다. 여태까지 예전의 &lt;em&gt;DirectX&lt;/em&gt; 소스만 보거나 &lt;em&gt;Unity&lt;/em&gt; 에서만 작업을 해서 그런지 이런 기능은 굉장히 낯설었다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.nvidia.com/gameworks/content/gameworkslibrary/visualfx/hbao/index.html&quot;&gt;NVIDIA HBAO+&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gdcvault.com/play/1020624/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDC 2014 : Vertex Sahder Tricks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471418.aspx&quot;&gt;MSDN : mad function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="hlsl" />
      
        <category term="analysis" />
      
        <category term="hbaoplus" />
      

      

      
        <summary type="html">HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다. 이전 hbao plus analysis 2 글에서 Horizon based ambient occlusion 와 Cross Bilateral Filter 대해서 알아보았다. 이번 글에서는 부록의 느낌으로 HLSL 코드를 읽으면서 생소했던 기타 기법들에 대해서 써볼 것이다. 첫번째로 Full Screen Triangle 이라는 기법이다. 알고마면 굉장히 단순한 개념으로, 화면을 모두 덮는 한개의 삼각형을 그려서 모든 픽셀에 쉐이더를 돌릴 수 있게 해주는 기법이다. 아래 슬라이드를 보면 쉽게 이해가 갈것이다. 출처 : GDC 2014 : Vertex Sahder Tricks 단순하지만 처음 봤을 때는 조금 신박하게 느껴질 수도 있다. 두번째로는 모든 계산에 최대한 HLSL Intrisic 을 사용한다. 특히 벡터와 벡터사이의 거리를 계산할때 dot product 를 써서 하는게 정말 많았다. 어셈블리 레벨에서 달라지는것 같긴하나 정확한 이유는 알지 못했다. 추측해보면 GPU 에서 해당 명령어가 있지 않을까.. 라고 생각한다. 세번째도 위의 것과 비슷하다. 대부분의 데이터에 MAD 방식을 사용해서 계산한다. 하지만 이는 거의 공식적으로 정해진게 있다. MSDN : mad function 레퍼런스에서도 나오듯이 어떤 GPU 에서는 위에서 추측한대로 하드웨어에서 지원하는 명령어라고 한다. … Shaders can then take advantage of potential performance improvements by using a native mad instruction (versus mul + add) on some hardware. … 또한 HBAO+ 소스에서 찾은 주석에는 GK104 부터 특정 구간에서 10% 퍼포먼스 이득이 있다고 쓰여져 있다. 네번째는 나누기를 절대 쓰지 않는다. 나머지 연산(mod, A % B)는 간혹 쓰이지만 나누기는 절대로 쓰이지 않았었다. 혹시라도 필요하다면 전부 Constant Buffer 에 CPU 에서 역수를 취해서 넘겨주는 방식으로 되어 있었다. 이도 역시 하드웨어에서 동작하는 부분을 알고 짠듯하다. 다섯번째는 HLSL 코드를 cpp 소스에 include 하여 Constant Buffer 값을 갱신하는 코드였다. 여태까지 예전의 DirectX 소스만 보거나 Unity 에서만 작업을 해서 그런지 이런 기능은 굉장히 낯설었다. 참조 자료 NVIDIA HBAO+ GDC 2014 : Vertex Sahder Tricks MSDN : mad function</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Hbao Plus Analysis 2</title>
      
      <link href="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-2/" rel="alternate" type="text/html" title="Hbao Plus Analysis 2" />
      <published>2017-11-15T00:00:00+00:00</published>
      <updated>2017-11-15T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-2</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-2/">&lt;p&gt;&lt;strong&gt;HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이전 &lt;a href=&quot;/2017/11/15/hbao-plus-analysis-1/&quot;&gt;hbao plus analysis 1&lt;/a&gt; 글에서 &lt;em&gt;HBAO+&lt;/em&gt; 에서 &lt;em&gt;Linearize Depth&lt;/em&gt; 와 &lt;em&gt;Deinterleaved Texturing&lt;/em&gt; 에 대해서 알아보았다. 이번 글에서는 &lt;em&gt;HBAO+&lt;/em&gt; 의 핵심 알고리즘인 &lt;em&gt;Horizon Based Ambient Occlusion&lt;/em&gt; 와 AO 블러에 사용되는 &lt;em&gt;Cross Bilateral Filter&lt;/em&gt; 에 대해서 알아볼것이다.&lt;/p&gt;

&lt;h2&gt;Horizon Based Ambient Occlusion&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Horizon Based Ambient Occlusion&lt;/em&gt; 은 xy 평면과(horizon) Depth 값을 사용해서 &lt;em&gt;AO&lt;/em&gt; 를 계산한다. 슬라이드에서 가져온 일부를 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao_siggraph08_05.png&quot; alt=&quot;Horizon Mapping&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf&quot;&gt;Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;해당 슬라이드에서는 xy평면을 단순하게 1차원인 x축만으로 나타냈다. &lt;em&gt;HBAO&lt;/em&gt; 는 그림에 나오는 &lt;em&gt;horizon angle&lt;/em&gt; 을 사용하여 &lt;em&gt;AO&lt;/em&gt; 값을 구한다. 자세한 방법은 아래 슬라이드를 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao_siggraph08_12.png&quot; alt=&quot;Horizon-Based AO&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf&quot;&gt;Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;슬라이드에서는 표면의 접선을 나타내는 &lt;em&gt;Tangent&lt;/em&gt; 벡터와 &lt;em&gt;Horizon&lt;/em&gt; 벡터를 사용해서 &lt;em&gt;sin&lt;/em&gt; 의 차이로 &lt;em&gt;AO&lt;/em&gt; 를 계산한다고 설명되어 있다. &lt;em&gt;Horizon&lt;/em&gt; 벡터는 &lt;em&gt;Depth&lt;/em&gt; 와 화면의 좌표를 구해서 샘플링하는 위치값을 구하고 기준이 되는 위치값의 차이를 통해 구한다. &lt;em&gt;HBAO+&lt;/em&gt; 코드에서는 입력을 받은 &lt;em&gt;Normal&lt;/em&gt; 벡터와 &lt;em&gt;Horizon&lt;/em&gt; 벡터에 &lt;em&gt;dot&lt;/em&gt; 을 사용해 &lt;em&gt;cos&lt;/em&gt; 값을 구하고 변환해준다. 이렇게 한번 &lt;em&gt;AO&lt;/em&gt; 값을 구한다.&lt;/p&gt;

&lt;p&gt;보다 정확한 &lt;em&gt;AO&lt;/em&gt; 값을 구하기 위해서는 전방위로 탐색할 필요가 있다. 정해진 방향으로 샘플링을 해도 오차가 생길 수 있고 완전히 랜덤하게 방향을 정해도 부정확한 결과를 얻을 수 있다. 그래서 &lt;em&gt;HBAO&lt;/em&gt; 는 랜덤하게 방향을 정하나 그 방향 벡터를 정해진 각도로 돌려주어 그나마 정확한 결과를 얻으려 한다. 슬라이드를 보고 넘어가자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao_siggraph08_14.png&quot; alt=&quot;Sampling the Depth Image&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf&quot;&gt;Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;핵심적인 개념은 모두 설명했지만 만족할만한 결과를 얻기 위해 여러가지 보정 방법들이 필요하다. 그래서 &lt;em&gt;HBAO&lt;/em&gt; 에서는 두가지 보정을 해주는 개념을 설명한다. &lt;em&gt;HBAO&lt;/em&gt; 는 방향을 설정해주고 해당 방향으로 한번만 샘플링 하는게 아니라 여러번 샘플링 한다. 그러므로 거리에 따른 감쇠(attenuation)가 필요하다. 방법은 간단하다. &lt;em&gt;AO&lt;/em&gt; 를 계산할때 구했던 &lt;em&gt;Horizon&lt;/em&gt; 벡터의 크기에 따라서 &lt;em&gt;AO&lt;/em&gt; 값을 줄여준다. 나머지 한가지는 &lt;em&gt;Horizon&lt;/em&gt; 벡터와 &lt;em&gt;Tangent&lt;/em&gt; 벡터를 이용해 구하는 실질적인 &lt;em&gt;AO&lt;/em&gt; 값에 &lt;em&gt;Bias&lt;/em&gt; 로 낮은 &lt;em&gt;AO&lt;/em&gt; 값들을 무시하는 방법이다. &lt;em&gt;Bias&lt;/em&gt; 가 없이 &lt;em&gt;AO&lt;/em&gt; 를 생성하게 되면 노이즈가 생기기 때문이다. 또한 &lt;em&gt;Bias&lt;/em&gt; 로 생긴 수학적 오차는 코드에서 따로 보정해주기 때문에 크게 문제는 없다.&lt;/p&gt;

&lt;h2&gt;Cross Bilateral Filter&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;SSAO&lt;/em&gt; 의 결과에는 일반적으로 블러를 먹이게 된다. 대부분 근사에 기반한 계산이기 때문이다. &lt;em&gt;HBAO&lt;/em&gt; 에서는 &lt;em&gt;Depth&lt;/em&gt; 를 이용한 방법을 소개한다. 바로 &lt;em&gt;Cross Bilateral Filter&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Cross Bilateral Filter&lt;/em&gt; 은 &lt;em&gt;Gaussian Filter&lt;/em&gt; 와 비슷한 필터로, &lt;em&gt;Gaussian Filter&lt;/em&gt; 는 샘플링할 위치의 거리에 따라 점차 가중치가 줄어드는 필터라면, &lt;em&gt;Bilateral Filter&lt;/em&gt; 는 위치에 따라 가중치가 줄어드는게 아닌 각 위치별로 가지고 있는 한개의 스칼라값에 차이에 따라서 가중치를 정하는 필터다. &lt;em&gt;Cross&lt;/em&gt; 단어를 붙인 이유는 왼쪽과 오른쪽 방향의 필터와 위와 아래의 필터를 따로하기 때문에 &lt;em&gt;Cross&lt;/em&gt; 라는 단어를 붙인 듯 하다. &lt;em&gt;HBAO+&lt;/em&gt; 코드에서도 X 축과 Y 축을 기준으로 하는 블러 소스가 나누어져 있다. &lt;em&gt;HBAO&lt;/em&gt; 에는 한개의 스칼라 값을 &lt;em&gt;Depth&lt;/em&gt; 를 기준으로 계산한다. 그래서 크게 튀는 부분의 결과는 많이 반영하지 않아 전체적으로 뿌옇게 바뀐다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao_siggraph08_28.png&quot; alt=&quot;Sampling the Depth Image&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf&quot;&gt;Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.nvidia.com/gameworks/content/gameworkslibrary/visualfx/hbao/index.html&quot;&gt;NVidia HBAO+&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf&quot;&gt;Image-Space Horizon Based Ambient Occlusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gaussian_filter&quot;&gt;Wikipedia : Gaussian Filter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bilateral_filter&quot;&gt;Wikipedia : Bilateral Filter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="analysis" />
      
        <category term="hbaoplus" />
      
        <category term="hbao" />
      
        <category term="bilateral_filter" />
      

      

      
        <summary type="html">HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다. 이전 hbao plus analysis 1 글에서 HBAO+ 에서 Linearize Depth 와 Deinterleaved Texturing 에 대해서 알아보았다. 이번 글에서는 HBAO+ 의 핵심 알고리즘인 Horizon Based Ambient Occlusion 와 AO 블러에 사용되는 Cross Bilateral Filter 에 대해서 알아볼것이다. Horizon Based Ambient Occlusion Horizon Based Ambient Occlusion 은 xy 평면과(horizon) Depth 값을 사용해서 AO 를 계산한다. 슬라이드에서 가져온 일부를 보자. 출처 : Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion 해당 슬라이드에서는 xy평면을 단순하게 1차원인 x축만으로 나타냈다. HBAO 는 그림에 나오는 horizon angle 을 사용하여 AO 값을 구한다. 자세한 방법은 아래 슬라이드를 보자. 출처 : Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion 슬라이드에서는 표면의 접선을 나타내는 Tangent 벡터와 Horizon 벡터를 사용해서 sin 의 차이로 AO 를 계산한다고 설명되어 있다. Horizon 벡터는 Depth 와 화면의 좌표를 구해서 샘플링하는 위치값을 구하고 기준이 되는 위치값의 차이를 통해 구한다. HBAO+ 코드에서는 입력을 받은 Normal 벡터와 Horizon 벡터에 dot 을 사용해 cos 값을 구하고 변환해준다. 이렇게 한번 AO 값을 구한다. 보다 정확한 AO 값을 구하기 위해서는 전방위로 탐색할 필요가 있다. 정해진 방향으로 샘플링을 해도 오차가 생길 수 있고 완전히 랜덤하게 방향을 정해도 부정확한 결과를 얻을 수 있다. 그래서 HBAO 는 랜덤하게 방향을 정하나 그 방향 벡터를 정해진 각도로 돌려주어 그나마 정확한 결과를 얻으려 한다. 슬라이드를 보고 넘어가자. 출처 : Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion 핵심적인 개념은 모두 설명했지만 만족할만한 결과를 얻기 위해 여러가지 보정 방법들이 필요하다. 그래서 HBAO 에서는 두가지 보정을 해주는 개념을 설명한다. HBAO 는 방향을 설정해주고 해당 방향으로 한번만 샘플링 하는게 아니라 여러번 샘플링 한다. 그러므로 거리에 따른 감쇠(attenuation)가 필요하다. 방법은 간단하다. AO 를 계산할때 구했던 Horizon 벡터의 크기에 따라서 AO 값을 줄여준다. 나머지 한가지는 Horizon 벡터와 Tangent 벡터를 이용해 구하는 실질적인 AO 값에 Bias 로 낮은 AO 값들을 무시하는 방법이다. Bias 가 없이 AO 를 생성하게 되면 노이즈가 생기기 때문이다. 또한 Bias 로 생긴 수학적 오차는 코드에서 따로 보정해주기 때문에 크게 문제는 없다. Cross Bilateral Filter SSAO 의 결과에는 일반적으로 블러를 먹이게 된다. 대부분 근사에 기반한 계산이기 때문이다. HBAO 에서는 Depth 를 이용한 방법을 소개한다. 바로 Cross Bilateral Filter 다. Cross Bilateral Filter 은 Gaussian Filter 와 비슷한 필터로, Gaussian Filter 는 샘플링할 위치의 거리에 따라 점차 가중치가 줄어드는 필터라면, Bilateral Filter 는 위치에 따라 가중치가 줄어드는게 아닌 각 위치별로 가지고 있는 한개의 스칼라값에 차이에 따라서 가중치를 정하는 필터다. Cross 단어를 붙인 이유는 왼쪽과 오른쪽 방향의 필터와 위와 아래의 필터를 따로하기 때문에 Cross 라는 단어를 붙인 듯 하다. HBAO+ 코드에서도 X 축과 Y 축을 기준으로 하는 블러 소스가 나누어져 있다. HBAO 에는 한개의 스칼라 값을 Depth 를 기준으로 계산한다. 그래서 크게 튀는 부분의 결과는 많이 반영하지 않아 전체적으로 뿌옇게 바뀐다. 출처 : Siggraph 2008 : Image-Space Horizon-Based Ambient Occlusion 참조 자료 NVidia HBAO+ Image-Space Horizon Based Ambient Occlusion Wikipedia : Gaussian Filter Wikipedia : Bilateral Filter</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Hbao Plus Analysis 1</title>
      
      <link href="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-1/" rel="alternate" type="text/html" title="Hbao Plus Analysis 1" />
      <published>2017-11-15T00:00:00+00:00</published>
      <updated>2017-11-15T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-1</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-1/">&lt;p&gt;&lt;strong&gt;HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이전 &lt;a href=&quot;/2017/11/15/hbao-plus-analysis-0/&quot;&gt;hbao plus analysis 0&lt;/a&gt; 글에서 &lt;em&gt;HBAO+&lt;/em&gt; 을 알기위한 기본적인 개념들에 대해서 살펴보았다. 이번 글에서는 &lt;em&gt;HBAO+&lt;/em&gt; 의 구조와 &lt;em&gt;Linearize Depth&lt;/em&gt; 와 &lt;em&gt;Deinterleaved Texturing&lt;/em&gt; 에 대해서 알아보겠다.&lt;/p&gt;

&lt;h2&gt;&lt;em&gt;HBAO+&lt;/em&gt; Pipeline&lt;/h2&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao+_pipeline_with_input_normals.png&quot; alt=&quot;hbao+ with input normal&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://docs.nvidia.com/gameworks/content/gameworkslibrary/visualfx/hbao/index.html&quot;&gt;NVIDIA HBAO+&lt;/a&gt;
&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao+_pipeline_without_input_normals.png&quot; alt=&quot;hbao+ without input normal&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://docs.nvidia.com/gameworks/content/gameworkslibrary/visualfx/hbao/index.html&quot;&gt;NVIDIA HBAO+&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그림이 두개가 있다. 하나는 &lt;em&gt;GBuffer&lt;/em&gt; 를 사용할 시 &lt;em&gt;World-Space Normal&lt;/em&gt; 버퍼와 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 넘겨주어 계산하는 방식과 입력으로 &lt;em&gt;Depth Buffer&lt;/em&gt; 만 넘겨서 &lt;em&gt;Normal&lt;/em&gt; 데이터를 계산하는 두가지 방식에 대한 파이프라인이다. 두가지의 차이는 &lt;em&gt;Normal&lt;/em&gt; 데이터에 대한 처리방식만 다르다. 나머지 계산은 다를게 없다.&lt;/p&gt;

&lt;h2&gt;Linearize Depths&lt;/h2&gt;

&lt;p&gt;코드를 보면 가장 처음에 시작하는 단계는 바로 &lt;em&gt;Linearize Depths&lt;/em&gt; 다. 이는 꽤나 알려진 방법이다. 하지만 필자는 &lt;em&gt;HBAO+&lt;/em&gt; 를 볼때 처음 봤기에 어느 정도의 설명을 해놓아야겠다. &lt;em&gt;Linearize Depths&lt;/em&gt; 를 알기 위해선 입력된 정점의 위치를 &lt;em&gt;Clipping-Space&lt;/em&gt; 로 변환하는 방법이 어떻게 이루어지는지 알고 있어야 한다.&lt;/p&gt;

&lt;p&gt;일반적인 오브젝트를 렌더링 할때는 &lt;em&gt;Shader&lt;/em&gt; 에 입력으로 들어오는 정점의 기준 공간은 &lt;em&gt;Model-Space&lt;/em&gt;(또는 &lt;em&gt;Local-Space&lt;/em&gt;) &lt;em&gt;Position&lt;/em&gt; 이다. 그래서 &lt;em&gt;MVP&lt;/em&gt; 변환을 통해 &lt;em&gt;Rasterizer&lt;/em&gt; 가 처리할 수 있도록 &lt;em&gt;Clipping-Space&lt;/em&gt; 로 &lt;em&gt;Rasterizer&lt;/em&gt; 로 넘어가기 전에 변환해주어야 한다.(전체적인 내용은 &lt;a href=&quot;https://docs.google.com/presentation/d/10VzsjfifKJlRTHDlBq7e8vNBTu4D5jOWUF87KYYGwlk/edit#slide=id.g25f88339be_0_0&quot;&gt;Model, View, Projection 변환&lt;/a&gt; 에서 확인할 수 있다.
) 그래서 &lt;em&gt;Pixel Shader&lt;/em&gt; 로 넘어간 데이터들은 픽셀별로 들어가고, 픽셀별로 들어간 정점들의 위치는 &lt;em&gt;Clipping-Space&lt;/em&gt; 로 되어있다. 여기까지 이해했으면 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/Graphics3D_ClipVolume.png&quot; alt=&quot;Frustom vs Clipping&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.ntu.edu.sg/home/ehchua/programming/opengl/CG_BasicsTheory.html&quot;&gt;3D Graphics with OpenGL Basic Theory&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 &lt;em&gt;View Frustom&lt;/em&gt; 과 &lt;em&gt;Clipping Volume&lt;/em&gt; 을 보여준다. &lt;em&gt;View Frustom&lt;/em&gt; 은 &lt;em&gt;Perspective&lt;/em&gt; 방식으로 카메라가 실제로 보여주는 공간을 시각화 한것이고, &lt;em&gt;Clipping Volume&lt;/em&gt; 은 &lt;em&gt;MVP&lt;/em&gt; 변환에서 &lt;em&gt;Projection&lt;/em&gt; 행렬을 사용할시 &lt;em&gt;View Frustom&lt;/em&gt; 에서 &lt;em&gt;Clipping Volume&lt;/em&gt; 으로 변환되는 볼륨을 시각화 한것이다. &lt;em&gt;Projection&lt;/em&gt; 변환은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/projection_matrix.png&quot; alt=&quot;perspective projection matrix&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://stackoverflow.com/questions/6652253/getting-the-true-z-value-from-the-depth-buffer
&quot;&gt;Stackoverflow : Getting the true z value from the depth buffer&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Perspective Projection&lt;/em&gt; 은 &lt;em&gt;Frustom&lt;/em&gt; 기준 위치를 &lt;em&gt;Cube&lt;/em&gt; 기준 위치로 바꾸는 연산이기 때문에 실제 좌표의 왜곡이 발생한다. 우리는 Z(Detph) 값이 어떤식으로 왜곡되는지 알아야 한다. 우선 &lt;em&gt;Clipping-Space&lt;/em&gt; 로 변환할때, &lt;em&gt;Perspective&lt;/em&gt; 형식의 &lt;em&gt;View Frustom&lt;/em&gt; 의 &lt;em&gt;zNear&lt;/em&gt;, &lt;em&gt;zFar&lt;/em&gt; 사이의 Z 값을 [0~1] 값으로 매핑한다. 그러면 &lt;em&gt;zNear&lt;/em&gt;, &lt;em&gt;zFar&lt;/em&gt; 값을에 따라서 실제 좌표가 바뀐다. 그리고 값 자체가 실제 Z 값과 선형적으로 매핑되지 않는다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/nonlinearDepth.png&quot; alt=&quot;non linear depth&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://computergraphics.stackexchange.com/questions/5116/how-am-i-able-to-perform-perspective-projection-without-a-near-plane&quot;&gt;Computer Graphics StackExchange : How am I able to perform perspective projection without a near plane?&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그림이 조금 헷갈릴수도 있다. 세로축의 &lt;em&gt;d&lt;/em&gt; 값은 &lt;em&gt;Projection&lt;/em&gt; 을 한 Z, &lt;em&gt;Depth&lt;/em&gt; 값이고 가로축은 &lt;em&gt;World-Space&lt;/em&gt; 의 Z 값이다. 조금 헷갈릴수도 있는 부분은 세로축의 기준값이 윗부분이 0이고 아랫부분이 1이다. 이 부분은 신경써서 봐야한다. 이해했다면 변경된 &lt;em&gt;Depth&lt;/em&gt; 값은 실제 Z 값과 선형적인 관계가 아니고, 실제 Z 값으로 복원하려면 여러 연산을 해야하기에 &lt;em&gt;HBAO+&lt;/em&gt; 에서는 &lt;em&gt;Depth&lt;/em&gt; 값들을 &lt;em&gt;Linearize&lt;/em&gt; 하는 과정을 맨 처음에 넣은 것이다. 실제 Z 값으로 복원하는 이유는 간단하다. &lt;em&gt;Linear&lt;/em&gt; 하지 않은 &lt;em&gt;Depth&lt;/em&gt; 값을 연산시에 사용하면 보다 부정확한 결과가 나오기 때문이다. 특히 &lt;em&gt;SSAO&lt;/em&gt; 연산을 할때는 &lt;em&gt;Depth&lt;/em&gt; 값이 기본이 되기 때문에 해주어야 한다.&lt;/p&gt;

&lt;p&gt;이 단계에서의 결론은 간단하다. &lt;em&gt;Clipping-Space&lt;/em&gt; 의 &lt;em&gt;Depth&lt;/em&gt; 값을 &lt;em&gt;View-Space&lt;/em&gt; 의 Z 값으로 변환하는 단계다. 처리하는 코드는 다른 단계에 비해 짧다. 만약에 넘겨준 &lt;em&gt;Depth&lt;/em&gt; 데이터들이 &lt;em&gt;View-Space&lt;/em&gt; 인 경우에는 옵션을 통해 처리할 수 있다.&lt;/p&gt;

&lt;h2&gt;Deintereaved Texturing&lt;/h2&gt;

&lt;p&gt;위의 그림에는 &lt;em&gt;Generate HBAO+&lt;/em&gt; 라고 단순히 뭉뚱그려서 표현했지만 그 안에는 단순한 &lt;em&gt;Horizon based ambient occlusion(HBAO)&lt;/em&gt; 계산만 있지는 않다. &lt;em&gt;Deintereaved Texturing&lt;/em&gt; 이라는 테크닉과 함께 &lt;em&gt;HBAO&lt;/em&gt; 를 계산한다. &lt;em&gt;Computer Engineering&lt;/em&gt; 분야의 지식을 응용한 이론으로 개인적으로 이 이론을 접했을 떄 꽤나 충격이였다. 자세한 설명은 &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt; 슬라이드의 몇장과 함께 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_51.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_51&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Deintereaved Texturing&lt;/em&gt; 의 방법은 간단하다. 텍스쳐를 여러장으로 나누어 샘플링을 한 후 각각의 나눠진 텍스쳐를 샘플링한 결과를 하나로 합친다. 슬라이드에는 &lt;em&gt;Post-Processing&lt;/em&gt; 을 기준으로 설명이 되어있다. 이점은 생각하면서 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_52.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_52&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;한 텍스쳐를 여러장으로 나누는건 &lt;em&gt;Multiple Render Target&lt;/em&gt; 을 사용해서 나눈다. 슬라이드는 4개를 기준으로 설명했지만 &lt;em&gt;DirectX10&lt;/em&gt; 부터는 최대 8개까지 지원하기 때문에 16개로 나누어 샘플링한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_53.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_53&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;다음은 나누어진 각각의 텍스쳐를 샘플링하여 원하는 알고리즘으로 결과를 낸다. 조각난 텍스쳐 한개당 한번 &lt;em&gt;DrawCall&lt;/em&gt; 을 걸어준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_54.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_54&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Deintereave&lt;/em&gt; 를 하기전까지는 넓은 범위의 텍스쳐를 샘플링하여 캐시 효율이 많이 떨어졌지만 텍스쳐를 나누어 각각 할때마다 처리를 하게되니 캐시 효율의 이득을 얻었다. 또한 각각의 &lt;em&gt;DrawCall&lt;/em&gt; 마다 텍스쳐의 용량이 조금만 필요하게 되니 대역폭의 이득도 얻게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_55.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_55&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;한번의 &lt;em&gt;DrawCall&lt;/em&gt; 로 나누어진 결과들을 합친다. &lt;em&gt;Deintereaved Texturing&lt;/em&gt; 은 여기서 끝이다. 실제로 &lt;em&gt;HBAO+&lt;/em&gt; 는 16개의 텍스쳐로 나누어 샘플링한다. &lt;em&gt;Multiple Render Target&lt;/em&gt; 이 8개까지 지원되어 16개로 &lt;em&gt;Deintereave&lt;/em&gt; 하려면 2번 &lt;em&gt;DrawCall&lt;/em&gt; 을 해야한다. 또한 샘플링은 16번 &lt;em&gt;DrawCall&lt;/em&gt; 을 하여 계산한다. 그래서 한번 &lt;em&gt;Deintereaved Texturing&lt;/em&gt; 을 사용하여 &lt;em&gt;Post-Processing&lt;/em&gt; 처리하려면 약 20번의 &lt;em&gt;DrawCall&lt;/em&gt; 을 계산해야 한다. 절대적으로 큰 숫자가 아니기 때문에 크게 신경쓸 필요는 없어보인다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/gdc2013_ParticleShadowsAndCacheEfficientPost_62.png&quot; alt=&quot;gdc2013_ParticleShadowsAndCacheEfficientPost_62&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;엄청난 성과를 거둔게 보인다. 캐시 히트 확률이 굉장히 올라갔고, 시간도 많이 절약했다. &lt;em&gt;HBAO+&lt;/em&gt; 의 성능향상을 시켜준 것이 이 &lt;em&gt;Deinterleaved Texturing&lt;/em&gt; 인듯하다.&lt;/p&gt;

&lt;h2&gt;Reconstruction of Normal&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;HBAO+&lt;/em&gt; 는 기본적으로 &lt;em&gt;Depth&lt;/em&gt; 와 &lt;em&gt;Normal&lt;/em&gt; 을 통해서 계산한다. 그렇기 때문에 외부에서 &lt;em&gt;Normal&lt;/em&gt; 데이터를 넣어주거나 직접 만들어야 한다. 보통 &lt;em&gt;Deffered Rendering&lt;/em&gt; 을 차용하는 시스템들은 간단하게 &lt;em&gt;GBuffer&lt;/em&gt; 의 &lt;em&gt;Normal&lt;/em&gt; 데이터만 넣어주면 된다. &lt;em&gt;Normal&lt;/em&gt; 데이터를 가져오는 코드가 있으니 조금만 수정하여 사용하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Normal&lt;/em&gt; 데이터가 없는 경우에는 라이브러리 내에 직접 계산한다. 계산하는 픽셀을 기준으로 상하,좌우별로 &lt;em&gt;Depth&lt;/em&gt; 와 화면상의 좌표계를 이용하여 &lt;em&gt;View-Space&lt;/em&gt; 의 위치를 구한다음 위치가 상하, 좌우별로 가까운 픽셀의 위치 오프셋을 사용해 외적하여 &lt;em&gt;Normal&lt;/em&gt; 값을 구한다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.nvidia.com/gameworks/content/gameworkslibrary/visualfx/hbao/index.html&quot;&gt;NVidia HBAO+&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gameworks/samples/DeinterleavedTexturing.pdf&quot;&gt;NVidia : Deintereaved Texturing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf&quot;&gt;GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.gdcvault.com/play/1017623/Advanced-Visual-Effects-with-DirectX&quot;&gt;GDCVault : Particle Shadows &amp;amp; Cache-Efficient Post-Processing Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="analysis" />
      
        <category term="hbaoplus" />
      
        <category term="linearize_depth" />
      
        <category term="deintereaved_texturing" />
      

      

      
        <summary type="html">HBAO+ 3.1 버젼을 기준으로 글이 작성되었습니다. 이전 hbao plus analysis 0 글에서 HBAO+ 을 알기위한 기본적인 개념들에 대해서 살펴보았다. 이번 글에서는 HBAO+ 의 구조와 Linearize Depth 와 Deinterleaved Texturing 에 대해서 알아보겠다. HBAO+ Pipeline 출처 : NVIDIA HBAO+ 출처 : NVIDIA HBAO+ 그림이 두개가 있다. 하나는 GBuffer 를 사용할 시 World-Space Normal 버퍼와 Depth Buffer 를 넘겨주어 계산하는 방식과 입력으로 Depth Buffer 만 넘겨서 Normal 데이터를 계산하는 두가지 방식에 대한 파이프라인이다. 두가지의 차이는 Normal 데이터에 대한 처리방식만 다르다. 나머지 계산은 다를게 없다. Linearize Depths 코드를 보면 가장 처음에 시작하는 단계는 바로 Linearize Depths 다. 이는 꽤나 알려진 방법이다. 하지만 필자는 HBAO+ 를 볼때 처음 봤기에 어느 정도의 설명을 해놓아야겠다. Linearize Depths 를 알기 위해선 입력된 정점의 위치를 Clipping-Space 로 변환하는 방법이 어떻게 이루어지는지 알고 있어야 한다. 일반적인 오브젝트를 렌더링 할때는 Shader 에 입력으로 들어오는 정점의 기준 공간은 Model-Space(또는 Local-Space) Position 이다. 그래서 MVP 변환을 통해 Rasterizer 가 처리할 수 있도록 Clipping-Space 로 Rasterizer 로 넘어가기 전에 변환해주어야 한다.(전체적인 내용은 Model, View, Projection 변환 에서 확인할 수 있다. ) 그래서 Pixel Shader 로 넘어간 데이터들은 픽셀별로 들어가고, 픽셀별로 들어간 정점들의 위치는 Clipping-Space 로 되어있다. 여기까지 이해했으면 아래 그림을 보자. 출처 : 3D Graphics with OpenGL Basic Theory 위 그림은 View Frustom 과 Clipping Volume 을 보여준다. View Frustom 은 Perspective 방식으로 카메라가 실제로 보여주는 공간을 시각화 한것이고, Clipping Volume 은 MVP 변환에서 Projection 행렬을 사용할시 View Frustom 에서 Clipping Volume 으로 변환되는 볼륨을 시각화 한것이다. Projection 변환은 아래와 같다. 출처 : Stackoverflow : Getting the true z value from the depth buffer Perspective Projection 은 Frustom 기준 위치를 Cube 기준 위치로 바꾸는 연산이기 때문에 실제 좌표의 왜곡이 발생한다. 우리는 Z(Detph) 값이 어떤식으로 왜곡되는지 알아야 한다. 우선 Clipping-Space 로 변환할때, Perspective 형식의 View Frustom 의 zNear, zFar 사이의 Z 값을 [0~1] 값으로 매핑한다. 그러면 zNear, zFar 값을에 따라서 실제 좌표가 바뀐다. 그리고 값 자체가 실제 Z 값과 선형적으로 매핑되지 않는다. 아래 그림을 보자. 출처 : Computer Graphics StackExchange : How am I able to perform perspective projection without a near plane? 그림이 조금 헷갈릴수도 있다. 세로축의 d 값은 Projection 을 한 Z, Depth 값이고 가로축은 World-Space 의 Z 값이다. 조금 헷갈릴수도 있는 부분은 세로축의 기준값이 윗부분이 0이고 아랫부분이 1이다. 이 부분은 신경써서 봐야한다. 이해했다면 변경된 Depth 값은 실제 Z 값과 선형적인 관계가 아니고, 실제 Z 값으로 복원하려면 여러 연산을 해야하기에 HBAO+ 에서는 Depth 값들을 Linearize 하는 과정을 맨 처음에 넣은 것이다. 실제 Z 값으로 복원하는 이유는 간단하다. Linear 하지 않은 Depth 값을 연산시에 사용하면 보다 부정확한 결과가 나오기 때문이다. 특히 SSAO 연산을 할때는 Depth 값이 기본이 되기 때문에 해주어야 한다. 이 단계에서의 결론은 간단하다. Clipping-Space 의 Depth 값을 View-Space 의 Z 값으로 변환하는 단계다. 처리하는 코드는 다른 단계에 비해 짧다. 만약에 넘겨준 Depth 데이터들이 View-Space 인 경우에는 옵션을 통해 처리할 수 있다. Deintereaved Texturing 위의 그림에는 Generate HBAO+ 라고 단순히 뭉뚱그려서 표현했지만 그 안에는 단순한 Horizon based ambient occlusion(HBAO) 계산만 있지는 않다. Deintereaved Texturing 이라는 테크닉과 함께 HBAO 를 계산한다. Computer Engineering 분야의 지식을 응용한 이론으로 개인적으로 이 이론을 접했을 떄 꽤나 충격이였다. 자세한 설명은 GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing 슬라이드의 몇장과 함께 보자. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing Deintereaved Texturing 의 방법은 간단하다. 텍스쳐를 여러장으로 나누어 샘플링을 한 후 각각의 나눠진 텍스쳐를 샘플링한 결과를 하나로 합친다. 슬라이드에는 Post-Processing 을 기준으로 설명이 되어있다. 이점은 생각하면서 보자. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing 한 텍스쳐를 여러장으로 나누는건 Multiple Render Target 을 사용해서 나눈다. 슬라이드는 4개를 기준으로 설명했지만 DirectX10 부터는 최대 8개까지 지원하기 때문에 16개로 나누어 샘플링한다. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing 다음은 나누어진 각각의 텍스쳐를 샘플링하여 원하는 알고리즘으로 결과를 낸다. 조각난 텍스쳐 한개당 한번 DrawCall 을 걸어준다. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing Deintereave 를 하기전까지는 넓은 범위의 텍스쳐를 샘플링하여 캐시 효율이 많이 떨어졌지만 텍스쳐를 나누어 각각 할때마다 처리를 하게되니 캐시 효율의 이득을 얻었다. 또한 각각의 DrawCall 마다 텍스쳐의 용량이 조금만 필요하게 되니 대역폭의 이득도 얻게 된다. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing 한번의 DrawCall 로 나누어진 결과들을 합친다. Deintereaved Texturing 은 여기서 끝이다. 실제로 HBAO+ 는 16개의 텍스쳐로 나누어 샘플링한다. Multiple Render Target 이 8개까지 지원되어 16개로 Deintereave 하려면 2번 DrawCall 을 해야한다. 또한 샘플링은 16번 DrawCall 을 하여 계산한다. 그래서 한번 Deintereaved Texturing 을 사용하여 Post-Processing 처리하려면 약 20번의 DrawCall 을 계산해야 한다. 절대적으로 큰 숫자가 아니기 때문에 크게 신경쓸 필요는 없어보인다. 출처 : GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing 엄청난 성과를 거둔게 보인다. 캐시 히트 확률이 굉장히 올라갔고, 시간도 많이 절약했다. HBAO+ 의 성능향상을 시켜준 것이 이 Deinterleaved Texturing 인듯하다. Reconstruction of Normal HBAO+ 는 기본적으로 Depth 와 Normal 을 통해서 계산한다. 그렇기 때문에 외부에서 Normal 데이터를 넣어주거나 직접 만들어야 한다. 보통 Deffered Rendering 을 차용하는 시스템들은 간단하게 GBuffer 의 Normal 데이터만 넣어주면 된다. Normal 데이터를 가져오는 코드가 있으니 조금만 수정하여 사용하면 된다. Normal 데이터가 없는 경우에는 라이브러리 내에 직접 계산한다. 계산하는 픽셀을 기준으로 상하,좌우별로 Depth 와 화면상의 좌표계를 이용하여 View-Space 의 위치를 구한다음 위치가 상하, 좌우별로 가까운 픽셀의 위치 오프셋을 사용해 외적하여 Normal 값을 구한다. 참조 자료 NVidia HBAO+ NVidia : Deintereaved Texturing GDC2013 : Particle Shadows &amp;amp; Cache-Efficient Post-Processing GDCVault : Particle Shadows &amp;amp; Cache-Efficient Post-Processing Video</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Hbao Plus Analysis 0</title>
      
      <link href="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-0/" rel="alternate" type="text/html" title="Hbao Plus Analysis 0" />
      <published>2017-11-15T00:00:00+00:00</published>
      <updated>2017-11-15T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-0</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/11/15/hbao-plus-analysis-0/">&lt;p&gt;게임에서 쓰이는 실시간 렌더링에서 빛과 물체들의 상호작용을 완벽하게 현실적으로 표현하는 거의 불가능하다. 하지만 이를 위해 수십년동안 많은 엔지니어와 연구자들이 노력하여 부분적이고 제한된 환경에서의 빛과 물체의 상호작용을 현실 세계와 비슷하게 따라잡고 있다. 이번 글에서 살펴볼 것은 &lt;em&gt;Screen-Space Ambient Occlusion(SSAO)&lt;/em&gt; 기반의 &lt;em&gt;HBAO+&lt;/em&gt; 라는 라이브러리에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;HBAO+&lt;/em&gt; 는 NVidia 에서 만든 라이브러리로써, 현재 &lt;a href=&quot;https://developer.nvidia.com/shadowworks&quot;&gt;&lt;em&gt;ShadowWorks&lt;/em&gt;&lt;/a&gt; 라는 프로젝트에 포함되어 있다. &lt;a href=&quot;https://developer.nvidia.com/shadowworks&quot;&gt;&lt;em&gt;ShadowWorks&lt;/em&gt;&lt;/a&gt; 에는 &lt;em&gt;HBAO+&lt;/em&gt; 뿐만 아니라 &lt;em&gt;ShadowLib&lt;/em&gt; 이라는 그림자 렌더링을 위한 라이브러리로써 HFTS, PCSS, CSM 등 많은 기능들을 포함하고 있는 라이브러리가 있다. 현재 &lt;em&gt;ShadowLib&lt;/em&gt; 은 오픈소스가 아니지만 이번에 알아볼 &lt;em&gt;HBAO+&lt;/em&gt; 는 &lt;em&gt;Github&lt;/em&gt; 에서 소스를 받을 수 있다. 이에 대한 자세한 사항은 &lt;a href=&quot;https://developer.nvidia.com/gameworks-source-github&quot;&gt;“Access GameWorks Source on Github”&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;h3&gt;Ambient Occlusion?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Ambient Occlusion&lt;/em&gt; 이란 말은 처음 들어본 사람에게는 생소한 말이지만 한번이라도 들어본 사람들에게는 꽤나 익숙한 말일 것이다. 빠른 이해를 위해 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/220px-AmbientOcclusion_German.jpg&quot; alt=&quot;Wikipedia : Ambient Occlusion Image&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Ambient_occlusion&quot;&gt;Wikipedia : Ambient Occlusion&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;가장 위의 이미지를 보자. 단순한 렌더링이 아니라 반사를 구현해놓아서 꽤나 사실적이다. 하지만 여기서 더욱더 사실적으로 표현이 가능하다. 중간의 이미지를 보면 &lt;em&gt;Ambient Occlusion&lt;/em&gt; 이 무엇인지 쉽게 알 수 있다. 흰색 물체와 흰색 배경과 함께 아래 구석에 어두워진 것을 볼 수 있다. 이를 &lt;em&gt;Ambient Occlusion&lt;/em&gt; 이라고 한다.&lt;/p&gt;

&lt;p&gt;글로 간단하게 설명하자면 물체가 모이면 좁은 공간이 생기게 되고, 구석이면 구석일 수록 직접 들어오는 빛은 있으나 반사되어 오는 빛이 적어지므로 어두워진다. 이를 말하는 것이바로 &lt;em&gt;Ambient Occlusion&lt;/em&gt; 이다. &lt;em&gt;Ambient&lt;/em&gt; 는 주변을 뜻하고, &lt;em&gt;Occlusion&lt;/em&gt; 은 무언가 가리는 것을 뜻한다. 빛을 가려서 주변에 보이는 것이 어두워지는 것을 말하는 것이다.&lt;/p&gt;

&lt;p&gt;보통 &lt;em&gt;Ambient Occlusion&lt;/em&gt; 은 개발시에 미리 시간을 들여 계산해 미리 저장해놓은 다음 실시간으로 저장된 데이터를 읽어서 사용하는 &lt;em&gt;precomputed AO&lt;/em&gt; 방식으로 사용한다. 이유는 간단하다. 실시간으로 계산되기에는 요즘 컴퓨터로는 연산량을 버틸 수 없어서 그렇다. 월드가 복잡할수록, 넓을수록, 고퀄리티의 &lt;em&gt;AO&lt;/em&gt; 를 계산할수록 시간이 대폭 증가한다. 하지만 이는 물체와 물체간의 &lt;em&gt;AO&lt;/em&gt; 를 계산할때의 이야기이다.&lt;/p&gt;

&lt;h3&gt;Screen-Space AO?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Deffered Rendering&lt;/em&gt; 이 많이 쓰이면서 이를 위한 많은 기술들이 연구되었다. &lt;em&gt;Deffered Rendering&lt;/em&gt; 의 대부분의 기술들은 이름앞에 보통 &lt;em&gt;Screen-Space&lt;/em&gt; 라는 단어를 달고 나왔다. &lt;em&gt;Screen-Space&lt;/em&gt; 란 &lt;em&gt;Geometry Stage&lt;/em&gt; 아닌 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 로 넘어가서 처리되는 부분을 말한다. 말 뜻대로 해석한다면 2D 이미지의 공간이라는 뜻도 되겠다. 다만 &lt;em&gt;Pixel Shader&lt;/em&gt; 로 넘어간다고 해서 &lt;em&gt;Depth(Z value)&lt;/em&gt; 가 사라지지는 않기 때문에 이를 온전히 2D 공간이라고도 볼 수는 없다. 실제 좌표계는 &lt;em&gt;Clipping-Space&lt;/em&gt; 로 되어 있을 것이다.(x,y,z 가 -1 ~ 1 범위의 좌표로 되어있는 공간, Driver API 에 따라 조금씩 다르다.) 쉽게 이해하기 위해 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/DeferredLighting.jpg&quot; alt=&quot;Deffered Rendering&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://tower22.blogspot.kr/2010/11/from-deferred-to-inferred-part-uno.html&quot;&gt;From Deferred to Inferred, part uno&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 &lt;em&gt;Deffered Rendering&lt;/em&gt; 의 중요한 특징을 나타내는 그림이다. 이 데이터들을 &lt;em&gt;GBuffer&lt;/em&gt; 라고 한다. 저 결과들은 &lt;em&gt;Multi Render Target&lt;/em&gt; 을 통해 한 &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 나온 결과물들이다. 즉 한 장면을 렌더링해서 2D 버퍼안에 데이터들을 픽셀별로 저장한 것이다. 각각 저마다 필요한 정보들을 담고 있다. 우리가 알아볼 &lt;em&gt;Screen-Space AO&lt;/em&gt; 또한 이런식으로 데이터를 처리한다. 위 그림에는 나와있지 않지만 하드웨어 차원에서 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 지원한다. &lt;em&gt;Pixel Shader&lt;/em&gt; 를 실행한 후 알아서 &lt;em&gt;Depth Buffer&lt;/em&gt; 에 Z 값을 저장해준다. &lt;em&gt;Screen-Space AO&lt;/em&gt; 는 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 이용하여 계산한다. 물론 &lt;em&gt;Depth Buffer&lt;/em&gt; 뿐만아니라 &lt;em&gt;GBuffer&lt;/em&gt; 에서 &lt;em&gt;Normal&lt;/em&gt; 데이터까지 사용하여 할 수도 있다.&lt;/p&gt;

&lt;p&gt;하지만 &lt;em&gt;SSAO&lt;/em&gt; 는 정공법이 아니다. 모든 &lt;em&gt;AO&lt;/em&gt; 를 표현할 수 없으며 디테일한 &lt;em&gt;AO&lt;/em&gt; 밖에 표현하지 못한다. 그렇기에 이는 부가적인 방법으로 사용되어야 한다. &lt;em&gt;SSAO&lt;/em&gt; 를 활용하기 가장 좋은 장면은 화면에서 작게 표시되는 오브젝트들이 조밀하게 많이 있을 떄나 그려지는 오브젝트의 디테일이 많을 때다. 이럴때 &lt;em&gt;SSAO&lt;/em&gt; 를 표현하면 괜찮은 결과가 나온다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/0cf69542-8ff5-422a-8d01-f11bd65ab62e_scaled.jpg&quot; alt=&quot;Unity Technology : SSAO&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://forum.unity.com/threads/ssao-pro-high-quality-screen-space-ambient-occlusion.274003/page-5&quot;&gt;Unity Forum&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;게임에서는 조금이라도 복잡한 메시를 쓸 수 밖에 없기 때문에 결국 왠만한 게임에는 &lt;em&gt;SSAO&lt;/em&gt; 를 넣는 것이 괜찮은 선택이 된것이다. 하지만 초기에 제안된 &lt;em&gt;SSAO&lt;/em&gt; 구현물들은 대부분 꽤나 시간을 잡아먹었었다. 그래서 시간에 따른 선택이 되었지만 &lt;em&gt;HBAO+&lt;/em&gt; 와 같은 개량된 기법이 여러개 등장하여 퍼포먼스를 다른 곳에 쓸 수 있게 되었다. &lt;a href=&quot;https://www.geforce.com/hardware/technology/hbao-plus/technology&quot;&gt;Geforce : HBAO+ Technology&lt;/a&gt; 에서 &lt;em&gt;SSAO&lt;/em&gt; 테크닉에 따른 벤치마킹을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hbao_bench.png&quot; alt=&quot;benchmark&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.geforce.com/hardware/technology/hbao-plus/technology&quot;&gt;Geforce : HBAO+ Technology&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;우리가 살펴볼 것은 가장 아래에 있는 &lt;em&gt;HBAO+&lt;/em&gt; 에 대한 것들이다. &lt;em&gt;Resolution&lt;/em&gt; 은 &lt;em&gt;Depth Buffer&lt;/em&gt; 의 해상도를 뜻한다. 당연히 큰 사이즈여야 디테일한 것까지 표현할 수 있다. 가장 왼쪽에 있는 것은 시간이다. &lt;em&gt;HBAO+&lt;/em&gt; 가 2.4ms 로 조금 느리지만 그 오른쪽에 있는 &lt;em&gt;Occlusion Samples Per AO Pixel&lt;/em&gt; 의 숫자와 같이 비교하면 이야기가 다르다. 이는 한 픽셀별로 몇번 다른 텍스쳐의 데이터 샘플링 숫자다. &lt;em&gt;HBAO&lt;/em&gt; 는 4번만 하지만, &lt;em&gt;HBAO+&lt;/em&gt; 는 이의 9배인 36번이다. 샘플링을 많이하게 되면 더욱더 사실적인 &lt;em&gt;SSAO&lt;/em&gt; 를 표현할 수 있다. 샘플링 숫자에 비하면 시간은 내어줄 수 있는 자원인 것이다.&lt;/p&gt;

&lt;p&gt;이 글에서는 &lt;em&gt;HBAO+&lt;/em&gt; 를 분석하기 전 배경이 되는 개념에 대해서 알아보았다. 다음 &lt;a href=&quot;/2017/11/15/hbao-plus-analysis-1/&quot;&gt;hbao plus analysis 1&lt;/a&gt; 에서는 &lt;em&gt;HBAO+&lt;/em&gt; 라이브러리에 대한 본격적인 분석을 해보려고 한다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ambient_occlusion&quot;&gt;Wikipedia : Ambient Occlusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/developer-program&quot;&gt;NVidia Developer Program&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geforce.com/hardware/technology/hbao-plus/technology&quot;&gt;Geforce : HBAO+ Technology&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.geforce.co.kr/index.php?document_srl=12616&amp;amp;mid=geforce&quot;&gt;한국 지포스 포럼 : HBAO+&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="analysis" />
      
        <category term="hbaoplus" />
      

      

      
        <summary type="html">게임에서 쓰이는 실시간 렌더링에서 빛과 물체들의 상호작용을 완벽하게 현실적으로 표현하는 거의 불가능하다. 하지만 이를 위해 수십년동안 많은 엔지니어와 연구자들이 노력하여 부분적이고 제한된 환경에서의 빛과 물체의 상호작용을 현실 세계와 비슷하게 따라잡고 있다. 이번 글에서 살펴볼 것은 Screen-Space Ambient Occlusion(SSAO) 기반의 HBAO+ 라는 라이브러리에 대해서 알아볼 것이다. HBAO+ 는 NVidia 에서 만든 라이브러리로써, 현재 ShadowWorks 라는 프로젝트에 포함되어 있다. ShadowWorks 에는 HBAO+ 뿐만 아니라 ShadowLib 이라는 그림자 렌더링을 위한 라이브러리로써 HFTS, PCSS, CSM 등 많은 기능들을 포함하고 있는 라이브러리가 있다. 현재 ShadowLib 은 오픈소스가 아니지만 이번에 알아볼 HBAO+ 는 Github 에서 소스를 받을 수 있다. 이에 대한 자세한 사항은 “Access GameWorks Source on Github” 에서 확인할 수 있다. Ambient Occlusion? Ambient Occlusion 이란 말은 처음 들어본 사람에게는 생소한 말이지만 한번이라도 들어본 사람들에게는 꽤나 익숙한 말일 것이다. 빠른 이해를 위해 아래 그림을 보자. 출처 : Wikipedia : Ambient Occlusion 가장 위의 이미지를 보자. 단순한 렌더링이 아니라 반사를 구현해놓아서 꽤나 사실적이다. 하지만 여기서 더욱더 사실적으로 표현이 가능하다. 중간의 이미지를 보면 Ambient Occlusion 이 무엇인지 쉽게 알 수 있다. 흰색 물체와 흰색 배경과 함께 아래 구석에 어두워진 것을 볼 수 있다. 이를 Ambient Occlusion 이라고 한다. 글로 간단하게 설명하자면 물체가 모이면 좁은 공간이 생기게 되고, 구석이면 구석일 수록 직접 들어오는 빛은 있으나 반사되어 오는 빛이 적어지므로 어두워진다. 이를 말하는 것이바로 Ambient Occlusion 이다. Ambient 는 주변을 뜻하고, Occlusion 은 무언가 가리는 것을 뜻한다. 빛을 가려서 주변에 보이는 것이 어두워지는 것을 말하는 것이다. 보통 Ambient Occlusion 은 개발시에 미리 시간을 들여 계산해 미리 저장해놓은 다음 실시간으로 저장된 데이터를 읽어서 사용하는 precomputed AO 방식으로 사용한다. 이유는 간단하다. 실시간으로 계산되기에는 요즘 컴퓨터로는 연산량을 버틸 수 없어서 그렇다. 월드가 복잡할수록, 넓을수록, 고퀄리티의 AO 를 계산할수록 시간이 대폭 증가한다. 하지만 이는 물체와 물체간의 AO 를 계산할때의 이야기이다. Screen-Space AO? Deffered Rendering 이 많이 쓰이면서 이를 위한 많은 기술들이 연구되었다. Deffered Rendering 의 대부분의 기술들은 이름앞에 보통 Screen-Space 라는 단어를 달고 나왔다. Screen-Space 란 Geometry Stage 아닌 Rasterizer Stage 로 넘어가서 처리되는 부분을 말한다. 말 뜻대로 해석한다면 2D 이미지의 공간이라는 뜻도 되겠다. 다만 Pixel Shader 로 넘어간다고 해서 Depth(Z value) 가 사라지지는 않기 때문에 이를 온전히 2D 공간이라고도 볼 수는 없다. 실제 좌표계는 Clipping-Space 로 되어 있을 것이다.(x,y,z 가 -1 ~ 1 범위의 좌표로 되어있는 공간, Driver API 에 따라 조금씩 다르다.) 쉽게 이해하기 위해 아래 그림을 보자. 출처 : From Deferred to Inferred, part uno 위 그림은 Deffered Rendering 의 중요한 특징을 나타내는 그림이다. 이 데이터들을 GBuffer 라고 한다. 저 결과들은 Multi Render Target 을 통해 한 Pixel Shader 에서 나온 결과물들이다. 즉 한 장면을 렌더링해서 2D 버퍼안에 데이터들을 픽셀별로 저장한 것이다. 각각 저마다 필요한 정보들을 담고 있다. 우리가 알아볼 Screen-Space AO 또한 이런식으로 데이터를 처리한다. 위 그림에는 나와있지 않지만 하드웨어 차원에서 Depth Buffer 를 지원한다. Pixel Shader 를 실행한 후 알아서 Depth Buffer 에 Z 값을 저장해준다. Screen-Space AO 는 Depth Buffer 를 이용하여 계산한다. 물론 Depth Buffer 뿐만아니라 GBuffer 에서 Normal 데이터까지 사용하여 할 수도 있다. 하지만 SSAO 는 정공법이 아니다. 모든 AO 를 표현할 수 없으며 디테일한 AO 밖에 표현하지 못한다. 그렇기에 이는 부가적인 방법으로 사용되어야 한다. SSAO 를 활용하기 가장 좋은 장면은 화면에서 작게 표시되는 오브젝트들이 조밀하게 많이 있을 떄나 그려지는 오브젝트의 디테일이 많을 때다. 이럴때 SSAO 를 표현하면 괜찮은 결과가 나온다. 출처 : Unity Forum 게임에서는 조금이라도 복잡한 메시를 쓸 수 밖에 없기 때문에 결국 왠만한 게임에는 SSAO 를 넣는 것이 괜찮은 선택이 된것이다. 하지만 초기에 제안된 SSAO 구현물들은 대부분 꽤나 시간을 잡아먹었었다. 그래서 시간에 따른 선택이 되었지만 HBAO+ 와 같은 개량된 기법이 여러개 등장하여 퍼포먼스를 다른 곳에 쓸 수 있게 되었다. Geforce : HBAO+ Technology 에서 SSAO 테크닉에 따른 벤치마킹을 볼 수 있다. 출처 : Geforce : HBAO+ Technology 우리가 살펴볼 것은 가장 아래에 있는 HBAO+ 에 대한 것들이다. Resolution 은 Depth Buffer 의 해상도를 뜻한다. 당연히 큰 사이즈여야 디테일한 것까지 표현할 수 있다. 가장 왼쪽에 있는 것은 시간이다. HBAO+ 가 2.4ms 로 조금 느리지만 그 오른쪽에 있는 Occlusion Samples Per AO Pixel 의 숫자와 같이 비교하면 이야기가 다르다. 이는 한 픽셀별로 몇번 다른 텍스쳐의 데이터 샘플링 숫자다. HBAO 는 4번만 하지만, HBAO+ 는 이의 9배인 36번이다. 샘플링을 많이하게 되면 더욱더 사실적인 SSAO 를 표현할 수 있다. 샘플링 숫자에 비하면 시간은 내어줄 수 있는 자원인 것이다. 이 글에서는 HBAO+ 를 분석하기 전 배경이 되는 개념에 대해서 알아보았다. 다음 hbao plus analysis 1 에서는 HBAO+ 라이브러리에 대한 본격적인 분석을 해보려고 한다. 참조 자료 Wikipedia : Ambient Occlusion NVidia Developer Program Geforce : HBAO+ Technology 한국 지포스 포럼 : HBAO+</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 4 Geometry Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader/" rel="alternate" type="text/html" title="Shader Pipeline 4 Geometry Shader" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader/">&lt;p&gt;“&lt;a href=&quot;/2017/10/31/shader-pipeline-3-fragment-shader/&quot;&gt;Fragemnt Shader&lt;/a&gt;” 에서 &lt;em&gt;Fragment Shader&lt;/em&gt; 에 대해 알아보았다. 다음은 &lt;em&gt;Geometry Shader&lt;/em&gt; 에 대해서 써보려 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Geometry Shader&lt;/em&gt; 는 쉐이더 파이프라인에서 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 넘어가기 전의 &lt;em&gt;Geometry Stage&lt;/em&gt; 의 마지막 단계로써 이전 쉐이더에서 넘긴  &lt;em&gt;Primitive&lt;/em&gt; 데이터(point, line, triangle..)를 프로그래머가 원하는 복수의 &lt;em&gt;Primitive&lt;/em&gt; 데이터로 변환할 수 있다. 삼각형을 삼각형의 중심을 나타내는 점으로 변환하는 쉐이더를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;[maxvertexcount(1)]
void geom(vertexOutput input[3], inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream)
{
    geometryShaderOutput o;

    o.vertex = (input[0].vertex + input[1].vertex + input[2].vertex) / 3;

    pointStream.Append(o);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;매우 간단한 코드다. 간략하게 설명하자면, 맨 윗줄의 &lt;em&gt;maxvertexcount&lt;/em&gt; 는 해당 지오메트리 쉐이더에서 &lt;em&gt;Stream&lt;/em&gt; 으로 넘길 정점별 데이터의 갯수를 뜻한다. &lt;em&gt;Geometry Shader&lt;/em&gt; 한번당 &lt;em&gt;Stream&lt;/em&gt; 으로 넘길 &lt;em&gt;maxvertexcount&lt;/em&gt; 의 한계는 정해지지 않았지만 크기는 1024 바이트로 정해져 있기 때문에 적절하게 사용해야 겠다. 그 다음줄의 인자들에 대해서 설명하면, 첫번째 &lt;em&gt;vertexOutput input[3]&lt;/em&gt; 은 정해진 프리미티브의 값들을 뜻한다. 여기서는 삼각형을 기준으로 만들었기 때문에 정점별 정보가 3개가 있다. _inout PointStream&lt;geometryOutput&gt; pointStream_ 은 _Geometry Shader_ 의 최종 출력을 해주는 오브젝트다. _PointStream_ 은 점 프리미티브의 데이터를 받는 _Stream_ 으로써, 프리미티브가 다르면 각자 다른것을 사용할 수 있다.([MSDN : Getting Started with the Stream-Output Stage](https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx)) 부등호 안에 있는 것은 일반적으로 알려진 제너릭이나 템플릿의 형태와 같으니 안에 출력으로 넘길 구조체를 넘겨주면 된다. 함수의 내용은 삼각형을 구성하는 각 정점의 위치의 평균을 구해 하나의 정점 정보만 _Stream_ 에 넘긴다.&lt;/geometryOutput&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stream&lt;/em&gt; 은 총 두가지의 역할을 한다. 하나는 &lt;em&gt;Rasterizer&lt;/em&gt; 단계로 넘겨서 쉐이더에서 처리를 할 수 있게 하는 통로 역할을 하고, 다른 하나는 드라이버 레벨에서 데이터를 출력해주는 통로 역할을 한다. 두가지의 일을 하기 때문에 &lt;em&gt;Stream&lt;/em&gt; 의 개념으로 추상화한 것인가 싶다. 그리고 하나의 &lt;em&gt;Geometry Shader&lt;/em&gt; 에서 여러개의 &lt;em&gt;Stream&lt;/em&gt; 으로 출력이 가능하긴 하다. 최대 4개의 &lt;em&gt;Stream&lt;/em&gt; 을 사용할 수 있다. &lt;em&gt;Stream&lt;/em&gt; 을 선택해서 데이터를 받아올 수도 있으며, &lt;em&gt;Rasterizer&lt;/em&gt; 로 보낼수도 있다. 자세한 사항은 &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471424.aspx&quot;&gt;MSDN : How To: Index Multiple Output Streams &lt;/a&gt; 에서 확인하면 되겠다.&lt;/p&gt;

&lt;p&gt;활용할 수 있는 다른 기능이 하나 더 있다. &lt;em&gt;instance&lt;/em&gt; 기능이다. 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;[instance(3)]
[maxvertexcount(1)]
void geom(vertexOutput input[3], uint InstanceID : SV_GSInstanceID, inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream)
{
    geometryShaderOutput o;

    o.vertex = input[InstanceID].vertex;

    pointStream.Append(o);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 코드는 삼각형의 세개의 정점 위치를 넘기는 코드다. 달라진 것은 &lt;em&gt;instance(3)&lt;/em&gt; 코드가 붙고, &lt;em&gt;uint InstanceID : SV_GSInstanceID&lt;/em&gt; 파라미터가 생겨 코드 안에서 이를 활용한다. &lt;em&gt;instance(x)&lt;/em&gt; 에 들어가는 x 는 반복하는 횟수를 뜻하고, &lt;em&gt;InstanceID&lt;/em&gt; 파라미터는 반복하는 인덱스를 뜻한다. 같은 입력을 여러번 받아서 일정한 수만큼 반복하는 것이다.  &lt;em&gt;instance&lt;/em&gt; 속성에 들어가는 숫자의 한계는 32까지다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Geometry Shader&lt;/em&gt; 는 &lt;em&gt;Shader Model 4.0&lt;/em&gt; 에서 추가되었으며 뒤에 추가적으로 알아본 &lt;em&gt;multiple stream&lt;/em&gt; 과 &lt;em&gt;instance&lt;/em&gt; 키워드는 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 에서 확장된 기능들이다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509609.aspx&quot;&gt;MSDN : Geometry-Shader Object&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx&quot;&gt;MSDN : Getting Started with the Stream-Output Stage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471424.aspx&quot;&gt;MSDN : How To: Index Multiple Output Streams&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471425.aspx&quot;&gt;MSDN : How To: Instance a Geometry Shader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/600141-limit-on-maxvertexcount-gs/&quot;&gt;GameDev : limit on maxvertexcount() GS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">“Fragemnt Shader” 에서 Fragment Shader 에 대해 알아보았다. 다음은 Geometry Shader 에 대해서 써보려 한다. Geometry Shader 는 쉐이더 파이프라인에서 Rasterizer Stage 넘어가기 전의 Geometry Stage 의 마지막 단계로써 이전 쉐이더에서 넘긴 Primitive 데이터(point, line, triangle..)를 프로그래머가 원하는 복수의 Primitive 데이터로 변환할 수 있다. 삼각형을 삼각형의 중심을 나타내는 점으로 변환하는 쉐이더를 보자. [maxvertexcount(1)] void geom(vertexOutput input[3], inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream) { geometryShaderOutput o; o.vertex = (input[0].vertex + input[1].vertex + input[2].vertex) / 3; pointStream.Append(o); } 매우 간단한 코드다. 간략하게 설명하자면, 맨 윗줄의 maxvertexcount 는 해당 지오메트리 쉐이더에서 Stream 으로 넘길 정점별 데이터의 갯수를 뜻한다. Geometry Shader 한번당 Stream 으로 넘길 maxvertexcount 의 한계는 정해지지 않았지만 크기는 1024 바이트로 정해져 있기 때문에 적절하게 사용해야 겠다. 그 다음줄의 인자들에 대해서 설명하면, 첫번째 vertexOutput input[3] 은 정해진 프리미티브의 값들을 뜻한다. 여기서는 삼각형을 기준으로 만들었기 때문에 정점별 정보가 3개가 있다. _inout PointStream pointStream_ 은 _Geometry Shader_ 의 최종 출력을 해주는 오브젝트다. _PointStream_ 은 점 프리미티브의 데이터를 받는 _Stream_ 으로써, 프리미티브가 다르면 각자 다른것을 사용할 수 있다.([MSDN : Getting Started with the Stream-Output Stage](https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx)) 부등호 안에 있는 것은 일반적으로 알려진 제너릭이나 템플릿의 형태와 같으니 안에 출력으로 넘길 구조체를 넘겨주면 된다. 함수의 내용은 삼각형을 구성하는 각 정점의 위치의 평균을 구해 하나의 정점 정보만 _Stream_ 에 넘긴다. Stream 은 총 두가지의 역할을 한다. 하나는 Rasterizer 단계로 넘겨서 쉐이더에서 처리를 할 수 있게 하는 통로 역할을 하고, 다른 하나는 드라이버 레벨에서 데이터를 출력해주는 통로 역할을 한다. 두가지의 일을 하기 때문에 Stream 의 개념으로 추상화한 것인가 싶다. 그리고 하나의 Geometry Shader 에서 여러개의 Stream 으로 출력이 가능하긴 하다. 최대 4개의 Stream 을 사용할 수 있다. Stream 을 선택해서 데이터를 받아올 수도 있으며, Rasterizer 로 보낼수도 있다. 자세한 사항은 MSDN : How To: Index Multiple Output Streams 에서 확인하면 되겠다. 활용할 수 있는 다른 기능이 하나 더 있다. instance 기능이다. 아래 코드를 보자. [instance(3)] [maxvertexcount(1)] void geom(vertexOutput input[3], uint InstanceID : SV_GSInstanceID, inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream) { geometryShaderOutput o; o.vertex = input[InstanceID].vertex; pointStream.Append(o); } 해당 코드는 삼각형의 세개의 정점 위치를 넘기는 코드다. 달라진 것은 instance(3) 코드가 붙고, uint InstanceID : SV_GSInstanceID 파라미터가 생겨 코드 안에서 이를 활용한다. instance(x) 에 들어가는 x 는 반복하는 횟수를 뜻하고, InstanceID 파라미터는 반복하는 인덱스를 뜻한다. 같은 입력을 여러번 받아서 일정한 수만큼 반복하는 것이다. instance 속성에 들어가는 숫자의 한계는 32까지다. Geometry Shader 는 Shader Model 4.0 에서 추가되었으며 뒤에 추가적으로 알아본 multiple stream 과 instance 키워드는 Shader Model 5.0 에서 확장된 기능들이다. 참조 자료 MSDN : Geometry-Shader Object MSDN : Getting Started with the Stream-Output Stage MSDN : How To: Index Multiple Output Streams MSDN : How To: Instance a Geometry Shader GameDev : limit on maxvertexcount() GS</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 3 Fragment Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader/" rel="alternate" type="text/html" title="Shader Pipeline 3 Fragment Shader" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader/">&lt;p&gt;이전 글 : “&lt;a href=&quot;/2017/10/31/shader-pipeline-2-rasterizer/&quot;&gt;Rasterizer&lt;/a&gt;” 에서 &lt;em&gt;Rasterizer&lt;/em&gt; 에 대해 알아보았다. 이번에는 &lt;em&gt;Fragment Shader&lt;/em&gt; 을 알아보자.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인에서 &lt;em&gt;Rasterizer&lt;/em&gt; 다음에 실행되는 것은 &lt;em&gt;Programmable Shader&lt;/em&gt; 중에서 &lt;em&gt;Fragment Shader&lt;/em&gt; 이다. &lt;em&gt;Fragment Shader&lt;/em&gt; 은 &lt;em&gt;Pixel Shader&lt;/em&gt; 라고도 불리는데, 이전에 &lt;em&gt;Rasterizer&lt;/em&gt; 에서 조각낸 픽셀들을 단위로 실행되기 때문에 &lt;em&gt;Pixel Shader&lt;/em&gt; 라고 불리기도 한다. 또한 각 픽셀은 조각난 단위이기 때문에 조각의 뜻을 가진 &lt;em&gt;Fragment Shader&lt;/em&gt; 라고도 불린다. 이 글에서는 &lt;em&gt;Fragment Shader&lt;/em&gt; 로 사용할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Fragment Shader&lt;/em&gt; 의 역할은 굉장히 단순하다. &lt;em&gt;Geometry Stage&lt;/em&gt; 에서 넘어와 &lt;em&gt;Rasterizer&lt;/em&gt; 단계에서 정리된 파라미터를 받고, 해당 픽셀의 색을 반환하면 끝난다. 역할은 단순하지만 그만큼 중요한 것이 &lt;em&gt;Fragment Shader&lt;/em&gt; 다. 마지막으로 픽셀 단위로 보여주는 색을 바꿀 수 있는 &lt;em&gt;Programmable Shader&lt;/em&gt; 로써 반복하는 비용이 꽤나 많아 일반적으로 오래 걸린다고 평가되지만 색을 바꿀 수 있어 그만큼 잘쓰면 굉장한 효과를 낼 수 있는 &lt;em&gt;Programmable Shader&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/fragment_shader.jpg&quot; alt=&quot;Fragment Shader&quot; /&gt;&lt;/p&gt;

&lt;p&gt;가장 단순한 형태의 Unity 에서 사용하는 CG/HLSL 쉐이더를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#pragma fragment frag

struct v2f
{
    float4 vertex : SV_POSITION;
    float4 tangent : TANGENT;
    float3 normal : NORMAL;
    float4 texcoord : TEXCOORD0;
}

/*
  다른 코드 들..
*/

fixed4 frag(v2f i)
{
  return float4(1,1,1,1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 쉐이더는 단순하게 흰색만 출력해주는 쉐이더다. 그만큼 매우 단순하고 쉽다. 하지만 많은 것들을 표현하려면 &lt;em&gt;frag&lt;/em&gt; 함수의 코드는 점점 길어질 것이다.&lt;/p&gt;

&lt;p&gt;또한 &lt;em&gt;Fragment Shader&lt;/em&gt; 가 실행되는 시점에서 하드웨어, 드라이버 단계에서 지원하는 기능들도 있다. 일반적인 것들에 대해서 이야기 하자면 &lt;em&gt;Depth Buffer&lt;/em&gt; 와 &lt;em&gt;Stencil Buffer&lt;/em&gt; 가 있다. 두가지의 공통점은 각 픽셀 단위별로 데이터를 저장하는 버퍼들이다. &lt;em&gt;Depth Buffer&lt;/em&gt; 는 &lt;em&gt;Clip-Space&lt;/em&gt; 로 변환된 정점 값의 Z 값을 저장하는 용도로 쓰이는 버퍼로, 요즘 개발되거나 쓰이는 기술들은 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 엄청 많이 쓴다. 대표적으로 &lt;em&gt;Depth Pre-Pass&lt;/em&gt; 가 있다. &lt;em&gt;Stencil Buffer&lt;/em&gt; 는 픽셀별로 정수 데이터를 저장해서 사용하는 버퍼로써, 대부분 마스킹을 할 때 쓰인다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/kyruie/everything-about-earlyz&quot;&gt;SlideShader : Everything about Early-Z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">이전 글 : “Rasterizer” 에서 Rasterizer 에 대해 알아보았다. 이번에는 Fragment Shader 을 알아보자. 쉐이더 파이프라인에서 Rasterizer 다음에 실행되는 것은 Programmable Shader 중에서 Fragment Shader 이다. Fragment Shader 은 Pixel Shader 라고도 불리는데, 이전에 Rasterizer 에서 조각낸 픽셀들을 단위로 실행되기 때문에 Pixel Shader 라고 불리기도 한다. 또한 각 픽셀은 조각난 단위이기 때문에 조각의 뜻을 가진 Fragment Shader 라고도 불린다. 이 글에서는 Fragment Shader 로 사용할 것이다. Fragment Shader 의 역할은 굉장히 단순하다. Geometry Stage 에서 넘어와 Rasterizer 단계에서 정리된 파라미터를 받고, 해당 픽셀의 색을 반환하면 끝난다. 역할은 단순하지만 그만큼 중요한 것이 Fragment Shader 다. 마지막으로 픽셀 단위로 보여주는 색을 바꿀 수 있는 Programmable Shader 로써 반복하는 비용이 꽤나 많아 일반적으로 오래 걸린다고 평가되지만 색을 바꿀 수 있어 그만큼 잘쓰면 굉장한 효과를 낼 수 있는 Programmable Shader 다. 가장 단순한 형태의 Unity 에서 사용하는 CG/HLSL 쉐이더를 보자. #pragma fragment frag struct v2f { float4 vertex : SV_POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; } /* 다른 코드 들.. */ fixed4 frag(v2f i) { return float4(1,1,1,1); } 해당 쉐이더는 단순하게 흰색만 출력해주는 쉐이더다. 그만큼 매우 단순하고 쉽다. 하지만 많은 것들을 표현하려면 frag 함수의 코드는 점점 길어질 것이다. 또한 Fragment Shader 가 실행되는 시점에서 하드웨어, 드라이버 단계에서 지원하는 기능들도 있다. 일반적인 것들에 대해서 이야기 하자면 Depth Buffer 와 Stencil Buffer 가 있다. 두가지의 공통점은 각 픽셀 단위별로 데이터를 저장하는 버퍼들이다. Depth Buffer 는 Clip-Space 로 변환된 정점 값의 Z 값을 저장하는 용도로 쓰이는 버퍼로, 요즘 개발되거나 쓰이는 기술들은 Depth Buffer 를 엄청 많이 쓴다. 대표적으로 Depth Pre-Pass 가 있다. Stencil Buffer 는 픽셀별로 정수 데이터를 저장해서 사용하는 버퍼로써, 대부분 마스킹을 할 때 쓰인다. 참조 자료 SlideShader : Everything about Early-Z</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 2 Rasterizer</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer/" rel="alternate" type="text/html" title="Shader Pipeline 2 Rasterizer" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer/">&lt;p&gt;이전 포스트 “&lt;a href=&quot;/2017/10/30/shader-pipeline-1-vertex-shader/&quot;&gt;Vertex Shader&lt;/a&gt;” 에서 &lt;em&gt;Vertex Shader&lt;/em&gt; 에 대해 간단히 알아보았다. 이번 글에서는 &lt;em&gt;Rasterizer&lt;/em&gt; 에 대해서 간단히 써보려 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Rasterizer&lt;/em&gt; 는 쉐이더 파이프라인에 존재하는 고정 기능 단계이다. 간단하게 정의하면, &lt;em&gt;Rasterizer&lt;/em&gt; 이전 단계를 거쳐 나온 Geometry 데이터들(vertex, mesh, …)을 정해진 해상도에 맞춰 픽셀별로 조각내어 주는 단계다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i-msdn.sec.s-msft.com/dynimg/IC520311.png&quot; alt=&quot;MSDN : Traignel Rasterization Rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이는 일반적인 삼각형 폴리곤을 &lt;em&gt;Rasterizer&lt;/em&gt; 단계에서 어떻게 픽셀로 변환하는지 한눈에 알게 해놓은 사진이다. 겹치는 정도에 따라 검은색에 가깝게 해놓은 것을 볼 수있다. &lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/cc627092.aspx&quot;&gt;MSDN : Rasterization Rules&lt;/a&gt; 에서 다른 프리미티브의 &lt;em&gt;Rasterize&lt;/em&gt; 과정도 살펴볼 수 있다.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인에서 &lt;em&gt;Rasterizer&lt;/em&gt; 가 가지는 의미도 조금 특별하다. 이는 3차원 메시 데이터를 2차원 이미지 데이터로 바꿔주는 과정이기 때문에 &lt;em&gt;Geometry Stage&lt;/em&gt; 에서 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 로 넘어가는 관문이다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/cc627092.aspx&quot;&gt;MSDN : Rasterization Rules&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">이전 포스트 “Vertex Shader” 에서 Vertex Shader 에 대해 간단히 알아보았다. 이번 글에서는 Rasterizer 에 대해서 간단히 써보려 한다. Rasterizer 는 쉐이더 파이프라인에 존재하는 고정 기능 단계이다. 간단하게 정의하면, Rasterizer 이전 단계를 거쳐 나온 Geometry 데이터들(vertex, mesh, …)을 정해진 해상도에 맞춰 픽셀별로 조각내어 주는 단계다. 아래 그림을 보자. 이는 일반적인 삼각형 폴리곤을 Rasterizer 단계에서 어떻게 픽셀로 변환하는지 한눈에 알게 해놓은 사진이다. 겹치는 정도에 따라 검은색에 가깝게 해놓은 것을 볼 수있다. MSDN : Rasterization Rules 에서 다른 프리미티브의 Rasterize 과정도 살펴볼 수 있다. 쉐이더 파이프라인에서 Rasterizer 가 가지는 의미도 조금 특별하다. 이는 3차원 메시 데이터를 2차원 이미지 데이터로 바꿔주는 과정이기 때문에 Geometry Stage 에서 Rasterizer Stage 로 넘어가는 관문이다. 참조 자료 MSDN : Rasterization Rules</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 1 Vertex Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader/" rel="alternate" type="text/html" title="Shader Pipeline 1 Vertex Shader" />
      <published>2017-10-30T00:00:00+00:00</published>
      <updated>2017-10-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader/">&lt;p&gt;이번 글에서 언급할 쉐이더는 &lt;em&gt;Vertex Shader&lt;/em&gt; 다. 한글로는 &lt;em&gt;정점 쉐이더&lt;/em&gt; 라고 보통 말한다. &lt;em&gt;Vertex Shader&lt;/em&gt; 에서 할 수 있는 것은, 정점별로 들어온 정보들을 코딩을 해서 프로그래머가 원하는대로 바꾸어 다음 쉐이더에서 처리할 수 있도록 해주는 &lt;em&gt;Shader&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;Unity 에서의 CG/HLSL 일반적인 &lt;em&gt;Vertex Shader&lt;/em&gt; 코드는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#pragma vertex vert
#include &quot;UnityCG.cginc&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appdata_tan&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TANGENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NORMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXCOORD0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TANGENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NORMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXCOORD0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdata_tan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UNITY_MATRIX_MVP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  기타 코드들..
*/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;굉장히 단순한 &lt;em&gt;Vertex Shader&lt;/em&gt; 코드다. 코드가 단순한 만큼 이 &lt;em&gt;Shader&lt;/em&gt; 는 최소한의 역할만 하고 있다. &lt;em&gt;model-space&lt;/em&gt; 에 있는 정점을 &lt;em&gt;clipping-space&lt;/em&gt; 의 정점으로 변환 시켜 다음으로(fragment shader) 넘긴다. 위에서 위치 데이터를 바꿀 수 있다고 언급했는데, 이 변환은 정상적인 메커니즘을 통해 오브젝트를 출력하려면 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 로 넘어가기전에 반드시 정점값에 적용시켜주어야 하는 변환이다. 해당 변환에 대해서는 &lt;a href=&quot;https://docs.google.com/presentation/d/10VzsjfifKJlRTHDlBq7e8vNBTu4D5jOWUF87KYYGwlk/edit?usp=sharing&quot;&gt;Model, View, Projection&lt;/a&gt;에 설명해 놓았으니 간단하게 참고하길 바란다.&lt;/p&gt;

&lt;p&gt;위 코드에서 보여준 것들은 최소한의 것들이다. 코드를 짜는 것은 프로그래머의 역량이기 때문에 더 창의적인 것들을 할 수 있다. 쉬운 것들 중에서는 표면에서 웨이브를 주어 표면이 일렁이는 것처럼 보이게 할 수 있다. 이는 시간을 키값으로 두어 삼각함수를 이용해 할 수 있겠다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;float time;

struct appdata
{
    float4 vertex : POSITION;
};

struct v2f
{
    float4 vertex : SV_POSITION;
}

v2f vert(appdata i)
{
    v2f o;

    i.vertex = i.vertex + i.normal * sin(time + i.vertex.x + i.vertex.z);
    o.vertex = mul(UNITY_MATRIX_MVP, i.vertex);

    return o;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;메쉬는 여러개의 정사각형 모양으로 잘라진 평평한 판의 형태의 메쉬를 준비하고, 간단하게 x 좌표와 z 좌표를 기준으로 오브젝트가 일렁이는 것을 만들어 보았다. 이렇게 &lt;em&gt;Vertex Shader&lt;/em&gt; 를 응용해서 정점 데이터를 프로그래머가 원하는데로 움직일 수 있다. 정점 쉐이더는 사용하기에 크게 어려운점은 없기에 &lt;em&gt;Shader&lt;/em&gt; 를 처음 다룰 때 가지고 놀만하다. 또한 &lt;em&gt;Vertex Shader&lt;/em&gt; 가 가장 응용되기 쉬운 것은 바로 &lt;em&gt;skinning&lt;/em&gt; 이다. &lt;em&gt;skinning&lt;/em&gt; 자체가 정점 데이터들을 움직이고 움직임을 기반으로 바꾸는 것이기 때문에 &lt;em&gt;Vertex Shader&lt;/em&gt; 의 형태가 &lt;em&gt;skinning&lt;/em&gt; 을 적용하기 가장 알맞다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="cg" />
      
        <category term="hlsl" />
      
        <category term="unity" />
      

      

      
        <summary type="html">이번 글에서 언급할 쉐이더는 Vertex Shader 다. 한글로는 정점 쉐이더 라고 보통 말한다. Vertex Shader 에서 할 수 있는 것은, 정점별로 들어온 정보들을 코딩을 해서 프로그래머가 원하는대로 바꾸어 다음 쉐이더에서 처리할 수 있도록 해주는 Shader 다. Unity 에서의 CG/HLSL 일반적인 Vertex Shader 코드는 아래와 같다. #pragma vertex vert #include &quot;UnityCG.cginc&quot; struct appdata_tan { float4 vertex : POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; } v2f vert(appdata_tan i) { v2f o; o.vertex = mul(UNITY_MATRIX_MVP, i.vertex); o.tangent = i.tangent; o.normal = i.normal; o.texcoord = i.texcoord; return o; } /* 기타 코드들.. */ 굉장히 단순한 Vertex Shader 코드다. 코드가 단순한 만큼 이 Shader 는 최소한의 역할만 하고 있다. model-space 에 있는 정점을 clipping-space 의 정점으로 변환 시켜 다음으로(fragment shader) 넘긴다. 위에서 위치 데이터를 바꿀 수 있다고 언급했는데, 이 변환은 정상적인 메커니즘을 통해 오브젝트를 출력하려면 Rasterizer Stage 로 넘어가기전에 반드시 정점값에 적용시켜주어야 하는 변환이다. 해당 변환에 대해서는 Model, View, Projection에 설명해 놓았으니 간단하게 참고하길 바란다. 위 코드에서 보여준 것들은 최소한의 것들이다. 코드를 짜는 것은 프로그래머의 역량이기 때문에 더 창의적인 것들을 할 수 있다. 쉬운 것들 중에서는 표면에서 웨이브를 주어 표면이 일렁이는 것처럼 보이게 할 수 있다. 이는 시간을 키값으로 두어 삼각함수를 이용해 할 수 있겠다. float time; struct appdata { float4 vertex : POSITION; }; struct v2f { float4 vertex : SV_POSITION; } v2f vert(appdata i) { v2f o; i.vertex = i.vertex + i.normal * sin(time + i.vertex.x + i.vertex.z); o.vertex = mul(UNITY_MATRIX_MVP, i.vertex); return o; } 메쉬는 여러개의 정사각형 모양으로 잘라진 평평한 판의 형태의 메쉬를 준비하고, 간단하게 x 좌표와 z 좌표를 기준으로 오브젝트가 일렁이는 것을 만들어 보았다. 이렇게 Vertex Shader 를 응용해서 정점 데이터를 프로그래머가 원하는데로 움직일 수 있다. 정점 쉐이더는 사용하기에 크게 어려운점은 없기에 Shader 를 처음 다룰 때 가지고 놀만하다. 또한 Vertex Shader 가 가장 응용되기 쉬운 것은 바로 skinning 이다. skinning 자체가 정점 데이터들을 움직이고 움직임을 기반으로 바꾸는 것이기 때문에 Vertex Shader 의 형태가 skinning 을 적용하기 가장 알맞다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 0 Opening</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening/" rel="alternate" type="text/html" title="Shader Pipeline 0 Opening" />
      <published>2017-10-30T00:00:00+00:00</published>
      <updated>2017-10-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening/">&lt;h3&gt;쉐이더 프로그래밍 환경&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Programmable Shader&lt;/em&gt; 들을 정리하기 위해 각 쉐이더별로 한개씩 글을 써보기로 했다. 그 전에 미리 알아야될 것들에 대해 알아보려고 한다. 각각의 &lt;em&gt;Shader&lt;/em&gt; 들은 코더의 입장에서 바라보았을 때는 단지 몇개의 파라미터를 받고 값을 반환하는 함수들이다. 하지만 일반적으로 알고있는 함수들과는 조금 다르게 실행된다. 첫번째로 일반적인 바이너리들은 CPU 에서 직렬로 실행된다. 멀티 스레드 기능을 따로 쓰지 않는한 말이다. 하지만 &lt;em&gt;Shader&lt;/em&gt; 는 기본적으로 병렬로 실행된다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/cpucore_vs_gpucore.jpg&quot; alt=&quot;CPU core vs GPU core&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CPU 와 GPU 의 차이를 간단하게 보여주는 그림이다. 다만 위 그림이 전부는 아니니 간단하게 알고 넘어가도록 하자. 우리가 주목해야 할 것은 바로 &lt;em&gt;core&lt;/em&gt; 갯수의 차이다. 요즘의 CPU 는 &lt;em&gt;core&lt;/em&gt; 의 갯수가 많지 않다. 최근에 나온 &lt;a href=&quot;https://ark.intel.com/ko/products/126684/Intel-Core-i7-8700K-Processor-12M-Cache-up-to-4_70-GHz&quot;&gt;i7-8700k&lt;/a&gt; 를 보면 코어의 갯수가 6개 인것을 확인할 수 있다. 다만 OS 스케줄링이 있어서 실질적으로 실행되는 것은 &lt;em&gt;core&lt;/em&gt; 의 갯수에 엄격하게 제한되지는 않는다. 중요한 것은 개인용 PC 에 들어가는 CPU 는 아직은 &lt;em&gt;core&lt;/em&gt; 의 갯수가 10개를 넘어가지 않는다는 것이다. 반면에 실제 GPU 의 코어의 갯수를 꽤나 많다. 그림에서는 &lt;em&gt;hundreds of cores&lt;/em&gt;, 몇백개의 &lt;em&gt;core&lt;/em&gt; 라고 하지만 요즘 개인용 PC 에 들어가는 GPU 코어는 몇천개나(&lt;a href=&quot;https://www.geforce.co.uk/hardware/desktop-gpus/geforce-gtx-1080/specifications&quot;&gt;gtx1080&lt;/a&gt;) 된다. GPU 의 코어가 많은 이유는 간단하다. CPU 에서 돌아가는 프로그램에 비해 간단한 프로그램 바이너리(쉐이더 혹은 GPGPU 프로그램)를 동시에 실행하는게 최근의 GPU 가 쓰이는 목적이기 때문이다.&lt;/p&gt;

&lt;p&gt;일반적으로 CPU 에서 코딩하는 프로그램과 다르게 GPU 에서 실행되는 프로그램들은 이러한 병렬적인 실행 환경 때문에 특수한 사항들과 제약사항들이 존재한다. 퍼포먼스를 염두하고 프로그램을 코딩하다 보면 처음 경험하는 프로그래머는 조금 당황스러울 수도 있다.&lt;/p&gt;

&lt;h3&gt;쉐이더 파이프라인&lt;/h3&gt;

&lt;p&gt;GPU 의 여태까지의 주요한 역할은 기하학적(geometry) 성격을 띄고있는 데이터들을(mesh, vertex …) 이차원 이미지로 계산하여 보여주는 일이였다. 그렇게 3D 에셋 저작툴이나(3dsmax, maya, …) 게임에서 GPU 를 활용해 보다 많은 것들을 표현할 수 있게 해주었다. 우리가 이번에 살펴볼 것은 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 의 쉐이더가 실행되는 단계다. 이 단계는 위에서 언급한 기하학적 성격을 띄고 있는 데이터를 이차원 이미지로 계산하는 단계를 나타낸 것이다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/sm_5-0_pipeline.jpg&quot; alt=&quot;Shader Model 5_0 pipeline&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 그림에는 여러가지 항목들이 있다. &lt;em&gt;Programmable Shader&lt;/em&gt; 를 제외하면 전부 고정된 기능을 가진 단계로써 프로그래머가 완전히 제어를 할 수 없는 단계다. 우리가 살펴볼 것은 이름 끝에 &lt;em&gt;Shader&lt;/em&gt; 가 붙은 것들이다. 차례대로 &lt;em&gt;Vertex Shader&lt;/em&gt;, &lt;em&gt;Hull Shader&lt;/em&gt;, &lt;em&gt;Domain Shader&lt;/em&gt;, &lt;em&gt;Geometry Shader&lt;/em&gt;, &lt;em&gt;Pixel Shader&lt;/em&gt; 가 있다. 위의 단계들은 두가지로 분류할 수 있다. &lt;em&gt;Geometry Stage&lt;/em&gt; 와 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 다. &lt;em&gt;Geometry Stage&lt;/em&gt; 는 일반적인 3D 상의 위치나 벡터를 가지고 있는 데이터를 처리하는 단계를 말한다. 위 그림에서는 &lt;em&gt;Rasterizer&lt;/em&gt; 전 까지의 단계를 뜻한다. &lt;em&gt;Rasterizer Stage&lt;/em&gt; 는 2D 이미지로 처리된 상태에서 데이터를 처리하는 단계를 말한다. &lt;em&gt;Rasterizer&lt;/em&gt; 단계 부터 오른쪽 끝까지의 단계다. 각 단계에 대한 자세한 설명은 해당 글에서 하겠다.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인을 알고 있어야 여러 이론들을 구현할 수 있다. 쉐이더를 다루려면 이 쉐이더 파이프라인을 아는 것은 필수라고 할 수 있겠다.&lt;/p&gt;

&lt;h3&gt;각종 버퍼들의 활용&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Shader Model 4.0&lt;/em&gt; 과 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 를 통해 여러 버퍼들을 사용하여 &lt;em&gt;Shader&lt;/em&gt; 안에서 돌고도는 &lt;em&gt;varying data&lt;/em&gt; (쉐이더들의 파라미터들) 와 함께 응용을 할 수 있게 되었다. 이는 함수 한개씩을 파라미터와 반환값만 바꾸면서 코딩하는 환경에서 참조할 전역 변수를 만들어주어 훨씬 더 많은 데이터들을 접근할 수 있게 해준것이다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">쉐이더 프로그래밍 환경 Programmable Shader 들을 정리하기 위해 각 쉐이더별로 한개씩 글을 써보기로 했다. 그 전에 미리 알아야될 것들에 대해 알아보려고 한다. 각각의 Shader 들은 코더의 입장에서 바라보았을 때는 단지 몇개의 파라미터를 받고 값을 반환하는 함수들이다. 하지만 일반적으로 알고있는 함수들과는 조금 다르게 실행된다. 첫번째로 일반적인 바이너리들은 CPU 에서 직렬로 실행된다. 멀티 스레드 기능을 따로 쓰지 않는한 말이다. 하지만 Shader 는 기본적으로 병렬로 실행된다. 아래 그림을 보자. CPU 와 GPU 의 차이를 간단하게 보여주는 그림이다. 다만 위 그림이 전부는 아니니 간단하게 알고 넘어가도록 하자. 우리가 주목해야 할 것은 바로 core 갯수의 차이다. 요즘의 CPU 는 core 의 갯수가 많지 않다. 최근에 나온 i7-8700k 를 보면 코어의 갯수가 6개 인것을 확인할 수 있다. 다만 OS 스케줄링이 있어서 실질적으로 실행되는 것은 core 의 갯수에 엄격하게 제한되지는 않는다. 중요한 것은 개인용 PC 에 들어가는 CPU 는 아직은 core 의 갯수가 10개를 넘어가지 않는다는 것이다. 반면에 실제 GPU 의 코어의 갯수를 꽤나 많다. 그림에서는 hundreds of cores, 몇백개의 core 라고 하지만 요즘 개인용 PC 에 들어가는 GPU 코어는 몇천개나(gtx1080) 된다. GPU 의 코어가 많은 이유는 간단하다. CPU 에서 돌아가는 프로그램에 비해 간단한 프로그램 바이너리(쉐이더 혹은 GPGPU 프로그램)를 동시에 실행하는게 최근의 GPU 가 쓰이는 목적이기 때문이다. 일반적으로 CPU 에서 코딩하는 프로그램과 다르게 GPU 에서 실행되는 프로그램들은 이러한 병렬적인 실행 환경 때문에 특수한 사항들과 제약사항들이 존재한다. 퍼포먼스를 염두하고 프로그램을 코딩하다 보면 처음 경험하는 프로그래머는 조금 당황스러울 수도 있다. 쉐이더 파이프라인 GPU 의 여태까지의 주요한 역할은 기하학적(geometry) 성격을 띄고있는 데이터들을(mesh, vertex …) 이차원 이미지로 계산하여 보여주는 일이였다. 그렇게 3D 에셋 저작툴이나(3dsmax, maya, …) 게임에서 GPU 를 활용해 보다 많은 것들을 표현할 수 있게 해주었다. 우리가 이번에 살펴볼 것은 Shader Model 5.0 의 쉐이더가 실행되는 단계다. 이 단계는 위에서 언급한 기하학적 성격을 띄고 있는 데이터를 이차원 이미지로 계산하는 단계를 나타낸 것이다. 아래 그림을 보자. 이 그림에는 여러가지 항목들이 있다. Programmable Shader 를 제외하면 전부 고정된 기능을 가진 단계로써 프로그래머가 완전히 제어를 할 수 없는 단계다. 우리가 살펴볼 것은 이름 끝에 Shader 가 붙은 것들이다. 차례대로 Vertex Shader, Hull Shader, Domain Shader, Geometry Shader, Pixel Shader 가 있다. 위의 단계들은 두가지로 분류할 수 있다. Geometry Stage 와 Rasterizer Stage 다. Geometry Stage 는 일반적인 3D 상의 위치나 벡터를 가지고 있는 데이터를 처리하는 단계를 말한다. 위 그림에서는 Rasterizer 전 까지의 단계를 뜻한다. Rasterizer Stage 는 2D 이미지로 처리된 상태에서 데이터를 처리하는 단계를 말한다. Rasterizer 단계 부터 오른쪽 끝까지의 단계다. 각 단계에 대한 자세한 설명은 해당 글에서 하겠다. 쉐이더 파이프라인을 알고 있어야 여러 이론들을 구현할 수 있다. 쉐이더를 다루려면 이 쉐이더 파이프라인을 아는 것은 필수라고 할 수 있겠다. 각종 버퍼들의 활용 Shader Model 4.0 과 Shader Model 5.0 를 통해 여러 버퍼들을 사용하여 Shader 안에서 돌고도는 varying data (쉐이더들의 파라미터들) 와 함께 응용을 할 수 있게 되었다. 이는 함수 한개씩을 파라미터와 반환값만 바꾸면서 코딩하는 환경에서 참조할 전역 변수를 만들어주어 훨씬 더 많은 데이터들을 접근할 수 있게 해준것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Loop Attributes For Dynamic Branching</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching/" rel="alternate" type="text/html" title="Loop Attributes For Dynamic Branching" />
      <published>2017-10-26T00:00:00+00:00</published>
      <updated>2017-10-26T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching/">&lt;p&gt;&lt;em&gt;Programmable Shader&lt;/em&gt; 를 작성할 때에는 한가지 유의해야 할 점이 있다. 이는 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이라는 개념이다. &lt;em&gt;Dynamic Branching&lt;/em&gt; 은 조건 분기문이 &lt;em&gt;Programmable Shader&lt;/em&gt; 에서 사용될 때 나타나는 현상을 말한다. &lt;em&gt;Programmable Shader&lt;/em&gt; 는 직렬이 아닌 병렬로 실행되기 때문에 나타나는 특성이다. 반복문에서도 조건 분기를 사용한다. 간단한 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;int i = 0;
while(i &amp;lt; 5)
{
  i++;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드는 프로그래밍을 입문할때 볼 수 있는 코드다. 중요한 것은 &lt;em&gt;while&lt;/em&gt; 단어가 있는 줄에 있는 조건 식이다. &lt;em&gt;(i &amp;lt; 5)&lt;/em&gt; 조건식 때문에 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이 발생한다. 이 &lt;em&gt;Dynamic Branching&lt;/em&gt; 을 명시적으로 없에거나 만들기 위해 &lt;em&gt;hlsl&lt;/em&gt; 에서 &lt;em&gt;attribute&lt;/em&gt; 를 지원한다. 아래를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;[Attribute] for ( Initializer; Conditional; Iterator )
{
  Statement Block;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 구문은 &lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509602.aspx&quot;&gt;MSDN : for Statement&lt;/a&gt; 에서 가져왔다. 일반적으로 프로그래머이 정말 많이본 &lt;em&gt;for&lt;/em&gt; 반복문이다. 우리가 봐야할 것은 &lt;em&gt;for&lt;/em&gt; 구문 왼쪽의 &lt;em&gt;[Attribute]&lt;/em&gt; 라는 구문이다. 이 부분에는 총 4가지의 옵션을 넣을 수 있는데, 이 글에서 언급할 &lt;em&gt;[Attribute]&lt;/em&gt; 는 두가지다. &lt;em&gt;unroll&lt;/em&gt; 과 &lt;em&gt;loop&lt;/em&gt; 이 두가지이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;hlsl&lt;/em&gt; 로 정상적인 반복문 실행을 하게되면, 매번 반복을 할때 마다 조건식을 검사하게 되고, 해당 반복문의 범위를 마음대로 조정하여 코딩을 할 수 있다. 다만 조건식의 범위가 매번 달라진다면 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이 발생하게 된다. 그리고 반복문이 매번 &lt;em&gt;Programmable Shader&lt;/em&gt; 가 실행될 때 상수로 반복을 한다면 쉐이더 컴파일러는 최적화를 위해 특정한 행동을 하게 된다. 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;for(int i = 0; i &amp;lt; 5; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 코드는 루프를 다섯번 실행시키는 코드다. 따로 안에 인덱스 &lt;em&gt;i&lt;/em&gt; 를 건드리지 않는다면 쉐이더 컴파일러는 컴파일 시점에 최적화를 한다. 이를 &lt;em&gt;unroll&lt;/em&gt; 이라고 부를 수 있는데, 실행할 반복문을 반복문으로 해석하는게 아닌 5번 연속해서 같은 행동을 하게 하는 것이다. 조건 자체도 없어지고 그저 인덱스를 풀어쓰게 된다. 이는 상수(constant)로 반복문을 제어하면 쉐이더 컴파일러가 알아서 해주기 때문에 신경써주지 않아도 된다. 다만 &lt;em&gt;unroll&lt;/em&gt; 이라는 키워드를 써서 바뀔 때는 변수를 사용해 반복문을 제어할 때다. 변수를 사용하면 컴파일 시점에서는 추측할 수 없기 때문에 암시적으로 &lt;em&gt;unroll&lt;/em&gt; 을 할 수 없다. 이 때 &lt;em&gt;unroll&lt;/em&gt; 키워드를 사용하여 제어할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;int count = ...;
[unroll(5)]
for(int i = 0; i &amp;lt; count; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;또한 암시적으로 &lt;em&gt;unroll&lt;/em&gt; 된 반복문을 명시적으로 반복문으로 실행되게 할 수도 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;[loop]
for(int i = 0; i &amp;lt; 5; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509602.aspx&quot;&gt;MSDN : for Statement&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/649408-can-someone-explain-loop-and-unroll-to-me/&quot;&gt;GameDev : Can someone explain [loop] and [unroll] to me?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/543541-hlsl-warning-gradient-based-operations-must-be-moved-out-of-flow-control-to-prevent/&quot;&gt;GameDev : HLSL warning: Gradient-based operations must be moved out of flow control to prevent
 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">Programmable Shader 를 작성할 때에는 한가지 유의해야 할 점이 있다. 이는 Dynamic Branching 이라는 개념이다. Dynamic Branching 은 조건 분기문이 Programmable Shader 에서 사용될 때 나타나는 현상을 말한다. Programmable Shader 는 직렬이 아닌 병렬로 실행되기 때문에 나타나는 특성이다. 반복문에서도 조건 분기를 사용한다. 간단한 아래 코드를 보자. int i = 0; while(i &amp;lt; 5) { i++; } 위 코드는 프로그래밍을 입문할때 볼 수 있는 코드다. 중요한 것은 while 단어가 있는 줄에 있는 조건 식이다. (i &amp;lt; 5) 조건식 때문에 Dynamic Branching 이 발생한다. 이 Dynamic Branching 을 명시적으로 없에거나 만들기 위해 hlsl 에서 attribute 를 지원한다. 아래를 보자. [Attribute] for ( Initializer; Conditional; Iterator ) { Statement Block; } 해당 구문은 MSDN : for Statement 에서 가져왔다. 일반적으로 프로그래머이 정말 많이본 for 반복문이다. 우리가 봐야할 것은 for 구문 왼쪽의 [Attribute] 라는 구문이다. 이 부분에는 총 4가지의 옵션을 넣을 수 있는데, 이 글에서 언급할 [Attribute] 는 두가지다. unroll 과 loop 이 두가지이다. hlsl 로 정상적인 반복문 실행을 하게되면, 매번 반복을 할때 마다 조건식을 검사하게 되고, 해당 반복문의 범위를 마음대로 조정하여 코딩을 할 수 있다. 다만 조건식의 범위가 매번 달라진다면 Dynamic Branching 이 발생하게 된다. 그리고 반복문이 매번 Programmable Shader 가 실행될 때 상수로 반복을 한다면 쉐이더 컴파일러는 최적화를 위해 특정한 행동을 하게 된다. 아래 코드를 보자. for(int i = 0; i &amp;lt; 5; i++) { } 위의 코드는 루프를 다섯번 실행시키는 코드다. 따로 안에 인덱스 i 를 건드리지 않는다면 쉐이더 컴파일러는 컴파일 시점에 최적화를 한다. 이를 unroll 이라고 부를 수 있는데, 실행할 반복문을 반복문으로 해석하는게 아닌 5번 연속해서 같은 행동을 하게 하는 것이다. 조건 자체도 없어지고 그저 인덱스를 풀어쓰게 된다. 이는 상수(constant)로 반복문을 제어하면 쉐이더 컴파일러가 알아서 해주기 때문에 신경써주지 않아도 된다. 다만 unroll 이라는 키워드를 써서 바뀔 때는 변수를 사용해 반복문을 제어할 때다. 변수를 사용하면 컴파일 시점에서는 추측할 수 없기 때문에 암시적으로 unroll 을 할 수 없다. 이 때 unroll 키워드를 사용하여 제어할 수 있다. int count = ...; [unroll(5)] for(int i = 0; i &amp;lt; count; i++) { } 또한 암시적으로 unroll 된 반복문을 명시적으로 반복문으로 실행되게 할 수도 있다. [loop] for(int i = 0; i &amp;lt; 5; i++) { } 참조 자료 MSDN : for Statement GameDev : Can someone explain [loop] and [unroll] to me? GameDev : HLSL warning: Gradient-based operations must be moved out of flow control to prevent</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Introduce Of Wave Programming</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming/" rel="alternate" type="text/html" title="Introduce Of Wave Programming" />
      <published>2017-10-16T00:00:00+00:00</published>
      <updated>2017-10-16T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming/">&lt;p&gt;Windows 10 Fall Creators Update 가 나오면서 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 이 추가되었다. 여태까지의 &lt;em&gt;Shader Model&lt;/em&gt; 업데이트는 대부분 DirectX 버젼이 올라가면서 같이 업데이트 된 경우가 많으나 이번의 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 따로 업데이트 되었다. &lt;em&gt;Shader Model 6.0&lt;/em&gt; 에서의 가장 큰 기능 추가는 당연히 &lt;em&gt;Wave Intrisic&lt;/em&gt; 이라고 할 수 있겠다. &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 제외하면 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 바뀐게 없다.&lt;/p&gt;

&lt;p&gt;여태까지의 HLSL 을 사용한 쉐이더 작성은 거의 대부분 &lt;em&gt;Single-Threading&lt;/em&gt; 으로 작동되었다. &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 ddx, ddy instrisic 을 사용하여 Gradient 데이터를 가져올 수 있긴 했지만 이 것을 제외하면 거의 없었다고 보면 되겠다. 그래서 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 에서는 다른 &lt;em&gt;Thread&lt;/em&gt; 와 인터렉션 할 수 있는 &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 지원한다. &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt; 을 살펴보면 알겠지만 단순한 API 들을 제공하는 것이다. 하지만 내부에서 동작하는 것은 조금 다르다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt; 에서 나온 용어에 대한 설명이 필요하다. &lt;em&gt;Lane&lt;/em&gt; 은 일반적으로 생각되는 한개의 &lt;em&gt;Thread&lt;/em&gt; 가 실행되는 것이다. &lt;em&gt;Shader Model 6.0&lt;/em&gt; 이전의 쉐이더 모델은 단순히 &lt;em&gt;Lane&lt;/em&gt; 개념 안에서 코딩을 해야 했다. &lt;em&gt;Lane&lt;/em&gt; 은 상황에 따라 실행되고 있는 상태일 수도 있고, 쉬고 있는 상태일 수도 있다. &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 사용해 이를 각각의 &lt;em&gt;Lane&lt;/em&gt; 에서도 알 수 있다. &lt;em&gt;Wave&lt;/em&gt; 는 GPU 에서 실행되는 &lt;em&gt;Lane&lt;/em&gt; 의 묶음을 뜻한다. 즉 여러개의 &lt;em&gt;Lane&lt;/em&gt; 이라고 할 수 있겠다. 같은 &lt;em&gt;Wave&lt;/em&gt; 안의 &lt;em&gt;Lane&lt;/em&gt; 들은 &lt;em&gt;Barrier&lt;/em&gt; 라는게 없다. 필자가 알고 있는 &lt;em&gt;Barrier&lt;/em&gt; 는 &lt;em&gt;Memory Barrier&lt;/em&gt; 인데, 이는 &lt;em&gt;Thread&lt;/em&gt;(&lt;em&gt;Lane&lt;/em&gt;)끼리의 같은 메모리에 접근하는 것에 대한 동기화를 위해 있는 개념이다. 동기화를 위한 &lt;em&gt;Barrier&lt;/em&gt; 는 속도를 늦출 수 밖에 없다. 하지만 &lt;em&gt;Wave&lt;/em&gt; 로 묶여진 &lt;em&gt;Lane&lt;/em&gt; 들은 서로 &lt;em&gt;Barrier&lt;/em&gt; 가 명시적으로 존재하지 않기 때문에 &lt;em&gt;Wave&lt;/em&gt; 별로 빠른 메모리 접근이 가능하다는 것이다. &lt;em&gt;Wave&lt;/em&gt; 는 &lt;em&gt;Warp&lt;/em&gt;, &lt;em&gt;WaveFront&lt;/em&gt; 라고도 불리울 수 있다고 한다.&lt;/p&gt;

&lt;p&gt;그리고 이 API 들을 통해 약간의 드라이버 내부를 엿볼 수 있다. &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 &lt;em&gt;Render Lane&lt;/em&gt; 과 &lt;em&gt;Helper Lane&lt;/em&gt; 이 구분되어져 있는데, 이는 ddx,ddy 를 통해 픽셀의 Gradient 를 계산하는 것에 대한 보다 디테일한 개념을 생각할 수 있게 해준다. GPU 드라이버 시스템에서는 픽셀을 처리하기 위해 단순히 한개의 픽셀만 처리하는게 아닌 2x2 의 픽셀을 엮어 계산한다. 이를 MSDN 문서에서는 2x2 의 픽셀 뭉치를 &lt;em&gt;Quad&lt;/em&gt; 라고 명칭한다. &lt;em&gt;Quad&lt;/em&gt; 는 두가지 종류에 스레드가 실행된다. 하나는 우리가 잘 알고 있는 &lt;em&gt;Pixel Shader&lt;/em&gt; 를 실행하는 &lt;em&gt;Render Lane&lt;/em&gt; 이다. &lt;em&gt;Render Lane&lt;/em&gt; 은 화면에 보여주는 색을 결과로 내놓게 된다. 그리고 나머지 한가지는 &lt;em&gt;Helper Lane&lt;/em&gt; 인데, 이는 Pixel 별로 Gradient 를 계산하기 위해 실행되는 &lt;em&gt;Lane&lt;/em&gt; 으로써 아무런 결과를 내놓지 않고 단순히 계산을 위한 &lt;em&gt;Lane&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 DirectX12 과 Vulkan 에서 지원한다. DirectX 에서는 &lt;em&gt;Pixel Shader&lt;/em&gt; 와 &lt;em&gt;Computer Shader&lt;/em&gt; 에서 지원한다. Vulkan 에서는 모든 쉐이더 단계에서 지원한다. 그래픽 카드 벤더별로 조금씩 다른게 있으니 &lt;a href=&quot;http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2017/07/GDC2017-Wave-Programming-D3D12-Vulkan.pdf&quot;&gt;GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan &lt;/a&gt; 에서 참고 바란다.&lt;/p&gt;

&lt;p&gt;이 API 는 여러 쓰레드들 끼리 쉽게 협력하여 보다 효율적인 쉐이더 병렬 프로그래밍을 가능하게 해줄듯하다. 다만 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 에서 소개된 &lt;em&gt;ComputeShader&lt;/em&gt; 만큼의 임팩트는 없다. 패러다임의 아주 큰 변화는 없다는 뜻이다. DirectX12 가 지향하는 드라이버 시스템에서의 부담을 줄이는 것과 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 서로 방향이 비슷하다고 생각된다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.gdcvault.com/play/1024732/Advanced-Graphics-Tech-D3D12-and&quot;&gt;GDCVault(GDC 2017) : D3D12 &amp;amp; Vulkan Done Right&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2017/07/GDC2017-Wave-Programming-D3D12-Vulkan.pdf&quot;&gt;GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://optocrypto.com/2017/09/20/microsofts-program-shader-model-6-0-completed/&quot;&gt;Optocrypto : Microsoft’s first example program for shader model 6.0 was completed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      

      

      
        <summary type="html">Windows 10 Fall Creators Update 가 나오면서 Shader Model 6.0 이 추가되었다. 여태까지의 Shader Model 업데이트는 대부분 DirectX 버젼이 올라가면서 같이 업데이트 된 경우가 많으나 이번의 Shader Model 6.0 은 따로 업데이트 되었다. Shader Model 6.0 에서의 가장 큰 기능 추가는 당연히 Wave Intrisic 이라고 할 수 있겠다. Wave Intrisic 을 제외하면 Shader Model 6.0 은 바뀐게 없다. 여태까지의 HLSL 을 사용한 쉐이더 작성은 거의 대부분 Single-Threading 으로 작동되었다. Pixel Shader 에서 ddx, ddy instrisic 을 사용하여 Gradient 데이터를 가져올 수 있긴 했지만 이 것을 제외하면 거의 없었다고 보면 되겠다. 그래서 Shader Model 6.0 에서는 다른 Thread 와 인터렉션 할 수 있는 Wave Intrisic 을 지원한다. MSDN : HLSL Shader Model 6.0 을 살펴보면 알겠지만 단순한 API 들을 제공하는 것이다. 하지만 내부에서 동작하는 것은 조금 다르다. MSDN : HLSL Shader Model 6.0 에서 나온 용어에 대한 설명이 필요하다. Lane 은 일반적으로 생각되는 한개의 Thread 가 실행되는 것이다. Shader Model 6.0 이전의 쉐이더 모델은 단순히 Lane 개념 안에서 코딩을 해야 했다. Lane 은 상황에 따라 실행되고 있는 상태일 수도 있고, 쉬고 있는 상태일 수도 있다. Wave Intrisic 을 사용해 이를 각각의 Lane 에서도 알 수 있다. Wave 는 GPU 에서 실행되는 Lane 의 묶음을 뜻한다. 즉 여러개의 Lane 이라고 할 수 있겠다. 같은 Wave 안의 Lane 들은 Barrier 라는게 없다. 필자가 알고 있는 Barrier 는 Memory Barrier 인데, 이는 Thread(Lane)끼리의 같은 메모리에 접근하는 것에 대한 동기화를 위해 있는 개념이다. 동기화를 위한 Barrier 는 속도를 늦출 수 밖에 없다. 하지만 Wave 로 묶여진 Lane 들은 서로 Barrier 가 명시적으로 존재하지 않기 때문에 Wave 별로 빠른 메모리 접근이 가능하다는 것이다. Wave 는 Warp, WaveFront 라고도 불리울 수 있다고 한다. 그리고 이 API 들을 통해 약간의 드라이버 내부를 엿볼 수 있다. Pixel Shader 에서 Render Lane 과 Helper Lane 이 구분되어져 있는데, 이는 ddx,ddy 를 통해 픽셀의 Gradient 를 계산하는 것에 대한 보다 디테일한 개념을 생각할 수 있게 해준다. GPU 드라이버 시스템에서는 픽셀을 처리하기 위해 단순히 한개의 픽셀만 처리하는게 아닌 2x2 의 픽셀을 엮어 계산한다. 이를 MSDN 문서에서는 2x2 의 픽셀 뭉치를 Quad 라고 명칭한다. Quad 는 두가지 종류에 스레드가 실행된다. 하나는 우리가 잘 알고 있는 Pixel Shader 를 실행하는 Render Lane 이다. Render Lane 은 화면에 보여주는 색을 결과로 내놓게 된다. 그리고 나머지 한가지는 Helper Lane 인데, 이는 Pixel 별로 Gradient 를 계산하기 위해 실행되는 Lane 으로써 아무런 결과를 내놓지 않고 단순히 계산을 위한 Lane 이다. Shader Model 6.0 은 DirectX12 과 Vulkan 에서 지원한다. DirectX 에서는 Pixel Shader 와 Computer Shader 에서 지원한다. Vulkan 에서는 모든 쉐이더 단계에서 지원한다. 그래픽 카드 벤더별로 조금씩 다른게 있으니 GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan 에서 참고 바란다. 이 API 는 여러 쓰레드들 끼리 쉽게 협력하여 보다 효율적인 쉐이더 병렬 프로그래밍을 가능하게 해줄듯하다. 다만 Shader Model 5.0 에서 소개된 ComputeShader 만큼의 임팩트는 없다. 패러다임의 아주 큰 변화는 없다는 뜻이다. DirectX12 가 지향하는 드라이버 시스템에서의 부담을 줄이는 것과 Shader Model 6.0 은 서로 방향이 비슷하다고 생각된다. 참조 자료 GDCVault(GDC 2017) : D3D12 &amp;amp; Vulkan Done Right GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan MSDN : HLSL Shader Model 6.0 Optocrypto : Microsoft’s first example program for shader model 6.0 was completed</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Rendering To Cubemap</title>
      
      <link href="https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap/" rel="alternate" type="text/html" title="Using Rendering To Cubemap" />
      <published>2017-09-29T00:00:00+00:00</published>
      <updated>2017-09-29T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap/">&lt;p&gt;&lt;a href=&quot;/2017/09/29/using-relplacement-shader/&quot;&gt;using replacement shader&lt;/a&gt; 에서 &lt;em&gt;Camera.RenderWithShader&lt;/em&gt; 와 같은 렌더링을 코드에서 직접해주면서 기능을 커스터마이징 할 수 있는 것을 살펴보았는데, 이 게시물에서는 비슷한 메서드인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 여러 렌더링 커스터마이징 기능을 제공하는데, 이 게시물에서는 그 중 하나인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 에 대해서 알아볼 것이다. 일반적으로 &lt;em&gt;Cubemap&lt;/em&gt; 은 SkyBox 나 주변의 Irradiance 를 나타낼 때 쓴다. 다만 이를 직접 구현할 때의 문제점은 각 모서리별로 &lt;em&gt;Aliasing&lt;/em&gt; 이 일어나는 경우다. 매우 매끄러운 표면의 Specular 에서 &lt;em&gt;Aliasing&lt;/em&gt; 이 나타난 Irradiance 를 표현하면 굉장히 티가 많이 나기 때문에 이는 굉장히 신경써야할 문제다.&lt;/p&gt;

&lt;p&gt;그래서 Unity 에서는 &lt;em&gt;Cubemap&lt;/em&gt; 에 렌더링을 하는 기능인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 을 지원한다. 이를 통해 할 수 있는 것은 실시간으로 &lt;em&gt;Cubemap&lt;/em&gt; 에 렌더링된 결과를 저장해 &lt;em&gt;Irradiance&lt;/em&gt; 의 소스로 쓰거나, 실시간으로 바뀌는 &lt;em&gt;Skybox&lt;/em&gt; 렌더링을 할 수도 있다. 사용 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;RenderTexture cubmapRT = ...;
camera.RenderToCubemap(cubemapRT, 63);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 의 두번째로 들어가는 인자는 어떤 면을 그릴건지에 대한 비트마스크다. &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 를 쓸때 주의할 점은 일부 하드웨어에서는 동작하지 않는 기능이라고 한다. 다만 특정한 하드웨어를 기술해 놓지않아서 추측하기는 어렵다. 단순히 추측할 수 있는 것은 MRT 를 지원하지 않거나 아니면 다른 &lt;em&gt;ComputeShader&lt;/em&gt; 같은 기능을 사용해 일부 하드웨어에서 안된다고 하는 정도 밖에 없다.&lt;/p&gt;

&lt;p&gt;위 예제에서는 RenderTexture 를 사용하였는데, 저렇게 코드에서 처리할 수도 있지만 CustomRenderTexture 를 통해 간편하게 처리할 수도 있다. CustomRenderTexture 는 업데이트 주기를 사용자 임의대로 정할 수 있으므로 꽤나 유용하게 쓰일 수 있다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/Camera.RenderToCubemap.html&quot;&gt;Unity Reference : Camera.RenderToCubemap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="render" />
      

      

      
        <summary type="html">using replacement shader 에서 Camera.RenderWithShader 와 같은 렌더링을 코드에서 직접해주면서 기능을 커스터마이징 할 수 있는 것을 살펴보았는데, 이 게시물에서는 비슷한 메서드인 Camera.RenderToCubemap 에 대해서 알아볼 것이다. Unity 에서는 여러 렌더링 커스터마이징 기능을 제공하는데, 이 게시물에서는 그 중 하나인 Camera.RenderToCubemap 에 대해서 알아볼 것이다. 일반적으로 Cubemap 은 SkyBox 나 주변의 Irradiance 를 나타낼 때 쓴다. 다만 이를 직접 구현할 때의 문제점은 각 모서리별로 Aliasing 이 일어나는 경우다. 매우 매끄러운 표면의 Specular 에서 Aliasing 이 나타난 Irradiance 를 표현하면 굉장히 티가 많이 나기 때문에 이는 굉장히 신경써야할 문제다. 그래서 Unity 에서는 Cubemap 에 렌더링을 하는 기능인 Camera.RenderToCubemap 을 지원한다. 이를 통해 할 수 있는 것은 실시간으로 Cubemap 에 렌더링된 결과를 저장해 Irradiance 의 소스로 쓰거나, 실시간으로 바뀌는 Skybox 렌더링을 할 수도 있다. 사용 방법은 아래와 같다. RenderTexture cubmapRT = ...; camera.RenderToCubemap(cubemapRT, 63); Camera.RenderToCubemap 의 두번째로 들어가는 인자는 어떤 면을 그릴건지에 대한 비트마스크다. Camera.RenderToCubemap 를 쓸때 주의할 점은 일부 하드웨어에서는 동작하지 않는 기능이라고 한다. 다만 특정한 하드웨어를 기술해 놓지않아서 추측하기는 어렵다. 단순히 추측할 수 있는 것은 MRT 를 지원하지 않거나 아니면 다른 ComputeShader 같은 기능을 사용해 일부 하드웨어에서 안된다고 하는 정도 밖에 없다. 위 예제에서는 RenderTexture 를 사용하였는데, 저렇게 코드에서 처리할 수도 있지만 CustomRenderTexture 를 통해 간편하게 처리할 수도 있다. CustomRenderTexture 는 업데이트 주기를 사용자 임의대로 정할 수 있으므로 꽤나 유용하게 쓰일 수 있다. 참조 자료 Unity Reference : Camera.RenderToCubemap</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Relplacement Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader/" rel="alternate" type="text/html" title="Using Relplacement Shader" />
      <published>2017-09-29T00:00:00+00:00</published>
      <updated>2017-09-29T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader/">&lt;p&gt;Unity 는 &lt;em&gt;Replacement Shader&lt;/em&gt; 라는 렌더링 기능을 지원한다. 이는 Unity 가 Rendering 기능에서 지원하는 약간 Hack 한 테크닉이며 이 기능을 잘 사용하면 쉐이더를 바꿔치기 해서 재미있는 것들을 할 수 있다. &lt;em&gt;Replacement Shader&lt;/em&gt; 는 렌더링할 MeshRenderer 들이 가지고 있는 &lt;strong&gt;Material&lt;/strong&gt; 의 Shader 를 사용자가 원하는 것으로 바꾸는 기능이다. 이 기능을 통해 그림자 같은 여러 부가적인 처리를 할 수 있다.&lt;/p&gt;

&lt;p&gt;사용하는 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;Shader shader = Shader.Find(&quot;CustomShaderName&quot;);
string replacementTag = &quot;replace&quot;;

// tag is optional. if dont need tag, insert null.
camera.RenderWithShader(shader, replacementTag);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 간단한 예제는 &lt;em&gt;Replacement Shader&lt;/em&gt; 를 사용해 한번 그려주는 예제다. 단순히 &lt;em&gt;Camera.RenderWithShader&lt;/em&gt; 를 사용하기 때문에 직접 값을 컨트롤할 때 사용하기 좋다. &lt;em&gt;Replacement Shader&lt;/em&gt; 를 영구적으로 세팅하여 자동으로 그려주면 아래와 같이 하면된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;Shader shader = Shader.Find(&quot;CustomShaderName&quot;);
string replacementTag = &quot;replace&quot;;

// tag is optional. if dont need tag, insert null.
camera.SetReplacementShader(shader, replacementTag);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;사용 방법은 굉장히 단순하다. 다만 이 &lt;em&gt;Replacement Shader&lt;/em&gt; 기능에서 중요한 것은 쉐이더를 단순히 치환하는 것만 포인트가 아니다. 치환된 쉐이더들은 기존 &lt;strong&gt;Material&lt;/strong&gt; 이 가지고 있던 데이터들과 쉐이더 코드에서 이름만 똑같이 맞추어주면 자동으로 데이터들이 쉐이더로 들어온다. 즉 쉐이더를 갈아치우지 않고도 데이터를 공유할 수 있는 것이다. 이는 Unity 의 렌더링에서 굉장히 강력한 시스템으로 초기에는 이해하기도 힘들고 잔머리가 필요하지만 이를 잘 사용만 한다면 굉장히 유용하게 쓰일 수 있다.&lt;/p&gt;

&lt;p&gt;필자는 Github 에서 OIT 예제를 보면서 처음 보았다. &lt;a href=&quot;https://github.com/candycat1992/OIT_Lab&quot;&gt;Github : OIT_Lab&lt;/a&gt; 에서 OIT 를 처리하는 코드에서 구경할 수 있다. 또한 일본 Unity 지사에서 일하는 유명한 keijiro 의 &lt;a href=&quot;https://github.com/keijiro/Skinner&quot;&gt;Skinner&lt;/a&gt; 에서 위치를 처리하는데 쓰이기도 한다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/SL-ShaderReplacement.html&quot;&gt;Unity Reference : Replaced Shaders 에서의 렌더링&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="render" />
      

      

      
        <summary type="html">Unity 는 Replacement Shader 라는 렌더링 기능을 지원한다. 이는 Unity 가 Rendering 기능에서 지원하는 약간 Hack 한 테크닉이며 이 기능을 잘 사용하면 쉐이더를 바꿔치기 해서 재미있는 것들을 할 수 있다. Replacement Shader 는 렌더링할 MeshRenderer 들이 가지고 있는 Material 의 Shader 를 사용자가 원하는 것으로 바꾸는 기능이다. 이 기능을 통해 그림자 같은 여러 부가적인 처리를 할 수 있다. 사용하는 방법은 아래와 같다. Shader shader = Shader.Find(&quot;CustomShaderName&quot;); string replacementTag = &quot;replace&quot;; // tag is optional. if dont need tag, insert null. camera.RenderWithShader(shader, replacementTag); 위의 간단한 예제는 Replacement Shader 를 사용해 한번 그려주는 예제다. 단순히 Camera.RenderWithShader 를 사용하기 때문에 직접 값을 컨트롤할 때 사용하기 좋다. Replacement Shader 를 영구적으로 세팅하여 자동으로 그려주면 아래와 같이 하면된다. Shader shader = Shader.Find(&quot;CustomShaderName&quot;); string replacementTag = &quot;replace&quot;; // tag is optional. if dont need tag, insert null. camera.SetReplacementShader(shader, replacementTag); 사용 방법은 굉장히 단순하다. 다만 이 Replacement Shader 기능에서 중요한 것은 쉐이더를 단순히 치환하는 것만 포인트가 아니다. 치환된 쉐이더들은 기존 Material 이 가지고 있던 데이터들과 쉐이더 코드에서 이름만 똑같이 맞추어주면 자동으로 데이터들이 쉐이더로 들어온다. 즉 쉐이더를 갈아치우지 않고도 데이터를 공유할 수 있는 것이다. 이는 Unity 의 렌더링에서 굉장히 강력한 시스템으로 초기에는 이해하기도 힘들고 잔머리가 필요하지만 이를 잘 사용만 한다면 굉장히 유용하게 쓰일 수 있다. 필자는 Github 에서 OIT 예제를 보면서 처음 보았다. Github : OIT_Lab 에서 OIT 를 처리하는 코드에서 구경할 수 있다. 또한 일본 Unity 지사에서 일하는 유명한 keijiro 의 Skinner 에서 위치를 처리하는데 쓰이기도 한다. 참조 자료 Unity Reference : Replaced Shaders 에서의 렌더링</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Compute Buffer In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/" rel="alternate" type="text/html" title="Using Compute Buffer In Unity" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/">&lt;p&gt;Unity 에서의 확실한 GPU Instancing 은 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 라는 구현체에서 시작될 것이다. 이 구현체는 &lt;strong&gt;UnityEngine.ComputeBuffer&lt;/strong&gt; 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 와 함께 등장했다. &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 구현해 놓았다. 하지만 이 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 이상이다. PC 플랫폼에서는 당연히 사용 가능하다.&lt;/p&gt;

&lt;p&gt;사용하는 방법 자체는 어렵지 않다. 스크립트에서 &lt;em&gt;size&lt;/em&gt; 와 &lt;em&gt;stride&lt;/em&gt; 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 &lt;strong&gt;System.Array&lt;/strong&gt; 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;int dataLen = ...;  // length of data
int[] dataArray = new int[dataLen];

// record data in dataArray..

ComputeShader computeShader = ...;
ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int));
dataBuffer.SetData(dataArray);

computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(&lt;em&gt;length&lt;/em&gt;)와 각 데이터별 크기(&lt;em&gt;stride&lt;/em&gt;)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(&lt;em&gt;write&lt;/em&gt;) 그리고 마지막으로 데이터가 세팅된 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에 연결해준다. 이러면 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드에서 &lt;em&gt;dataBuffer&lt;/em&gt; 라는 변수명을 가진 변수에 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 가 연결된다. 아래에 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드가 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-HLSL&quot;&gt;StructuredBuffer&amp;lt;int&amp;gt; dataBuffer;

[numthreads(8,8,1)]
void Process (uint3 id : SV_DispatchThreadID)
{
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;맨 처음에 있는 &lt;em&gt;dataBuffer&lt;/em&gt; 에 연결된다. &lt;a href=&quot;{ post_url 2017-07-06-structured-buffer-vs-constant-buffer }&quot;&gt;StructuredBuffer vs ConstantBuffer&lt;/a&gt; 에서본 &lt;em&gt;StructuredBuffer&lt;/em&gt; 타입이 가능하다. 또한 &lt;em&gt;RWStructuredBuffer&lt;/em&gt;, &lt;em&gt;ConsumeStructuredBuffer&lt;/em&gt;, &lt;em&gt;AppendStructuredBuffer&lt;/em&gt; 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/data-process-pipeline.png&quot; alt=&quot;data process&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞의 두가지 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 세팅하고 &lt;strong&gt;ComputeShader&lt;/strong&gt; 를 실행하는 코드는 대충 보았다, 뒷 부분의 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 스키닝의 계산을 &lt;strong&gt;ComputeShader&lt;/strong&gt; 로 넘겨서 계산한다. 또한 메시 데이터 전체를 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/ComputeBuffer.html&quot;&gt;Unity Reference : ComptuteBuffer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="gpuinstancing" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서의 확실한 GPU Instancing 은 ComputeBuffer 라는 구현체에서 시작될 것이다. 이 구현체는 UnityEngine.ComputeBuffer 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. ComputeBuffer 는 ComputeShader 와 함께 등장했다. ComputeShader 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 ComputeBuffer 를 구현해 놓았다. 하지만 이 ComputeBuffer 는 ComputeShader 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 Shader Model 5.0 이상이다. PC 플랫폼에서는 당연히 사용 가능하다. 사용하는 방법 자체는 어렵지 않다. 스크립트에서 size 와 stride 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 System.Array 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다. int dataLen = ...; // length of data int[] dataArray = new int[dataLen]; // record data in dataArray.. ComputeShader computeShader = ...; ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int)); dataBuffer.SetData(dataArray); computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer); 위 코드는 ComputeShader 에서 ComputeBuffer 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 ComputeBuffer 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(length)와 각 데이터별 크기(stride)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(write) 그리고 마지막으로 데이터가 세팅된 ComputeBuffer 를 ComputeShader 에 연결해준다. 이러면 ComputeShader 코드에서 dataBuffer 라는 변수명을 가진 변수에 ComputeBuffer 가 연결된다. 아래에 ComputeShader 코드가 있다. StructuredBuffer&amp;lt;int&amp;gt; dataBuffer; [numthreads(8,8,1)] void Process (uint3 id : SV_DispatchThreadID) { ... } 맨 처음에 있는 dataBuffer 에 연결된다. StructuredBuffer vs ConstantBuffer 에서본 StructuredBuffer 타입이 가능하다. 또한 RWStructuredBuffer, ConsumeStructuredBuffer, AppendStructuredBuffer 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다. 앞의 두가지 ComputeBuffer 를 세팅하고 ComputeShader 를 실행하는 코드는 대충 보았다, 뒷 부분의 ComputeBuffer 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다. Github : CustomSkinningExample 에서 스키닝의 계산을 ComputeShader 로 넘겨서 계산한다. 또한 메시 데이터 전체를 ComputeBuffer 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다. 참조 Unity Reference : ComptuteBuffer</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Darboux Frame</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/darboux-frame/" rel="alternate" type="text/html" title="Darboux Frame" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/darboux-frame</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/darboux-frame/">&lt;p&gt;여러 공간 법선 벡터(&lt;em&gt;tangent space normal&lt;/em&gt;, &lt;em&gt;object space normal&lt;/em&gt;)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. &lt;em&gt;darboux frame&lt;/em&gt; 이라는 놈이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;우선 &lt;em&gt;tangent space normal&lt;/em&gt; 과 &lt;em&gt;object space normal&lt;/em&gt; 에 대해서 설명해야 한다. 그래픽스에서는 빛을 표현하기 위해 노말벡터를 사용한다. 처음에 나온식은 매우 간단하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(빛의 방향 벡터) * (노말 벡터) = (빛이 표현하는 색의 범위(-1~1))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 벡터곱은 내적을 뜻한다. 이 식의 결과값은 반사광을 표현하는데 쓰인다. 일반적으로 말하는 &lt;em&gt;Specular&lt;/em&gt; 를 뜻한다. 하여튼 빛을 표현하는 것은 그래픽스에서는 굉장히 중요한 일이기 때문에 이 노말벡터를 어떻게 관리하는지가 엄청나게 중요하다. 그래서 여러 방법이 있는데 제일 많이 쓰이는건 &lt;em&gt;tangent space normal&lt;/em&gt; 이다. 그런데 &lt;em&gt;object space normal&lt;/em&gt; 은 갑자기 왜 튀어나왔느냐? 이유는 간단하다. 두개가 가장 비교가 많이 되는 방법이기 때문이다. &lt;em&gt;object space normal&lt;/em&gt; 은 굉장히 간단하다. 저장된 메시 데이터의 노말 벡터값이다. 기본 단위가 저장된 한 개체의 메시의 노말이기 때문에 &lt;em&gt;object spoce&lt;/em&gt; 라는 접두사가 붙은 것이다. 그래서 그런지 아래 그림에서 나오는 &lt;em&gt;object spoce normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 굉장히 다양하다. 하지만 옆에 &lt;em&gt;tangent space normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 거의 일정하다. 왜 그럴까? 우선 앞의 &lt;em&gt;object space normal&lt;/em&gt; 은 그냥 오브젝트 기준의 좌표계에서의 정점별 노말값을 저장한 데이터다. 하지만 &lt;em&gt;tangent space normal&lt;/em&gt; 은 모델에서 추출한 &lt;em&gt;tangent&lt;/em&gt; 값을 통해 &lt;em&gt;normal&lt;/em&gt; 값을 구하는 방법이다. &lt;a href=&quot;/2017/07/30/normal-tangent-binormal/&quot;&gt;normal tangent binormal&lt;/a&gt; 에서 설명했었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06b-tangent-space/nm_textures.jpg&quot; alt=&quot;tangent-space vs objcet-space&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그런데 &lt;em&gt;tangent space normal&lt;/em&gt; 에서의 &lt;em&gt;tangent&lt;/em&gt; 가 뜻하는 것은 표면의 접선 값이다. 이렇게 표면을 기준으로 하는 것을 &lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;&lt;em&gt;darboux frame&lt;/em&gt;&lt;/a&gt; 이라고 한다. 프랑스 사람의 이름이라 한글로 읽으면 &lt;em&gt;다르부-프레임&lt;/em&gt; 이다. 위키에서는 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이 표면 기하학에서 적용된 것이라 한다. 그만큼 대부분의 정의들이 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 과 매우 비슷하다. 다른 점은 곡선에서 표면으로 확장시켰다는 점이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ssloy/tinyrenderer/wiki/Lesson-6bis:-tangent-space-normal-mapping&quot;&gt;Github : tinyrenderer Wiki - tangent-space-normal-mapping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;Wikipedia : darvoux frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">여러 공간 법선 벡터(tangent space normal, object space normal)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. darboux frame 이라는 놈이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Normal Tangent Binormal</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/" rel="alternate" type="text/html" title="Normal Tangent Binormal" />
      <published>2017-07-30T00:00:00+00:00</published>
      <updated>2017-07-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/">&lt;p&gt;Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;노말 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;탄젠트 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;바이노말 벡터&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;법선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;접선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;이중법선(또는 종법선)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;하지만 이게 뭔지, 어디서 나온지에 대해서 설명한건 그다지 많이 본적이 없다. 물론 필자는 인터넷에 있는 레퍼런스만 보고 공부해서 그럴 수도 있다. 그래서 간단하게 지식의 뿌리만 살펴보려고 한다.&lt;/p&gt;

&lt;p&gt;이 세가지는 이름도 무시무시한 &lt;em&gt;미분기하학&lt;/em&gt; 에서 소개되는 &lt;em&gt;“프레네-세레 공식”(Frene-seret formula)&lt;/em&gt; 에서 정의된 것들이다. 정식 이름은 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 은 일반적으로 우리가 알고있는 실수 공간의 곡률이 있는 곡선 &lt;em&gt;r(t)&lt;/em&gt; 에서 유도된다. 중간에 있는 &lt;em&gt;t&lt;/em&gt; 는 시간을 나타내며 이는 이동한 거리, 곡선의 호 &lt;em&gt;s&lt;/em&gt; 로 매개화 시킨다고 한다. 그래서 그 곡선 &lt;em&gt;r(t(s))&lt;/em&gt; 를 미분해서 방향을 나타내는 말들이 우리가 평상시에 많이 들어왔던 노말, 탄젠트, 바이노말인 것이다.&lt;/p&gt;

&lt;p&gt;탄젠트는 곡선 공식을 그대로 미분한 값. 우리가 알고있는 일반적인 순간 가속도를 뜻한다. 이게 결국 방향을 나타내기 때문에 한글로는 비슷하게 접선벡터 라고 하는 듯하다. 그리고 현재 방향의 수직을 나타내는 노말은 탄젠트를 미분한 값을 정규화시켜서 표현한다. 필자는 이 값이 수학적으로 어떤 것을 나타내는지 몰라서 직관적으로 수식을보고 법선벡터인지 모르겠다. 마지막으로 바이노말은 탄젠트와 노말을 외적해서 구한다.&lt;/p&gt;

&lt;p&gt;여기까지는 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 을 위한 정의들이다. 사실 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 보다는 앞에서 말한  &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 의 정의가 훨씬 더 많이 알려져 있다. 빛을 나타내기 위한 노말과 탄젠트를 그래픽스 이론에서는 끊임없이 보기 때문이다. &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 에 대한 자세한건 이 글에서는 쓰지 않겠다. 이 글을 쓴 이유는 우리가 흔히 쓰는 용어의 뿌리를 찾기위함이였다. (자세한 설명은 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;을 참조)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas&quot;&gt;Wikipedia : Frene-seret formula&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://gall.dcinside.com/board/view/?id=mathematics&amp;amp;no=134445&quot;&gt;디시인사이드 수학 갤러리&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Optimized Center Of Rotation</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/" rel="alternate" type="text/html" title="Optimized Center Of Rotation" />
      <published>2017-07-22T00:00:00+00:00</published>
      <updated>2017-07-22T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;dual quaternion skinning&lt;/a&gt; 글에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 설명해 보았다. 이전 글에서는 단순히 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 의 단점에 대해서 언급했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dqs_ocor_bent.png&quot; alt=&quot;both bent&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 표현한 그림이고, 오른쪽은 곧 소개할 &lt;em&gt;optimized center of rotation&lt;/em&gt; 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 &lt;em&gt;dual quternion skinning&lt;/em&gt; 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 &lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 은 약간 움푹 들어간 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 &lt;em&gt;Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/em&gt; 이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;이 방식은 간단한 아이디어로 접근하면서도 기존의 &lt;em&gt;Weight Blending&lt;/em&gt; 데이터와 호환되며, 런타임에서도 꽤나 쓸만한 방식이다. 또한 처리하는 데이터도 &lt;em&gt;linear bleding skinning&lt;/em&gt; 과 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 비해서도 조금 늘었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 의 기본적인 아이디어는 기존의 방식은 회전 축의 위치가 뼈의 가중치로 결정되어 문제가 생기는 것을 알아채서 각 정점별로 다른 회전의 위치(&lt;em&gt;center of rotation&lt;/em&gt;)를 정해 주는 것이다. 앞에 붙은 &lt;em&gt;optimized&lt;/em&gt; 가 내포한 의미도 있다. 사실 모든 정점별로 &lt;em&gt;center of rotation&lt;/em&gt; 을 정해주면 굉장히 번거롭다. 또한 이 논문에서 소개하는 계산방식은 실시간으로 계산하기에는 너무 느리다. 그래서 이 논문에서는 각 정점별로 기본 포즈(보통 T 포즈를 뜻함.)를 기준으로 &lt;em&gt;center of rotatoin&lt;/em&gt; 을 미리 데이터를 계산해서 실시간으로는 데이터를 참조해서 &lt;em&gt;skinning&lt;/em&gt; 을 한다.&lt;/p&gt;

&lt;p&gt;그런데 이 스키닝 방식을 구현하려면 먼저 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산해주는 코드를 직접 짜야한다. 아직은 3D 에디팅 툴에서 지원을 하지 않기 때문이다. 게임 엔진들 또한 마찬가지다. 또한 일반적인 싱글 스레드 프로그램으로 짜기에는 너무 데이터가 많아서 여러 스레드를 이용하는 멀티 스레딩이나 GPGPU 기술을 사용해서 구현해야 한다. 필자는 구현의 편의성을 위해 멀티 스레딩을 사용했지만 조금 느렸다. 꽤나 괜찮은 GPU 를 가지고 있으면 GPGPU 를 사용하는것이 훨씬 빠를 것이다.&lt;/p&gt;

&lt;p&gt;자세한 방법을 알고 싶으면 논문을 참고하라.(&lt;a href=&quot;https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20160705174939/Real-time-Skeletal-Skinning-with-Optimized-Centers-of-Rotation-Paper.pdf&quot;&gt;논문 링크&lt;/a&gt;) 논문에서 나오는 첫번째로 소개되는 정점과 정점간에 &lt;em&gt;similarity&lt;/em&gt; 를 계산하는 식과 &lt;em&gt;center of rotation&lt;/em&gt; 위치를 계산하는 네번째 식, 그 아래에 있는 Intergration 항목을 참조하면 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 코드를 짤 수 있다. &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 방식의 아이디어는 꽤나 간단하다. &lt;em&gt;bone weight&lt;/em&gt; 들의 연관성(&lt;em&gt;similarity&lt;/em&gt;) 를 계산해 이 숫자를 각 정점간의 가중치로 설정한다. 이 연관성(&lt;em&gt;similarity&lt;/em&gt;)를 계산하기 위해서는 최소 두개의 같은 뼈의 가중치를 가지고 있어야 한다. 만약 아무것도 연관성이 없다면 &lt;em&gt;linear blending skinning&lt;/em&gt; 으로 계산하게 하면 된다. 그리고 각각 폴리곤의 세 정점의 평균 &lt;em&gt;similarity&lt;/em&gt; 와 폴리곤의 세 정점의 평균 위치, 그리고 삼각형의 넓이를 계산해서 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산한다.&lt;/p&gt;

&lt;p&gt;다만 논문의 처음에서는 모든 정점을 기준으로 전부 &lt;em&gt;similarity&lt;/em&gt; 를 계산하다는 늬앙스가 있었는데 그런식으로 계산하면 굉정히 오래걸린다고 논문에 쓰여져 있었다.(싱글 스레드 C++ 기준 30000 개의 정점을 가진 모델) 그래서 이 논문에서는 여러 방법을 제시했다. 가장 중점적인 것은 &lt;em&gt;bone weight&lt;/em&gt; 끼리의 거리를 직접 계산하여 &lt;em&gt;cluster&lt;/em&gt;(집단)을 구성하여 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산할 때 계산하는 절대적인 데이터를 줄이는 방법이다. 또한 일정 &lt;em&gt;similarity&lt;/em&gt; 보다 값이 적으면 탐색을 중단하는 방법도 제시했다. 그리고 마지막으로 제시한 방법은 위에서도 말한 병렬 프로그래밍을 이용하는 것이다.&lt;/p&gt;

&lt;p&gt;직접 스키닝을 계산하는 방법도 간단하다. 회전 연산은 기존의 행렬로 계산하던 것을 사원수로 변환 후 회전 연사을 하는 사원수를 &lt;em&gt;blending&lt;/em&gt; 하면된다. 위치 이동 연산은 살짝 다른데, &lt;em&gt;linear blending skinning&lt;/em&gt; 에서 정점을 계산하는 식을 정점 대신 &lt;em&gt;center of rotation&lt;/em&gt; 으로 계산 후에 그 값에다가 &lt;em&gt;blending&lt;/em&gt; 된 사원수로 &lt;em&gt;center of rotation&lt;/em&gt; 값을 변환시켜 빼주면 위치 이동 값(translate)가 완성된다. 위치 이동 값(translate)는 정점을 회전 연산 후에 값을 더해주기만 하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 을 계산하는 코드와 해당 skinning 방법을 Unity 로 구현해 놓았다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다. (&lt;em&gt;center of rotation&lt;/em&gt; 을 정확하게 논문에 나온대로 계산하는 코드를 짠것은 아닙니다. 그 부분은 이해 해주시고 참고해주길 바랍니다. 또한 자세한 방법을 아시는 분은 댓글 달아주시면 감사하겠습니다.)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.disneyresearch.com/publication/skinning-with-optimized-cors/&quot;&gt;Disney Reasearch : Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 dual quaternion skinning 글에서 dual quaternion skinning 에 대해서 설명해 보았다. 이전 글에서는 단순히 dual quaternion skinning 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 dual quaternion skinning 의 단점에 대해서 언급했다. joint bulging artifact 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다. 왼쪽은 dual quaternion skinning 을 표현한 그림이고, 오른쪽은 곧 소개할 optimized center of rotation 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 dual quternion skinning 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 joint bulging artifact 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 dual quaternion skinning 은 약간 움푹 들어간 것을 볼 수 있다. 그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 Real-time Skeletal Skinning with Optimized Centers of Rotation 이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Dual Quaternion Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/" rel="alternate" type="text/html" title="Dual Quaternion Skinning" />
      <published>2017-07-20T00:00:00+00:00</published>
      <updated>2017-07-20T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/07/introduce-of-skinning/&quot;&gt;Introduce of skinning&lt;/a&gt; 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 은 정점을 변환시키기 위해 행렬을 사용한다. 위치나 벡터를 1x4, 4x1 행렬로 취급해 행렬곱으로 계산해 위치값을 변환시킨다. 즉 한개의 값을 이용해서 변환을 한다. 조금 불편한 점은 변환 행렬을 &lt;em&gt;Weight Blending&lt;/em&gt; 하기가 어렵다.(필자의 경우 행렬을 Blending 하는데 실패했습니다. 아마 행렬 데이터 정규화가 안되서 그런것 같습니다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample/issues/6&quot;&gt;링크&lt;/a&gt;에 증상이 있으니, 혹여나 방법을 아신다면 댓글 부탁드립니다.) 그래서 각 뼈를 기준으로 변환된 위치를 뼈의 가중치로 평균값을 내서 최종 변환된 정점을 구한다.&lt;/p&gt;

&lt;p&gt;행렬을 사용한 변환의 장점은 위치 변환(translate), 회전 변환(rotation), 크기 변환(scaling)을 포함한 세가지 변환들을 전부 합쳐서 정보를 가지고 있을 수 있다. 물론 분리해서도 가능하다. 단점은 행렬 곱을 아는 사람은 알겠지만 절대적인 곱셈, 덧셈의 량이 꽤 된다. 3개의 변환을 합친 변환 행렬은 일반적으로 4x4 행렬을 사용하고 아무리 최적화를 해도 4x3 행렬을 사용하는게 전부다. 가장 중요한 단점은 &lt;em&gt;Linear&lt;/em&gt; 하게 위치를 &lt;em&gt;Blending&lt;/em&gt; 시키니 전글에서도 언급한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 뽑을 수 있겠다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;a href=&quot;https://www.cs.utah.edu/~ladislav/&quot;&gt;Ladislav Kavan&lt;/a&gt; 이라는 사람이 꽤나 많은 연구를 통해 다양한 논문을 내었는데 그 중 주목할 것은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 이다. 필자는 이 정보를 처음 접했을 때 조금 이해가 안되는 부분이 많이 있었다. 계산 방식 등 꽤나 이상한게 많았는데 &lt;em&gt;dual quaternion&lt;/em&gt; 이라는 개념이 우리가 알고 있는 일반적인 대수적인 개념에서 확장된 개념이였다. 게임 프로그래머라면 많이 들어봤을 법한 사원수(quaternion)과 &lt;em&gt;dual number&lt;/em&gt; 라는 이름만 들어도 생소한 개념의 단위를 합친 개념이다. 이를 수학적으로 알아보기 쉽게 자세히 설명하기엔 필자의 지식 수준이 매우 짧기에 정말 간단하게 설명하겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual number&lt;/em&gt; 라는건 두개의 숫자를 하나의 단위로 본다. 또한 여러 연산이 가능하도록 정의되어 있다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 사원수를 두개 가진 하나의 단위이다. 기본적으로 &lt;em&gt;dual number&lt;/em&gt; 의 연산을 따르지만 사원수(quaternion)의 개념에 의해 조금 바뀌는 부분이 꽤 있다. &lt;em&gt;dual&lt;/em&gt; 이니 두개의 개념이 있는데, 첫번째 개념은 &lt;em&gt;real&lt;/em&gt; 이라고 부른다. 두번째 개념은 &lt;em&gt;dual&lt;/em&gt; 이라고 부른다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual quaternion&lt;/em&gt; 은 변환을 위해 사용될 수 있고 우리가 사용할 목적과도 같다. 일반적으로 행렬은 위치, 회전, 크기 변환에 쓰인다고 했다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 일반적으로 위치, 회전 변환을 포함하고 있다. 또한 크기 변환도 가능하긴 하다. 일단은 크기 변환은 넘어가도록 하겠다. 그러면 우리가 볼것은 위치, 회전 변환인데 두개의 사원수에 회전 변환과 위치 변환이 각각 나뉘어져 들어간다. 첫번째 &lt;em&gt;real&lt;/em&gt; 에 회전변환이 들어가고, 두번째 &lt;em&gt;dual&lt;/em&gt; 에 위치변환이 들어간다. 그렇게 &lt;em&gt;dual quaternion&lt;/em&gt; 이 구성된다. 또한 각자 &lt;em&gt;dual quaternion&lt;/em&gt; 과 &lt;em&gt;Weight blending&lt;/em&gt; 도 정상적으로 되고(&lt;em&gt;quaternion&lt;/em&gt; 자체가 &lt;em&gt;blending&lt;/em&gt; 이 가능하기 때문이다.) &lt;em&gt;dual quaternion&lt;/em&gt; 끼리 합칠 수도 있고, 정점 변환도 가능하다. 그래서 이 &lt;em&gt;dual quaternion&lt;/em&gt; 을 &lt;em&gt;matrix&lt;/em&gt; 변환과 치환해서 사용이 가능하다.&lt;/p&gt;

&lt;p&gt;또한 앞에서 강조한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상도 어느정도 극복할 수 있다. 그냥 일반적으로 생각해 보았을 때 변환된 정점의 가중치를 곱해 평균값을 구한 것과는 다르게 변환 자체를 전부 합쳐서 한번의 변환으로 변환된 정점을 얻는 것은 조금 다르다고 생각된다. 필자는 Unity 를 사용하여 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 구현했다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;간단하게 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 해결하기 위해선 이 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 사용하면 된다. 하지만 필자는 약 10년전의 기술보다 더 나은 기술이 있을거라 생각해 여러가지 찾아보았다. 그 중 게임에서 쓸 수 있는 스키닝 기법을 하나 발견했다. 그 방법은 다음 글에서 확인해보자. &lt;a href=&quot;/2017/07/22/optimized-center-of-rotation/&quot;&gt;다음 글&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/other/dualQuaternion/&quot;&gt;EuclideanSpace : dual quaternion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://skinning.org/&quot;&gt;Skinning.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 Introduce of skinning 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. Linear Blend Skinning 의 “Candy Wrapper” 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Introduce Of Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/" rel="alternate" type="text/html" title="Introduce Of Skinning" />
      <published>2017-07-07T00:00:00+00:00</published>
      <updated>2017-07-07T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/">&lt;p&gt;2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 &lt;a href=&quot;/2017/05/19/handling-rig-and-skinning/&quot;&gt;handling rig and skinning&lt;/a&gt; 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;일반적으로 3D 물체는 대부분 고정된 정점을 가지고 그대로 그려진다. 물체의 정점들이 한꺼번에 움직이는 방법은 흔하나 정점 하나하나 각자 움직이는 경우는 몇 없다. 모든 정점이 자기만의 기준을 가지고 움직이면 엄청난 계산량을 요구하기 때문이다. 하지만 게임을 만들려면 정점을 움직여서 표현하여 보다 실제적인 움직임을 연출할 수 있을 수도 있다. 극단적인 예를 들면 펄럭이는 옷가지라던가 부서지는 오브젝트가 있겠다. 하지만 방금전에 말한 두가지는 굉장히 극단적인 이야기이고 살아 움직이는 물체를 표현하기 위해 스키닝이라는 기술이 있다. 예를 들면 사람 혹은 동물이 있겠다.&lt;/p&gt;

&lt;p&gt;스키닝이라는 말은 직역하면 &lt;em&gt;“피부를 입히다.”&lt;/em&gt; 라는 뜻이다. 하지만 일반적인 3D 오브젝트는 정해진 정점들을 이어서 삼각형을 만들어 꽤 많은 갯수의 삼각형으로 외형을 표현한다. 이렇게 생각하면 바깥의 피부를 입힌다는 것은 조금 이해가 안될 것이다. 여태까지 엄청나게 많은 이론이 나왔지만 게임에서 쓰이는 3D 모델의 스키닝이라는 용어는 일반적으로 생각하는 뜻이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;정점의 집합으로 이루어진 3D 물체에서 특정한 위치를 가지고 있는 “뼈” 라는 개념이 있다.&lt;/li&gt;
  &lt;li&gt;“뼈” 는 일반적은 3D 오브젝트가 가질 수 있는 변환을 할 수 있다. (Translate, Rotation, Scale)&lt;/li&gt;
  &lt;li&gt;각 정점들은 특정한 “뼈” 를 기준으로 잡아 기준이 되는 “뼈” 의 변환 정보를 각 정점에 적용시켜 뼈가 움직이면 정점도 같이 움직이게 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위에서 설명한 세가지가 적용이 된것이 “스키닝” 이 적용된 3D 물체라고 할 수 있다. 이 간단한 개념이 확장되어 현 시대의 게임에서도 쓰이고 있다. 매우 간단한 이 방법은 약간의 문제가 있다. 관절같은 경우 두개이상의 “뼈” 변환을 참조해야 한다. 어떻게 두개 이상의 “뼈” 변환을 합칠 것인가? 이 문제는 아직까지도 완전히 해결되지 않았고 이 문제를 해결하기 위해 꽤 많은 논문들이 나왔다. 단순히 뼈를 이용하는 방식 뿐만아니라 다양한 방식으로도 말이다. 먼저 가장 널리 알려지고 가장 많이 쓰이는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라는 방법이 있다. 이 방법은 굉~장히 단순하다. 그만큼 많이 쓰이는 듯 싶다. 논문이 1988년에 나온 기술로.. 조금만 잔머리 굴리면 쓸만한 내용이다. 두개 이상의 뼈의 변환 행렬을 정점 위치를 계산하여 정해진 가중치에 비례해서 값을 섞는다. 이 방식은 보통 값과 값사이의 특정한 위치를 가져올때 쓰이는 방법이다. 이 방식은 수학적으로 생각해보면 울퉁불퉁한 곡선에 해당되는게 아니라 선형적으로 값을 보간하는 방법이므로 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라고 불리는 것이다. Unity 의 스키닝된 메쉬를 그리는 &lt;em&gt;Skinned Mesh Renderer&lt;/em&gt; 컴포넌트가 아직도 LBS 를 사용하고 있다. 하지만 이 방법은 흔히 알려진 문제가 하나 있다. &lt;em&gt;‘Candy Wrapper’&lt;/em&gt; - 한국어로 사탕 껍질 이라고 불리는 현상인데, 아래 그림의 사탕 껍질을 이야기 하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/candy_wrapper.jpg&quot; alt=&quot;사탕 껍질&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;주목할 것은 안의 사탕이 아니라 양 옆의 꼬여져서 엄청 가늘어진 상태의 껍질이다. LBS 를 사용하면 해당 오브젝트의 관절이 저렇게 표현될 수 있다. 해당 축으로 180도 돌리면 말이다. 아래 그림에 상세하게 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/umbra-ignite-2015-rulon-raymond-the-state-of-skinning-a-dive-into-modern-approaches-to-model-skinning-33-638.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하여튼 &lt;em&gt;Linear Based Blending&lt;/em&gt; 은 현 시대에서는 그다지 유용한 기술은 아니다. 하지만 많은 곳에서 채택되어 아직도 남아있다. 많은 사람들의 관심이 몰리는 분야는 아니기 때문에 기술 발전 자체는 그다지 빠른편이 아니다. 하지만 30년 전의 기술을 아직도 쓴다는건 그리 좋은 생각은 아닌 것 같다. 이를 위해 10년전에 괜찮은 수 체계를 도입했다. 이는 다음 글에서 설명하겠다. 다음 글 : &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;&lt;em&gt;dual quaternion skinning&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;혹시 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 Unity 구현을 보고 싶으면 &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;GitHub : CustomSkinningExample&lt;/a&gt; 에서 보면 된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 handling rig and skinning 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.</summary>
      

      
      
    </entry>
  
  
</feed>
