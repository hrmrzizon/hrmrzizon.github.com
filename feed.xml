<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko">
  <generator uri="http://jekyllrb.com" version="3.5.2">Jekyll</generator>
  
  
  <link href="https://hrmrzizon.github.io/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://hrmrzizon.github.io/" rel="alternate" type="text/html" hreflang="ko" />
  <updated>2017-09-09T05:25:19+00:00</updated>
  <id>https://hrmrzizon.github.io//</id>

  
    <title type="html">Appocrypha</title>
  

  
    <subtitle>store limitless knowledges</subtitle>
  

  
    <author>
        <name>Su-Hyeok Kim</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Thought About Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/03/thought-about-unity/" rel="alternate" type="text/html" title="Thought About Unity" />
      <published>2017-08-03T00:00:00+00:00</published>
      <updated>2017-08-03T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/03/thought-about-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/03/thought-about-unity/">&lt;p&gt;※ 필자는 Unity 가 참 마음에 듭니다. 그만큼 편협한 시각을 가지고 있을 수도 있으니 사실과 다른 부분은 댓글로 알려주시기 바랍니다.&lt;/p&gt;

&lt;p&gt;최근에 우연한 기회로 SNS 에서 꽤나 대단한 사람을 통해 많은 정보를 들었다. 기술적인 것, 한국 게임 업계에 대한 고찰, 게임 업계의 미래 등 아무것도 몰랐던 필자에게 엄청난 정보들이 들어왔다. 그 중에서도 가장 도움이 된건 아무래도 로드맵을 제시해주고 기술에 대한 설명들이 아닐까 싶다. 그 분의 말씀중에 게임 엔진에 대한 고찰도 상당히 많이 써있었다. 대부분이 잘못된 부분에 대한 지적이였지만 미래 또한 포함되어 있었다. 그리고 그글을 보고 2년 동안 봐왔던 Unity 에 대해 극히 주관적인 생각들을 정리해 보려한다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;99% 의 CBD, 단순한 시스템, 수많은 가능성&lt;/h2&gt;

&lt;p&gt;Unity 의 게임 시스템은 Hierarchy 안에서 미리 저장된 Scene 의 데이터를 불러와 GameObject 들을 적재하고 로딩이 된 오브젝트들이 알아서 모든 것을 다하는 시스템이다. 모두가 알다시피 GameObject 에는 여러개의 컴포넌트가 붙어 각각의 컴포넌트가 각자의 역할을 한다. 그렇게 게임이 돌아간다. 컨텐츠 프로그래머는 컴포넌트와 Scene 의 데이터만 잘 설계해주면 된다.&lt;/p&gt;

&lt;p&gt;아무것도 정해지지 않은 Unity 의 극한의 CBD 는 초보자에게 당황스러움을 주지만 익숙해진 사람들에게는 극한의 자유가 머릿속에 각인되어져 있다. 아주 잠깐 회사에서 받은 외주 때문에 UE4 를 잠깐 건드려봤는데 꽤나 정해진 시스템이 많았다. 물론 엔진계의 쌍두마차답게 거의 모든 게임에 적용되게 시스템을 구성해놓아서 괜찮아 보였다. 하지만 그 시스템을 학습하는 시간은 오래 걸리지 않았지만 조금 아까웠다. 반대로 Unity 의 극한의 자유가 생각났다.&lt;/p&gt;

&lt;p&gt;그리고 Hierarchy 시스템말고도 Unity 에서 자랑하는 강력한 시스템이 있다. 바로 &lt;strong&gt;ScriptableObject&lt;/strong&gt; 라는 에셋 데이터 타입이다. 물론 스크립팅을 사용할 수 있어 저 이름이 붙었다. Unity 의 직렬화 시스템을 오직 한 스크립트만을 위해 사용 가능하며 스크립트별로 다른 데이터가 취급되기 때문에 사용자의 커스텀 데이터 타입을 만들 수 있는 가능성을 열어준다. 또한 Unity 에셋의 파일 시스템은 모든 에셋에 하위 에셋을 붙여서 저장이 가능하다. 이 하위 에셋 시스템과 &lt;strong&gt;ScriptableObject&lt;/strong&gt; 시스템을 사용하면 모든 데이터를 사용자 마음대로 저장이 가능하다.&lt;/p&gt;

&lt;p&gt;렌더링 쪽에서도 꽤나 여러가지를 할 수 있도록 가능성을 열어놓았다. &lt;strong&gt;CommandBuffer&lt;/strong&gt; 라는 놈이 있다. 어느정도 렌더링 파이프라인 안에서 사용자가 하고싶은 렌더링을 마음대로 하게 해주는 &lt;em&gt;명령(Command)&lt;/em&gt; 를 저장해 여러가지를 할 수 있다. 또한 Unity 시스템의 Mesh 인스턴스를 통한 렌더링 뿐만 아니라 데이터를 직접 저장해서 그릴 수도 있다. 또한 &lt;em&gt;Indirect Rendering&lt;/em&gt; 을 지원해 최적의 효율을 뽑을 수 있다. 이는 Graphics API 들에서 지원하는 기능을 그대로 가져온 것이지만 커스터마이징이 유연한 Unity 에서는 꽤나 강력한 시너지를 구성한다.&lt;/p&gt;

&lt;h2&gt;엉성한 기능, 상세하게 정리되지 않은 레퍼런스, 어려운 최적화&lt;/h2&gt;

&lt;p&gt;위에서 말한 하락세는 한가지 시스템에서 도드라지게 나타난다. 바로 지형 시스템이다. Unity 에서는 DrawCall 을 자체적으로 최적화해서 Batching Count 라고 따로 숫자가 있다. 결국 DrawCall 과 같은 개념이다. 근데 Terrain 에 있는게 많을 수록 Batching Count 가 기하급수적으로 늘어난다. 물론 필자가 충분한 사전조사는 하지 않았었다. 하지만 꽤나 많은 사람이 같은 문제를 겪는걸로 봐서는 고질적인 문제인듯 하다. 그리고 아직도 안고쳐졌다.&lt;/p&gt;

&lt;p&gt;Unity 의 웹 레퍼런스는 굉장히 별로다. 상세한 설명이 없이 그냥 단문으로 구성된 페이지도 간혹가다 있다. 물론 단문으로만 쓸 수도 있는 것도 있지만 그렇지 않은것들도 꽤나 많아 짜증을 유발한다. 또한 &lt;em&gt;Graphics.DrawProceduralIndirect&lt;/em&gt; 메서드를 사용하기 위해 래퍼런스를 보는데 &lt;em&gt;Indirect Rendering&lt;/em&gt; 구성에 중요한 데이터들을 표로 정리하지 않고 그냥 텍스트로만 정리해놓아서 조금 헷갈렸다. 이게 그대로 메모리 값을 복사하는 것이기 때문에 순서를 잘 맞춰주어야 하는데 성의없이 써놓은게 너무 아쉬웠다. 그리고 해당 API 의 단점도 안쓰여있어 써보기 전에는 아무것도 모른다. 이는 Unity 엔지니어들이 그다지 효율적으로 관리되지 않는 것으로 보인다.&lt;/p&gt;

&lt;p&gt;Terrain 도 그렇지만 Unity 에서 3D 게임을 만들면서 최적화를 하려면 굉장히 어렵다. 물론 지식이 없는것도 문제지만 그것을 유도해주는 레퍼런스나 가이드는 거의 없다. 또한 처음부터 제대로 만들려면 결국 전부다 뜯어 고쳐야 한다. 위에서 말한 데이터 커스터마이징을 통해 메시 데이터를 전부 합쳐 &lt;em&gt;Graphics.DrawProceduralIndirect&lt;/em&gt; 를 사용해 &lt;em&gt;Batching Count&lt;/em&gt; 를 줄이는 것은 이전에 기하급수적으로 증가한 &lt;em&gt;Batching Count&lt;/em&gt; 의 성능과 비교했을 떄 하늘과 땅 차이다. 또한 &lt;strong&gt;Terrain&lt;/strong&gt; 도 &lt;em&gt;Batching Count&lt;/em&gt; 가 너무 커서 사용이 불가능해 결국 데이터를 추출해 메시 데이터를 커스터마이징 한것처럼 결국 처음부터 다해야 한다. 특히나 바람에 흔들리는 물리 시스템이 있는 풀이나 나무를 움직이는 기술은 &lt;strong&gt;GPU Gems&lt;/strong&gt; 나 &lt;strong&gt;GPU Pro&lt;/strong&gt; 에 나올법한 기술들을 바탕으로 구현해야하기 때문에 문외한들에게는 답이 없다.&lt;/p&gt;

&lt;p&gt;이건 물론 기본적인 소양이겠지만 스크립트에서 GC 를 최대한 안일으키는게 게임 프로그래머의 중요한 역량이기 때문에 C# 의 쓰레기 메모리가 생기는 요인들을 거의 다 파악하고 있어야 한다. 이는 프로그래머에게 크나큰 고통을 안겨준다. 필자도 처음 이 사실을 알았을 때 굉장히 좌절했었다. 또한 퍼포먼스가 안나오는 플랫폼에서는 꽤 많은 갯수의 &lt;strong&gt;Update&lt;/strong&gt; 구문의 실행이 취약하다는 것도 놀라운 사실이었다.&lt;/p&gt;

&lt;h2&gt;결론&lt;/h2&gt;

&lt;p&gt;다행히 Unity 는 미래가 어둡지는 않을 것 같다. 여태까지는 엔진의 기능이 하락세를 걷고 있었지만 하나 하나 고쳐가는 중이다. 아마 2017 버젼이 몇개 더 릴리즈 되면 꽤나 안정화가 되어 많은 가능성이 열릴 듯 하다. 물론 구멍이 있는 기능들이 모두다 고쳐질라면 꽤나 시간은 걸릴 듯 하지만 말이다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      

      

      
        <summary type="html">※ 필자는 Unity 가 참 마음에 듭니다. 그만큼 편협한 시각을 가지고 있을 수도 있으니 사실과 다른 부분은 댓글로 알려주시기 바랍니다. 최근에 우연한 기회로 SNS 에서 꽤나 대단한 사람을 통해 많은 정보를 들었다. 기술적인 것, 한국 게임 업계에 대한 고찰, 게임 업계의 미래 등 아무것도 몰랐던 필자에게 엄청난 정보들이 들어왔다. 그 중에서도 가장 도움이 된건 아무래도 로드맵을 제시해주고 기술에 대한 설명들이 아닐까 싶다. 그 분의 말씀중에 게임 엔진에 대한 고찰도 상당히 많이 써있었다. 대부분이 잘못된 부분에 대한 지적이였지만 미래 또한 포함되어 있었다. 그리고 그글을 보고 2년 동안 봐왔던 Unity 에 대해 극히 주관적인 생각들을 정리해 보려한다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Compute Buffer In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/" rel="alternate" type="text/html" title="Using Compute Buffer In Unity" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/">&lt;p&gt;Unity 에서의 확실한 GPU Instancing 은 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 라는 구현체에서 시작될 것이다. 이 구현체는 &lt;strong&gt;UnityEngine.ComputeBuffer&lt;/strong&gt; 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 와 함께 등장했다. &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 구현해 놓았다. 하지만 이 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 이상이다. PC 플랫폼에서는 당연히 사용 가능하다.&lt;/p&gt;

&lt;p&gt;사용하는 방법 자체는 어렵지 않다. 스크립트에서 &lt;em&gt;size&lt;/em&gt; 와 &lt;em&gt;stride&lt;/em&gt; 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 &lt;strong&gt;System.Array&lt;/strong&gt; 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;int dataLen = ...;  // length of data
int[] dataArray = new int[dataLen];

// record data in dataArray..

ComputeShader computeShader = ...;
ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int));
dataBuffer.SetData(dataArray);

computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(&lt;em&gt;length&lt;/em&gt;)와 각 데이터별 크기(&lt;em&gt;stride&lt;/em&gt;)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(&lt;em&gt;write&lt;/em&gt;) 그리고 마지막으로 데이터가 세팅된 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에 연결해준다. 이러면 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드에서 &lt;em&gt;dataBuffer&lt;/em&gt; 라는 변수명을 가진 변수에 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 가 연결된다. 아래에 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드가 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-HLSL&quot;&gt;StructuredBuffer&amp;lt;int&amp;gt; dataBuffer;

[numthreads(8,8,1)]
void Process (uint3 id : SV_DispatchThreadID)
{
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;맨 처음에 있는 &lt;em&gt;dataBuffer&lt;/em&gt; 에 연결된다. &lt;a href=&quot;{ post_url 2017-07-06-structured-buffer-vs-constant-buffer }&quot;&gt;StructuredBuffer vs ConstantBuffer&lt;/a&gt; 에서본 &lt;em&gt;StructuredBuffer&lt;/em&gt; 타입이 가능하다. 또한 &lt;em&gt;RWStructuredBuffer&lt;/em&gt;, &lt;em&gt;ConsumeStructuredBuffer&lt;/em&gt;, &lt;em&gt;AppendStructuredBuffer&lt;/em&gt; 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/data-process-pipeline.png&quot; alt=&quot;data process&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞의 두가지 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 세팅하고 &lt;strong&gt;ComputeShader&lt;/strong&gt; 를 실행하는 코드는 대충 보았다, 뒷 부분의 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 스키닝의 계산을 &lt;strong&gt;ComputeShader&lt;/strong&gt; 로 넘겨서 계산한다. 또한 메시 데이터 전체를 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/ComputeBuffer.html&quot;&gt;Unity Reference : ComptuteBuffer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="gpuinstancing" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서의 확실한 GPU Instancing 은 ComputeBuffer 라는 구현체에서 시작될 것이다. 이 구현체는 UnityEngine.ComputeBuffer 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. ComputeBuffer 는 ComputeShader 와 함께 등장했다. ComputeShader 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 ComputeBuffer 를 구현해 놓았다. 하지만 이 ComputeBuffer 는 ComputeShader 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 Shader Model 5.0 이상이다. PC 플랫폼에서는 당연히 사용 가능하다. 사용하는 방법 자체는 어렵지 않다. 스크립트에서 size 와 stride 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 System.Array 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다. int dataLen = ...; // length of data int[] dataArray = new int[dataLen]; // record data in dataArray.. ComputeShader computeShader = ...; ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int)); dataBuffer.SetData(dataArray); computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer); 위 코드는 ComputeShader 에서 ComputeBuffer 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 ComputeBuffer 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(length)와 각 데이터별 크기(stride)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(write) 그리고 마지막으로 데이터가 세팅된 ComputeBuffer 를 ComputeShader 에 연결해준다. 이러면 ComputeShader 코드에서 dataBuffer 라는 변수명을 가진 변수에 ComputeBuffer 가 연결된다. 아래에 ComputeShader 코드가 있다. StructuredBuffer&amp;lt;int&amp;gt; dataBuffer; [numthreads(8,8,1)] void Process (uint3 id : SV_DispatchThreadID) { ... } 맨 처음에 있는 dataBuffer 에 연결된다. StructuredBuffer vs ConstantBuffer 에서본 StructuredBuffer 타입이 가능하다. 또한 RWStructuredBuffer, ConsumeStructuredBuffer, AppendStructuredBuffer 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다. 앞의 두가지 ComputeBuffer 를 세팅하고 ComputeShader 를 실행하는 코드는 대충 보았다, 뒷 부분의 ComputeBuffer 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다. Github : CustomSkinningExample 에서 스키닝의 계산을 ComputeShader 로 넘겨서 계산한다. 또한 메시 데이터 전체를 ComputeBuffer 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다. 참조 Unity Reference : ComptuteBuffer</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Darboux Frame</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/darboux-frame/" rel="alternate" type="text/html" title="Darboux Frame" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/darboux-frame</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/darboux-frame/">&lt;p&gt;여러 공간 법선 벡터(&lt;em&gt;tangent space normal&lt;/em&gt;, &lt;em&gt;object space normal&lt;/em&gt;)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. &lt;em&gt;darboux frame&lt;/em&gt; 이라는 놈이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;우선 &lt;em&gt;tangent space normal&lt;/em&gt; 과 &lt;em&gt;object space normal&lt;/em&gt; 에 대해서 설명해야 한다. 그래픽스에서는 빛을 표현하기 위해 노말벡터를 사용한다. 처음에 나온식은 매우 간단하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(빛의 방향 벡터) * (노말 벡터) = (빛이 표현하는 색의 범위(-1~1))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 벡터곱은 내적을 뜻한다. 이 식의 결과값은 반사광을 표현하는데 쓰인다. 일반적으로 말하는 &lt;em&gt;Specular&lt;/em&gt; 를 뜻한다. 하여튼 빛을 표현하는 것은 그래픽스에서는 굉장히 중요한 일이기 때문에 이 노말벡터를 어떻게 관리하는지가 엄청나게 중요하다. 그래서 여러 방법이 있는데 제일 많이 쓰이는건 &lt;em&gt;tangent space normal&lt;/em&gt; 이다. 그런데 &lt;em&gt;object space normal&lt;/em&gt; 은 갑자기 왜 튀어나왔느냐? 이유는 간단하다. 두개가 가장 비교가 많이 되는 방법이기 때문이다. &lt;em&gt;object space normal&lt;/em&gt; 은 굉장히 간단하다. 저장된 메시 데이터의 노말 벡터값이다. 기본 단위가 저장된 한 개체의 메시의 노말이기 때문에 &lt;em&gt;object spoce&lt;/em&gt; 라는 접두사가 붙은 것이다. 그래서 그런지 아래 그림에서 나오는 &lt;em&gt;object spoce normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 굉장히 다양하다. 하지만 옆에 &lt;em&gt;tangent space normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 거의 일정하다. 왜 그럴까? 우선 앞의 &lt;em&gt;object space normal&lt;/em&gt; 은 그냥 오브젝트 기준의 좌표계에서의 정점별 노말값을 저장한 데이터다. 하지만 &lt;em&gt;tangent space normal&lt;/em&gt; 은 모델에서 추출한 &lt;em&gt;tangent&lt;/em&gt; 값을 통해 &lt;em&gt;normal&lt;/em&gt; 값을 구하는 방법이다. &lt;a href=&quot;/2017/07/30/normal-tangent-binormal/&quot;&gt;normal tangent binormal&lt;/a&gt; 에서 설명했었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06b-tangent-space/nm_textures.jpg&quot; alt=&quot;tangent-space vs objcet-space&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그런데 &lt;em&gt;tangent space normal&lt;/em&gt; 에서의 &lt;em&gt;tangent&lt;/em&gt; 가 뜻하는 것은 표면의 접선 값이다. 이렇게 표면을 기준으로 하는 것을 &lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;&lt;em&gt;darboux frame&lt;/em&gt;&lt;/a&gt; 이라고 한다. 프랑스 사람의 이름이라 한글로 읽으면 &lt;em&gt;다르부-프레임&lt;/em&gt; 이다. 위키에서는 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이 표면 기하학에서 적용된 것이라 한다. 그만큼 대부분의 정의들이 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 과 매우 비슷하다. 다른 점은 곡선에서 표면으로 확장시켰다는 점이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ssloy/tinyrenderer/wiki/Lesson-6bis:-tangent-space-normal-mapping&quot;&gt;Github : tinyrenderer Wiki - tangent-space-normal-mapping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;Wikipedia : darvoux frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">여러 공간 법선 벡터(tangent space normal, object space normal)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. darboux frame 이라는 놈이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Normal Tangent Binormal</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/" rel="alternate" type="text/html" title="Normal Tangent Binormal" />
      <published>2017-07-30T00:00:00+00:00</published>
      <updated>2017-07-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/">&lt;p&gt;Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;노말 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;탄젠트 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;바이노말 벡터&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;법선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;접선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;이중법선(또는 종법선)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;하지만 이게 뭔지, 어디서 나온지에 대해서 설명한건 그다지 많이 본적이 없다. 물론 필자는 인터넷에 있는 레퍼런스만 보고 공부해서 그럴 수도 있다. 그래서 간단하게 지식의 뿌리만 살펴보려고 한다.&lt;/p&gt;

&lt;p&gt;이 세가지는 이름도 무시무시한 &lt;em&gt;미분기하학&lt;/em&gt; 에서 소개되는 &lt;em&gt;“프레네-세레 공식”(Frene-seret formula)&lt;/em&gt; 에서 정의된 것들이다. 정식 이름은 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 은 일반적으로 우리가 알고있는 실수 공간의 곡률이 있는 곡선 &lt;em&gt;r(t)&lt;/em&gt; 에서 유도된다. 중간에 있는 &lt;em&gt;t&lt;/em&gt; 는 시간을 나타내며 이는 이동한 거리, 곡선의 호 &lt;em&gt;s&lt;/em&gt; 로 매개화 시킨다고 한다. 그래서 그 곡선 &lt;em&gt;r(t(s))&lt;/em&gt; 를 미분해서 방향을 나타내는 말들이 우리가 평상시에 많이 들어왔던 노말, 탄젠트, 바이노말인 것이다.&lt;/p&gt;

&lt;p&gt;탄젠트는 곡선 공식을 그대로 미분한 값. 우리가 알고있는 일반적인 순간 가속도를 뜻한다. 이게 결국 방향을 나타내기 때문에 한글로는 비슷하게 접선벡터 라고 하는 듯하다. 그리고 현재 방향의 수직을 나타내는 노말은 탄젠트를 미분한 값을 정규화시켜서 표현한다. 필자는 이 값이 수학적으로 어떤 것을 나타내는지 몰라서 직관적으로 수식을보고 법선벡터인지 모르겠다. 마지막으로 바이노말은 탄젠트와 노말을 외적해서 구한다.&lt;/p&gt;

&lt;p&gt;여기까지는 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 을 위한 정의들이다. 사실 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 보다는 앞에서 말한  &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 의 정의가 훨씬 더 많이 알려져 있다. 빛을 나타내기 위한 노말과 탄젠트를 그래픽스 이론에서는 끊임없이 보기 때문이다. &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 에 대한 자세한건 이 글에서는 쓰지 않겠다. 이 글을 쓴 이유는 우리가 흔히 쓰는 용어의 뿌리를 찾기위함이였다. (자세한 설명은 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;을 참조)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas&quot;&gt;Wikipedia : Frene-seret formula&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://gall.dcinside.com/board/view/?id=mathematics&amp;amp;no=134445&quot;&gt;디시인사이드 수학 갤러리&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Optimized Center Of Rotation</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/" rel="alternate" type="text/html" title="Optimized Center Of Rotation" />
      <published>2017-07-22T00:00:00+00:00</published>
      <updated>2017-07-22T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;dual quaternion skinning&lt;/a&gt; 글에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 설명해 보았다. 이전 글에서는 단순히 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 의 단점에 대해서 언급했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dqs_ocor_bent.png&quot; alt=&quot;both bent&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 표현한 그림이고, 오른쪽은 곧 소개할 &lt;em&gt;optimized center of rotation&lt;/em&gt; 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 &lt;em&gt;dual quternion skinning&lt;/em&gt; 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 &lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 은 약간 움푹 들어간 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 &lt;em&gt;Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/em&gt; 이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;이 방식은 간단한 아이디어로 접근하면서도 기존의 &lt;em&gt;Weight Blending&lt;/em&gt; 데이터와 호환되며, 런타임에서도 꽤나 쓸만한 방식이다. 또한 처리하는 데이터도 &lt;em&gt;linear bleding skinning&lt;/em&gt; 과 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 비해서도 조금 늘었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 의 기본적인 아이디어는 기존의 방식은 회전 축의 위치가 뼈의 가중치로 결정되어 문제가 생기는 것을 알아채서 각 정점별로 다른 회전의 위치(&lt;em&gt;center of rotation&lt;/em&gt;)를 정해 주는 것이다. 앞에 붙은 &lt;em&gt;optimized&lt;/em&gt; 가 내포한 의미도 있다. 사실 모든 정점별로 &lt;em&gt;center of rotation&lt;/em&gt; 을 정해주면 굉장히 번거롭다. 또한 이 논문에서 소개하는 계산방식은 실시간으로 계산하기에는 너무 느리다. 그래서 이 논문에서는 각 정점별로 기본 포즈(보통 T 포즈를 뜻함.)를 기준으로 &lt;em&gt;center of rotatoin&lt;/em&gt; 을 미리 데이터를 계산해서 실시간으로는 데이터를 참조해서 &lt;em&gt;skinning&lt;/em&gt; 을 한다.&lt;/p&gt;

&lt;p&gt;그런데 이 스키닝 방식을 구현하려면 먼저 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산해주는 코드를 직접 짜야한다. 아직은 3D 에디팅 툴에서 지원을 하지 않기 때문이다. 게임 엔진들 또한 마찬가지다. 또한 일반적인 싱글 스레드 프로그램으로 짜기에는 너무 데이터가 많아서 여러 스레드를 이용하는 멀티 스레딩이나 GPGPU 기술을 사용해서 구현해야 한다. 필자는 구현의 편의성을 위해 멀티 스레딩을 사용했지만 조금 느렸다. 꽤나 괜찮은 GPU 를 가지고 있으면 GPGPU 를 사용하는것이 훨씬 빠를 것이다.&lt;/p&gt;

&lt;p&gt;자세한 방법을 알고 싶으면 논문을 참고하라.(&lt;a href=&quot;https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20160705174939/Real-time-Skeletal-Skinning-with-Optimized-Centers-of-Rotation-Paper.pdf&quot;&gt;논문 링크&lt;/a&gt;) 논문에서 나오는 첫번째로 소개되는 정점과 정점간에 &lt;em&gt;similarity&lt;/em&gt; 를 계산하는 식과 &lt;em&gt;center of rotation&lt;/em&gt; 위치를 계산하는 네번째 식, 그 아래에 있는 Intergration 항목을 참조하면 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 코드를 짤 수 있다. &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 방식의 아이디어는 꽤나 간단하다. &lt;em&gt;bone weight&lt;/em&gt; 들의 연관성(&lt;em&gt;similarity&lt;/em&gt;) 를 계산해 이 숫자를 각 정점간의 가중치로 설정한다. 이 연관성(&lt;em&gt;similarity&lt;/em&gt;)를 계산하기 위해서는 최소 두개의 같은 뼈의 가중치를 가지고 있어야 한다. 만약 아무것도 연관성이 없다면 &lt;em&gt;linear blending skinning&lt;/em&gt; 으로 계산하게 하면 된다. 그리고 각각 폴리곤의 세 정점의 평균 &lt;em&gt;similarity&lt;/em&gt; 와 폴리곤의 세 정점의 평균 위치, 그리고 삼각형의 넓이를 계산해서 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산한다.&lt;/p&gt;

&lt;p&gt;다만 논문의 처음에서는 모든 정점을 기준으로 전부 &lt;em&gt;similarity&lt;/em&gt; 를 계산하다는 늬앙스가 있었는데 그런식으로 계산하면 굉정히 오래걸린다고 논문에 쓰여져 있었다.(싱글 스레드 C++ 기준 30000 개의 정점을 가진 모델) 그래서 이 논문에서는 여러 방법을 제시했다. 가장 중점적인 것은 &lt;em&gt;bone weight&lt;/em&gt; 끼리의 거리를 직접 계산하여 &lt;em&gt;cluster&lt;/em&gt;(집단)을 구성하여 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산할 때 계산하는 절대적인 데이터를 줄이는 방법이다. 또한 일정 &lt;em&gt;similarity&lt;/em&gt; 보다 값이 적으면 탐색을 중단하는 방법도 제시했다. 그리고 마지막으로 제시한 방법은 위에서도 말한 병렬 프로그래밍을 이용하는 것이다.&lt;/p&gt;

&lt;p&gt;직접 스키닝을 계산하는 방법도 간단하다. 회전 연산은 기존의 행렬로 계산하던 것을 사원수로 변환 후 회전 연사을 하는 사원수를 &lt;em&gt;blending&lt;/em&gt; 하면된다. 위치 이동 연산은 살짝 다른데, &lt;em&gt;linear blending skinning&lt;/em&gt; 에서 정점을 계산하는 식을 정점 대신 &lt;em&gt;center of rotation&lt;/em&gt; 으로 계산 후에 그 값에다가 &lt;em&gt;blending&lt;/em&gt; 된 사원수로 &lt;em&gt;center of rotation&lt;/em&gt; 값을 변환시켜 빼주면 위치 이동 값(translate)가 완성된다. 위치 이동 값(translate)는 정점을 회전 연산 후에 값을 더해주기만 하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 을 계산하는 코드와 해당 skinning 방법을 Unity 로 구현해 놓았다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다. (&lt;em&gt;center of rotation&lt;/em&gt; 을 정확하게 논문에 나온대로 계산하는 코드를 짠것은 아닙니다. 그 부분은 이해 해주시고 참고해주길 바랍니다. 또한 자세한 방법을 아시는 분은 댓글 달아주시면 감사하겠습니다.)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.disneyresearch.com/publication/skinning-with-optimized-cors/&quot;&gt;Disney Reasearch : Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 dual quaternion skinning 글에서 dual quaternion skinning 에 대해서 설명해 보았다. 이전 글에서는 단순히 dual quaternion skinning 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 dual quaternion skinning 의 단점에 대해서 언급했다. joint bulging artifact 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다. 왼쪽은 dual quaternion skinning 을 표현한 그림이고, 오른쪽은 곧 소개할 optimized center of rotation 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 dual quternion skinning 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 joint bulging artifact 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 dual quaternion skinning 은 약간 움푹 들어간 것을 볼 수 있다. 그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 Real-time Skeletal Skinning with Optimized Centers of Rotation 이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Dual Quaternion Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/" rel="alternate" type="text/html" title="Dual Quaternion Skinning" />
      <published>2017-07-20T00:00:00+00:00</published>
      <updated>2017-07-20T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/07/introduce-of-skinning/&quot;&gt;Introduce of skinning&lt;/a&gt; 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 은 정점을 변환시키기 위해 행렬을 사용한다. 위치나 벡터를 1x4, 4x1 행렬로 취급해 행렬곱으로 계산해 위치값을 변환시킨다. 즉 한개의 값을 이용해서 변환을 한다. 조금 불편한 점은 변환 행렬을 &lt;em&gt;Weight Blending&lt;/em&gt; 하기가 어렵다.(필자의 경우 행렬을 Blending 하는데 실패했습니다. 아마 행렬 데이터 정규화가 안되서 그런것 같습니다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample/issues/6&quot;&gt;링크&lt;/a&gt;에 증상이 있으니, 혹여나 방법을 아신다면 댓글 부탁드립니다.) 그래서 각 뼈를 기준으로 변환된 위치를 뼈의 가중치로 평균값을 내서 최종 변환된 정점을 구한다.&lt;/p&gt;

&lt;p&gt;행렬을 사용한 변환의 장점은 위치 변환(translate), 회전 변환(rotation), 크기 변환(scaling)을 포함한 세가지 변환들을 전부 합쳐서 정보를 가지고 있을 수 있다. 물론 분리해서도 가능하다. 단점은 행렬 곱을 아는 사람은 알겠지만 절대적인 곱셈, 덧셈의 량이 꽤 된다. 3개의 변환을 합친 변환 행렬은 일반적으로 4x4 행렬을 사용하고 아무리 최적화를 해도 4x3 행렬을 사용하는게 전부다. 가장 중요한 단점은 &lt;em&gt;Linear&lt;/em&gt; 하게 위치를 &lt;em&gt;Blending&lt;/em&gt; 시키니 전글에서도 언급한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 뽑을 수 있겠다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;a href=&quot;https://www.cs.utah.edu/~ladislav/&quot;&gt;Ladislav Kavan&lt;/a&gt; 이라는 사람이 꽤나 많은 연구를 통해 다양한 논문을 내었는데 그 중 주목할 것은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 이다. 필자는 이 정보를 처음 접했을 때 조금 이해가 안되는 부분이 많이 있었다. 계산 방식 등 꽤나 이상한게 많았는데 &lt;em&gt;dual quaternion&lt;/em&gt; 이라는 개념이 우리가 알고 있는 일반적인 대수적인 개념에서 확장된 개념이였다. 게임 프로그래머라면 많이 들어봤을 법한 사원수(quaternion)과 &lt;em&gt;dual number&lt;/em&gt; 라는 이름만 들어도 생소한 개념의 단위를 합친 개념이다. 이를 수학적으로 알아보기 쉽게 자세히 설명하기엔 필자의 지식 수준이 매우 짧기에 정말 간단하게 설명하겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual number&lt;/em&gt; 라는건 두개의 숫자를 하나의 단위로 본다. 또한 여러 연산이 가능하도록 정의되어 있다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 사원수를 두개 가진 하나의 단위이다. 기본적으로 &lt;em&gt;dual number&lt;/em&gt; 의 연산을 따르지만 사원수(quaternion)의 개념에 의해 조금 바뀌는 부분이 꽤 있다. &lt;em&gt;dual&lt;/em&gt; 이니 두개의 개념이 있는데, 첫번째 개념은 &lt;em&gt;real&lt;/em&gt; 이라고 부른다. 두번째 개념은 &lt;em&gt;dual&lt;/em&gt; 이라고 부른다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual quaternion&lt;/em&gt; 은 변환을 위해 사용될 수 있고 우리가 사용할 목적과도 같다. 일반적으로 행렬은 위치, 회전, 크기 변환에 쓰인다고 했다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 일반적으로 위치, 회전 변환을 포함하고 있다. 또한 크기 변환도 가능하긴 하다. 일단은 크기 변환은 넘어가도록 하겠다. 그러면 우리가 볼것은 위치, 회전 변환인데 두개의 사원수에 회전 변환과 위치 변환이 각각 나뉘어져 들어간다. 첫번째 &lt;em&gt;real&lt;/em&gt; 에 회전변환이 들어가고, 두번째 &lt;em&gt;dual&lt;/em&gt; 에 위치변환이 들어간다. 그렇게 &lt;em&gt;dual quaternion&lt;/em&gt; 이 구성된다. 또한 각자 &lt;em&gt;dual quaternion&lt;/em&gt; 과 &lt;em&gt;Weight blending&lt;/em&gt; 도 정상적으로 되고(&lt;em&gt;quaternion&lt;/em&gt; 자체가 &lt;em&gt;blending&lt;/em&gt; 이 가능하기 때문이다.) &lt;em&gt;dual quaternion&lt;/em&gt; 끼리 합칠 수도 있고, 정점 변환도 가능하다. 그래서 이 &lt;em&gt;dual quaternion&lt;/em&gt; 을 &lt;em&gt;matrix&lt;/em&gt; 변환과 치환해서 사용이 가능하다.&lt;/p&gt;

&lt;p&gt;또한 앞에서 강조한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상도 어느정도 극복할 수 있다. 그냥 일반적으로 생각해 보았을 때 변환된 정점의 가중치를 곱해 평균값을 구한 것과는 다르게 변환 자체를 전부 합쳐서 한번의 변환으로 변환된 정점을 얻는 것은 조금 다르다고 생각된다. 필자는 Unity 를 사용하여 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 구현했다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;간단하게 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 해결하기 위해선 이 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 사용하면 된다. 하지만 필자는 약 10년전의 기술보다 더 나은 기술이 있을거라 생각해 여러가지 찾아보았다. 그 중 게임에서 쓸 수 있는 스키닝 기법을 하나 발견했다. 그 방법은 다음 글에서 확인해보자. &lt;a href=&quot;/2017/07/22/optimized-center-of-rotation/&quot;&gt;다음 글&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/other/dualQuaternion/&quot;&gt;EuclideanSpace : dual quaternion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://skinning.org/&quot;&gt;Skinning.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 Introduce of skinning 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. Linear Blend Skinning 의 “Candy Wrapper” 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Introduce Of Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/" rel="alternate" type="text/html" title="Introduce Of Skinning" />
      <published>2017-07-07T00:00:00+00:00</published>
      <updated>2017-07-07T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/">&lt;p&gt;2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 &lt;a href=&quot;/2017/05/19/handling-rig-and-skinning/&quot;&gt;handling rig and skinning&lt;/a&gt; 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;일반적으로 3D 물체는 대부분 고정된 정점을 가지고 그대로 그려진다. 물체의 정점들이 한꺼번에 움직이는 방법은 흔하나 정점 하나하나 각자 움직이는 경우는 몇 없다. 모든 정점이 자기만의 기준을 가지고 움직이면 엄청난 계산량을 요구하기 때문이다. 하지만 게임을 만들려면 정점을 움직여서 표현하여 보다 실제적인 움직임을 연출할 수 있을 수도 있다. 극단적인 예를 들면 펄럭이는 옷가지라던가 부서지는 오브젝트가 있겠다. 하지만 방금전에 말한 두가지는 굉장히 극단적인 이야기이고 살아 움직이는 물체를 표현하기 위해 스키닝이라는 기술이 있다. 예를 들면 사람 혹은 동물이 있겠다.&lt;/p&gt;

&lt;p&gt;스키닝이라는 말은 직역하면 &lt;em&gt;“피부를 입히다.”&lt;/em&gt; 라는 뜻이다. 하지만 일반적인 3D 오브젝트는 정해진 정점들을 이어서 삼각형을 만들어 꽤 많은 갯수의 삼각형으로 외형을 표현한다. 이렇게 생각하면 바깥의 피부를 입힌다는 것은 조금 이해가 안될 것이다. 여태까지 엄청나게 많은 이론이 나왔지만 게임에서 쓰이는 3D 모델의 스키닝이라는 용어는 일반적으로 생각하는 뜻이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;정점의 집합으로 이루어진 3D 물체에서 특정한 위치를 가지고 있는 “뼈” 라는 개념이 있다.&lt;/li&gt;
  &lt;li&gt;“뼈” 는 일반적은 3D 오브젝트가 가질 수 있는 변환을 할 수 있다. (Translate, Rotation, Scale)&lt;/li&gt;
  &lt;li&gt;각 정점들은 특정한 “뼈” 를 기준으로 잡아 기준이 되는 “뼈” 의 변환 정보를 각 정점에 적용시켜 뼈가 움직이면 정점도 같이 움직이게 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위에서 설명한 세가지가 적용이 된것이 “스키닝” 이 적용된 3D 물체라고 할 수 있다. 이 간단한 개념이 확장되어 현 시대의 게임에서도 쓰이고 있다. 매우 간단한 이 방법은 약간의 문제가 있다. 관절같은 경우 두개이상의 “뼈” 변환을 참조해야 한다. 어떻게 두개 이상의 “뼈” 변환을 합칠 것인가? 이 문제는 아직까지도 완전히 해결되지 않았고 이 문제를 해결하기 위해 꽤 많은 논문들이 나왔다. 단순히 뼈를 이용하는 방식 뿐만아니라 다양한 방식으로도 말이다. 먼저 가장 널리 알려지고 가장 많이 쓰이는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라는 방법이 있다. 이 방법은 굉~장히 단순하다. 그만큼 많이 쓰이는 듯 싶다. 논문이 1988년에 나온 기술로.. 조금만 잔머리 굴리면 쓸만한 내용이다. 두개 이상의 뼈의 변환 행렬을 정점 위치를 계산하여 정해진 가중치에 비례해서 값을 섞는다. 이 방식은 보통 값과 값사이의 특정한 위치를 가져올때 쓰이는 방법이다. 이 방식은 수학적으로 생각해보면 울퉁불퉁한 곡선에 해당되는게 아니라 선형적으로 값을 보간하는 방법이므로 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라고 불리는 것이다. Unity 의 스키닝된 메쉬를 그리는 &lt;em&gt;Skinned Mesh Renderer&lt;/em&gt; 컴포넌트가 아직도 LBS 를 사용하고 있다. 하지만 이 방법은 흔히 알려진 문제가 하나 있다. &lt;em&gt;‘Candy Wrapper’&lt;/em&gt; - 한국어로 사탕 껍질 이라고 불리는 현상인데, 아래 그림의 사탕 껍질을 이야기 하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/candy_wrapper.jpg&quot; alt=&quot;사탕 껍질&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;주목할 것은 안의 사탕이 아니라 양 옆의 꼬여져서 엄청 가늘어진 상태의 껍질이다. LBS 를 사용하면 해당 오브젝트의 관절이 저렇게 표현될 수 있다. 해당 축으로 180도 돌리면 말이다. 아래 그림에 상세하게 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/umbra-ignite-2015-rulon-raymond-the-state-of-skinning-a-dive-into-modern-approaches-to-model-skinning-33-638.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하여튼 &lt;em&gt;Linear Based Blending&lt;/em&gt; 은 현 시대에서는 그다지 유용한 기술은 아니다. 하지만 많은 곳에서 채택되어 아직도 남아있다. 많은 사람들의 관심이 몰리는 분야는 아니기 때문에 기술 발전 자체는 그다지 빠른편이 아니다. 하지만 30년 전의 기술을 아직도 쓴다는건 그리 좋은 생각은 아닌 것 같다. 이를 위해 10년전에 괜찮은 수 체계를 도입했다. 이는 다음 글에서 설명하겠다. 다음 글 : &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;&lt;em&gt;dual quaternion skinning&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;혹시 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 Unity 구현을 보고 싶으면 &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;GitHub : CustomSkinningExample&lt;/a&gt; 에서 보면 된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 handling rig and skinning 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Translate Gamedev Structured Buffer Vs Constant Buffer</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/" rel="alternate" type="text/html" title="Translate Gamedev Structured Buffer Vs Constant Buffer" />
      <published>2017-07-06T00:00:00+00:00</published>
      <updated>2017-07-06T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/">&lt;p&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt;의 답변 해석 글이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;유저 tsus 의 답변.&lt;/h3&gt;

&lt;p&gt;첫번째로 메모리 액세스가 다르게 작동한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 모든 스레드(역자 : GPU 안의 각각의 코어에서 도는 스레드) 에서 동일한 값을 Warp하게(정확히 뜻을 모르겠다) 접근하면 엄청나게 빠르다. 하지만 스레드 각각 다른 지점(역자 : 장소? 배열의 인덱싱을 말하는 듯 하다)를 접근하면 데이터를 읽는 방식이 직렬화된다. 이 현상은 &lt;em&gt;Constant Waterfalling&lt;/em&gt; 이라고 불리며 읽는 속도를 굉장히 느리게한다. 이는 뼈 애니메이션(역자 : 스키닝)을 하려는 사람들에게 두통을 유발한다. 설명한 세가지 시나리오 중 마지막 시나리오를 빼고 전부 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 &lt;em&gt;cbuffer&lt;/em&gt; 와 다르게 &lt;em&gt;통합 캐시 구조&lt;/em&gt; 를 사용하여 최적화했다. &lt;em&gt;통합 캐시 구조&lt;/em&gt; 는 첫번째 읽는 속도는 느리지만 뒤에 같은 데이터를 다시 읽는 것은 빠르다는 것이다.(물론 캐싱된 경우를 뜻한다.)&lt;/p&gt;

&lt;p&gt;두번째로 사용이 제한되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 특수 레지스터에 존재하기 때문에 굉장히 빠르다. 하지만 레지스터의 크기는 64kb 로 굉장히 작다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 레지스터에 저장되지 않으므로 더 많은 공간을 사용할 수 있다. 즉 저장된 데이터가 많아지면 &lt;em&gt;StructedBuffer&lt;/em&gt; 를 사용해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 렌더링 파이프 라인 어느 지점에서도 바인딩 할 수 없다.(역자 : 바인딩의 뜻을 모름니다;) 이는 정점 버퍼처럼 취급되지 않는다는 것을 뜻한다. DirectX10 의 하드웨어는 임의의 접근을 통한 쓰기를 타입을 가진 리소스(텍스쳐, 정점 버퍼)에 지원하지 않기 때문에 DirectCompute 를 DirectX10 에서 지원했다. 그래서 모든 쉐이더 단계에서 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 읽을 수 있게 되었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 숨겨진 꿀(?) 기능이 있다.(역자 : 그다지 꿀인지는 모르겠는데..) 접근한 스레드의 갯수를 세서 다른 여러 스레드에서 접근하게 해주는 &lt;em&gt;“hidden counter”&lt;/em&gt; 라는 기능이다. 게다가 이 카운터는 &lt;em&gt;ByteAddressBuffer&lt;/em&gt; 에 &lt;em&gt;interlockedAdd&lt;/em&gt; 를 사용하는 것 보다 조금 빠르다. &lt;em&gt;ByteAddressBuffer&lt;/em&gt; 는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 와는 다르게 형식이 정해져 있지 않아 어디에든지 바인딩이 될 수 있는 버퍼다.&lt;/p&gt;

&lt;h3&gt;운영자 MJP 의 답변&lt;/h3&gt;

&lt;p&gt;“Constant” 라는 단어는 쉐이더 프로그램이 실행될 동안 값이 일정하다는 것을 나타내며 CPU 값을 변경할 수 없다는것은 아니다. 이 단어는 DX10 이전에 나온 단어로써 쉐이더에 정의된 소수의 상수를 &lt;em&gt;Shader Constants&lt;/em&gt; 라고 했을 때 나온 단어다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Constant Buffer&lt;/em&gt; 는 작은 양의 원하는(역자 : heterogeneous 라고 표기하는데 이해가 안됨.) 값들을 쉐이더에서 이름을 가지게 하여 직접 접근하게 하려는 목적을 가지고 있다. 그래서 첫번째 예의 &lt;em&gt;View Matrix&lt;/em&gt; 와 &lt;em&gt;Projection Natrix&lt;/em&gt; 를 가지는 예제는 &lt;em&gt;Constant Buffer&lt;/em&gt; 에 완벽하게 어울린다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 구조체 배열과 같이 원하는 구조체의 배열을 뜻한다. 그래서 인덱스로 여러개를 접근할만한 데이터가 있다면 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 사용하는 걸 원할 것이다. 3번째로 예를든 조명 리스트는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 사용하기 좋다.&lt;/p&gt;

&lt;p&gt;DOF 쉐이더는 둘다 사용가능하다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 쓰고 데이터를 반복해서 읽으면 조금 부담스럽지만 가능은 하다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 읽기 동작을 계속 반복하지만, 정적 &lt;em&gt;cbuffer&lt;/em&gt; 읽기 동작은 더 최적화 되어있다. 정적 &lt;em&gt;cbuffer&lt;/em&gt; 읽기는 반복문이(Loop) 없어야 한다. Loop 가 존재하면 다른 쉐이더의 순열(역자 : permutations 라고 적혀있음, 의역 불능)이 필요할 수도 있다.&lt;/p&gt;

&lt;p&gt;어쨋든 현대 GPU 하드웨어는 일반적으로 동작하며, API 에서 제공하는 추상화간에 큰 차이는 거의 없다. 하드웨어가 덜 유연한 DX9 포함 이전 버젼의 GPU 들과는 많이 다르다. 다만 적절한 성능을 찾고싶다면 프로파일링을 해야한다.&lt;/p&gt;

&lt;p&gt;보통 프로그래머의 관점에서는 &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 비슷하게 보인다. 하지만 두 버퍼는 꽤 중요한 차이점이 있다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="translate" />
      
        <category term="try" />
      

      

      
        <summary type="html">GameDev : structured buffer vs constant buffer의 답변 해석 글이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Structured Buffer Vs Constant Buffer</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer/" rel="alternate" type="text/html" title="Structured Buffer Vs Constant Buffer" />
      <published>2017-07-06T00:00:00+00:00</published>
      <updated>2017-07-06T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer/">&lt;p&gt;CG 로 쉐이더 코딩을 하기 위해 여러 소스와 웹페이지를 뒤지던 도중 재미있는 글을 발견했다. HLSL 에서 사용하는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 와 &lt;em&gt;Constant Buffer&lt;/em&gt; 의 차이에 대한 글이였다. Unity 메뉴얼을 따라가면서 몇번 보긴했지만 무슨 차이인지도 모르는 것들이였다. 하지만 알고나니 GPU Instancing 에 대한 기본적인 상식이기에 글을 쓴다. 우선 두가지를 먼저 간단하게 알아보고 두 개념의 차이에 대해서 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;&lt;em&gt;Constant Buffer&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;이름을 직역하면 상수 버퍼다. 직관적인 느낌은 단순한 고정값 참조를 위한 버퍼인 것 같다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509581%28v=vs.85%29.aspx&quot;&gt;MSDN : Shader Constants&lt;/a&gt; 페이지에서 자세한 정보를 확인할 수 있다. 문서의 내용은 &lt;em&gt;Shdaer Model 4&lt;/em&gt; (DirectX10 이 &lt;em&gt;Shdaer Model 4&lt;/em&gt; 를 지원함.) 부터 쉐이더에서 쓰이는 상수(쉐이더 코드에서 변화시키지 않는 변수, 이하  &lt;em&gt;Shader Constants&lt;/em&gt;) 전용 버퍼 리소스를 제공한다고 한다. &lt;em&gt;Shader Constants&lt;/em&gt; 의 장점은 변경되지 않는 특징을 사용해 CPU 로 부터 낮은 시간으로 더 많이 업데이트를 받을 수 있다는 장점이 있다. 단점은 빠른만큼 제약조건이 여러개 있다는 것이다. 데이터의 크기는 정해져 있어야 하며 일정 크기를 넘기지 못한다. 그리고 데이터의 레이아웃(데이터를 정의하는데에 한계가 있는 듯하다. 필자는 정확히 모름)과 데이터를 접근할 때 한 쉐이더에서만 접근이 가능하다. 정점 쉐이더면 정점 쉐이더 전용, 프래그먼트 쉐이더면 프래그먼트 전용 상수 버퍼를 쓸 수 있다는 말이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shader Constants&lt;/em&gt; 는 두가지의 데이터의 형태를 지원하는데 하나는 위에서 언급한 &lt;em&gt;Constant Buffer&lt;/em&gt;(&lt;em&gt;cbuffer&lt;/em&gt;) 이고 하나는 &lt;em&gt;Texture Buffer&lt;/em&gt;(&lt;em&gt;tbuffer&lt;/em&gt;) 라는 놈이다. &lt;em&gt;tbuffer&lt;/em&gt; 는 텍스쳐처럼 접근 가능하다고 한다. 이 말은 뒤에 쓰여진 말을 생각해보면 이해할 수 있다. 임의로 인덱싱된 데이터에 대해 더 잘 수행된다고 쓰여있는데 이 말은 배열처럼 인덱스 단위로 바로바로 접근이 가능해서 랜덤으로 인덱스를 정해서 접근해도 잘 접근이 되야된다는 소리다. &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;tbuffer&lt;/em&gt; 의 갯수 제한은 없다. 각각의 크기 제한만 있을 뿐이다. 이 두가지 버퍼를 선언하는 방법은 C 언어의 구조체를 선언하는 법과 매우 유사하다고 한다. 정말 그렇다. 또한 직접 레지스터에 데이터를 넣고 싶거나, 데이터의 패킹 오프셋(C 언어에서는 padding 이라는 단어로 알려져 있다.) 을 설정할 수도 있다. 다만 Shader 에서는 1바이트가 기본이 아닌 16바이트 패킹이 기본이다. 16바이트 중 4바이트 단위로 접근을 할 수 있다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 GPU Instancing 기본 예제를 DirectX 의 경우에는 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용하게 한다. 아래처럼 선언하게 되어 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;UNITY_INSTANCING_CBUFFER_START(_CBufferName)
  ...
UNITY_INSTANCING_CBUFFER_END
&lt;/code&gt;&lt;/pre&gt;
&lt;!--__ --&gt;
&lt;p&gt;전처리가 끝나서 HLSL 식으로 컨버팅되면 아래와 같이 된다. Unity 에서 제공하는 쉐이더 코드를 참조했다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;cbuffer _CBufferName {
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unity 에서 제공하는 예제는 단순하게 컬러값을 인스턴스별로 바꾸게 해주는 그리하여 여러개의 메터리얼을 사용하지 않아 쓸데없는 &lt;em&gt;SetPass&lt;/em&gt; 를 안하게 해주는 예제다. 이 값들은 쉐이더에서 변경할 필요가 없는 상수 값이므로 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용해도 문제가 없다.&lt;/p&gt;

&lt;p&gt;하지만 필자는 &lt;a href=&quot;/2017/06/08/performence-and-optimization/&quot;&gt;Appocrypha : GPU Instancing&lt;/a&gt; 글에서 &lt;em&gt;cbuffer&lt;/em&gt; 가 추구하는 방향과는 조금 다르게 사용했다. 저 글을 쓸때 한창 스키닝에 대해 관심이 많았기 때문에 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용해서 각 뼈들의 위치와 회전 데이터들을 사용했다. 하지만 저 사용용도는 그다지 좋지 않은 생각이였다. 이유는 글의 끝에서 말하겠다.&lt;/p&gt;

&lt;h2&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;다음으로 알아볼 것은 &lt;em&gt;StructuredBuffer&lt;/em&gt; 다. 이 역시 맨 처음 등장한 것은 &lt;em&gt;Shader Model 4&lt;/em&gt; 부터 등장했다. 초기에는 사용 용도가 약간 한정되어 있는 것처럼 나온다. &lt;em&gt;Shader Model 4&lt;/em&gt; 에서는 읽기 전용의 버퍼만 지원하고, 버퍼의 종류가 적었다. 또한 사용 용도가 컴퓨터 쉐이더와 픽셀 쉐이더로 한정 되어 있었다고 한다. &lt;em&gt;Shader Model 5&lt;/em&gt; 부터는 다양한 변종의 버퍼들을 지원하고, 모든 쉐이더 코드에서 사용이 가능하게 되었다. 이는 쉐이더 코딩의 여러 가능성을 열어 주었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 &lt;em&gt;cbuffer&lt;/em&gt; 의 정의처럼 정적으로 명세를 지정했던 방식과는 다른 데이터를 접근하는 방식이다. &lt;em&gt;cbuffer&lt;/em&gt; 는 정해진 크기의 변수만 접근이 가능했다. 하지만 &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 데이터를 쉐이더 코드에서 전역변수로 길이에 상관없는 리스트 형식으로 인덱스를 사용해 접근할 수 있는 데이터 형식이다. 사용하자면 아래와 같이 사용할 수 있겠다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;
struct vertex
{
  float3 position;
  float3 normal;
}

StructuredBuffer&amp;lt;vertex&amp;gt; perVertexDataBuffer;

v2f vert (uint vertexID : SV_VertexID)
{
  vertex v = perVertexDataBuffer[vertexID];

  ...

  return someData;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Shader Model 5&lt;/em&gt; 에서는 쓰기도 가능한 &lt;em&gt;RWStructuredBuffer&lt;/em&gt; 와 단순한 데이터 한개씩 저장하는 &lt;em&gt;Buffer&lt;/em&gt;, &lt;em&gt;RWBuffer&lt;/em&gt; 등 특이한 다른 컨테이너도 지원해서 꽤나 재미있는 코딩이 가능할 듯 하다.&lt;/p&gt;

&lt;h2&gt;결론?&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 의 장단점에 대해서는 말하지 않았다. MSDN 에서도 그다지 자세하게 쓰여있지는 않다. 사실 필자도 그다지 관심이 없었다. 그냥 있으면 있는대로 쓰는거지 라는 생각을 당분간 하다가 문득 의문이 들었다. 도대체 무슨 차이길래 다르게 지원하는 것인가에 대한 의문이였다. 그래서 &lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt; 을 찾아 읽었고 꽤나 흥미로운 사실이였다. &lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;원문 링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;질문글은 &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;StructuredBuffer&lt;/em&gt; 의 차이점에 대한 데이터가 없어 무슨 차이 인지, 그리고 3가지의 예시를 들어 각각 어떤게 더 알맞는지에 대한 구체적인 글이였다. 글또한 꽤나 잘쓰여져 있지만 질문글 보다 더욱더 봐야할 것은 아래에 달린 답글 2개다. 일반적으로 알기 힘든 사실들을 다루고 있다. 하나의 글은 두 버퍼의 차이에 대하여 써놨으며 하나의 답글은 질문글의 핀트에 맞추어 답글을 써놓았다. 해당 글의 답변 해석은 블로그에 올려놓았다. &lt;a href=&quot;/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/&quot;&gt;글 링크&lt;/a&gt; 에서 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 레지스터를 사용하여 작으나 빠르고, 배열을 각각 다른 스레드에서 전부 다른 인덱스로 접근하면 느려진다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 조금은 느리나 내부적으로 thread-safe 하게 구현되어 있고, 데이터 캐싱을 한다. 또한 크기의 제한이 없어 자유롭게 쓰고, 크기가 입력에 따라서 달라져서 유동적인 데이터에 쓸만하다는 것이다. 위에서 스키닝을 &lt;em&gt;cbuffer&lt;/em&gt; 로 사용한게 문제라고 했었는데, 글을 보면 알겠지만 &lt;em&gt;cbuffer&lt;/em&gt; 에서 각각 다른 인덱스로 접근하면 느려지니 문제인 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509581%28v=vs.85%29.aspx&quot;&gt;MSDN : Shader Constants&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471514%28v=vs.85%29.aspx&quot;&gt;MSDN Reference : StructuredBuffer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff476335%28v=vs.85%29.aspx&quot;&gt;MSDN : New Resource Types&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="gpuinstancing" />
      
        <category term="try" />
      

      

      
        <summary type="html">CG 로 쉐이더 코딩을 하기 위해 여러 소스와 웹페이지를 뒤지던 도중 재미있는 글을 발견했다. HLSL 에서 사용하는 StructuredBuffer 와 Constant Buffer 의 차이에 대한 글이였다. Unity 메뉴얼을 따라가면서 몇번 보긴했지만 무슨 차이인지도 모르는 것들이였다. 하지만 알고나니 GPU Instancing 에 대한 기본적인 상식이기에 글을 쓴다. 우선 두가지를 먼저 간단하게 알아보고 두 개념의 차이에 대해서 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Gpu Instancing In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity/" rel="alternate" type="text/html" title="Using Gpu Instancing In Unity" />
      <published>2017-06-11T00:00:00+00:00</published>
      <updated>2017-06-11T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity/">&lt;p&gt;&lt;strong&gt;이 글은 Unity 5.6.1f 버젼에서 작성되었습니다. 다른 버젼에서는 에러가 날 수 있으니 참고 바랍니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2017/06/04/using-texture2darray-in-unity/&quot;&gt;Using Texture2DArray in Unity&lt;/a&gt; 에 이어 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄이기 위한 방법에 대해서 소개하려한다. GPU Instancing 이라는 방법인데 &lt;em&gt;TextureArray&lt;/em&gt; 와 같이 응용해서 사용하면 획기적으로 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;일반적으로 알려진 &lt;em&gt;GPU Instancing&lt;/em&gt; 에 대해서 말하자면 컴퓨터의 RAM 에만 저장하던 데이터들을 GPU 메모리에 복사해놓고 GPGPU 나 쉐이더를 실행할 때 빠르게 데이터에 접근하는 것을 GPU Instancing 이라 한다. 만약 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용하지 않으면 매번 &lt;em&gt;DrawCall&lt;/em&gt; 에 데이터를 넣어줘야하기 때문에 수많은 &lt;em&gt;DrawCall&lt;/em&gt; 이 걸리게 되고 이는 CPU 의 시간을 뺏어먹게 되어 영 좋지 않은 일이 된다. 보통은 같은 동작을 하는 오브젝트들을 최적화할 때 쓰인다. 사용하게 되면 &lt;em&gt;DrawCall&lt;/em&gt; 이 &lt;em&gt;O(&lt;strong&gt;오브젝트 갯수&lt;/strong&gt;)&lt;/em&gt; 로 되던것이 O(1) 의 갯수로 줄어든다. 그래서 &lt;em&gt;TextureArray&lt;/em&gt; 와 같이 사용하게 되면 &lt;em&gt;DrawCall&lt;/em&gt; 이 &lt;em&gt;O(&lt;strong&gt;오브젝트 갯수&lt;/strong&gt; * &lt;strong&gt;텍스쳐 갯수&lt;/strong&gt;)&lt;/em&gt; 로 계산되던게 &lt;em&gt;O(&lt;strong&gt;1&lt;/strong&gt;)&lt;/em&gt; 로 바뀌어 버리니 CPU 시간을 엄청나게 많이벌 수 있다. 다만 GPU 메모리를 많이 잡아먹기 때문에 신경써서 데이터를 구성하지 않으면 무슨일이 일어날지 모른다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;기술을 써보기 전에 우선 구현 사항부터 생각해야 한다. 필자는 Unity 에서 지원하는 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 가 &lt;em&gt;DrawCall&lt;/em&gt; 배칭을 해주지 않아 간단한 스키닝을 직접 구현하였다. &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 가 많은 기능을 지원하긴 하지만 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 컴포넌트의 갯수가 절대적으로 많아지고 매터리얼이 늘어나게 되면 어쩔 수 없이 원하는 기능을 붙여 직접 구현해야 한다. &lt;a href=&quot;git@github.com:hrmrzizon/InstancedSkinningExmaple.git&quot;&gt;InstancedSkinning&lt;/a&gt;에서 참고할 수 있다.&lt;/p&gt;

&lt;p&gt;해야할 것은 두가지다. 쉐이더에서 데이터를 선언 후 직접 사용하는 코드를 짜주어야 하고, 스크립트에서는 필요한 데이터를 모아서 넣어주기만 하면 된다. 말로는 간단하지만 신경써주어야 할것이 많다. 필자 역시 간단하다고 생각하여 시작했으나 꽤 많은 삽질 끝에 성공했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GPU Instancing&lt;/em&gt; 의 핵심은 GPU 메모리에 어떤 데이터들을 어떻게 옮겨놓고 그 데이터들을 어떻게 사용하느냐가 제일 핵심이다. 스크립트에서는 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스를 통해 데이터를 한꺼번에 세팅하고 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드를 호출해 그린다. 보통은 매 프레임별로 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 호출하기 때문에 적당히 코딩이 되어있다면 필요할때마다 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스에 데이터를 갱신해주기만 하면 된다. &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 은 쉐이더에 들어가는 정보들을 취급하는 데이터 뭉치(chunk)다. &lt;strong&gt;Material&lt;/strong&gt; 은 쉐이더 정보와 필요한 데이터를 가지고 있는 인스턴스다. 쉐이더 정보를 가지고 있기 때문에 매터리얼의 갯수가 많으면 많을수록 &lt;em&gt;DrawCall&lt;/em&gt; 의 갯수가 늘어난다. 하지만 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 은 &lt;strong&gt;Material&lt;/strong&gt; 과는 다르게 정보만 가지고 있는 것이기 때문에 &lt;em&gt;DrawCall&lt;/em&gt; 의 갯수가 늘어나지 않는다. &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 관한 자세한 사용법은 &lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/MaterialPropertyBlock.html&quot;&gt;Unity Reference : MaterialPropertyBlock&lt;/a&gt; 을 참고하라.&lt;/p&gt;

&lt;p&gt;아 그러면 쉐이더는 어디서 정의하냐고? &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드는 &lt;strong&gt;Material&lt;/strong&gt; 과 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 둘다 필요하다. 적당히 데이터를 분리해서 취급하면 된다. 아래 그리는 코드를 살펴보자. &lt;a href=&quot;https://github.com/hrmrzizon/InstancedSkinningExmaple/blob/master/Assets/2%20-%20InstancedSkinning/CharacterSet.cs&quot;&gt;InstancedSkinning - CharacterSet&lt;/a&gt; 에서 간추려서 가져왔다.&lt;/p&gt;

&lt;div class=&quot;language-csharp highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CharacterData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DrawData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drawDataDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drawDataDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;GetEnumerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;MoveNext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DrawData&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;UpdateMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;UpdateMaterialblcok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Graphics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;DrawMeshInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;material&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mainMatrixList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;castShadow&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;UnityEngine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Rendering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ShadowCastingMode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;On&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;UnityEngine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Rendering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ShadowCastingMode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;receiveShadow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;drawLayerNumber&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;drawCamera&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Material&lt;/strong&gt; 인스턴스는 단 한개이며 &lt;strong&gt;Texture2DArray&lt;/strong&gt; 를 사용해 모든 텍스쳐를 하나로 합쳐 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄였다. &lt;strong&gt;DrawData&lt;/strong&gt; 는 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드 호출을하기 위한 구조체 데이터다. 기본적으로 물체를 그릴때 필요한 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스와 각 그려야할 인스턴스 별로 필요한 변환행렬들을 가지고 있는 &lt;em&gt;DrawData.mainMatrixList&lt;/em&gt;, 필요한 데이터를 저장하고 있는 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스 &lt;em&gt;DrawData.block&lt;/em&gt; 을 가지고 있다. &lt;em&gt;DrawData.UpdateMaterialblcok&lt;/em&gt; 메소드는 필요한 데이터들을 &lt;em&gt;DrawData.block&lt;/em&gt; 에 넘겨주는 메소드다.&lt;/p&gt;

&lt;p&gt;여기까지 스크립트에서 해주어야할 것들에 대해 말했다. 필요한 데이터들을 준비하고 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 로 한꺼번에 그려주는게 핵심이다. 이제 쉐이더 코딩에 대해 알아보자. Unity 에서의 쉐이더 코딩은 굉장히 복잡하다. Unity 는 여러 플랫폼을 위한 엔진이기 때문에 여러 플랫폼, Graphics API 에 대한 세팅이 필요하며 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용할 때 약간의 애로사항이 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용할 때 결국 데이터는 전부 배열로 들어오게 된다. 각종 쉐이더 언어(HLSL, GLSL)에서 지원하는 &lt;em&gt;instanceID&lt;/em&gt; 라는 배열에 접근하기 위한 인덱스가 있다. 이 인덱스에 접근하는 기능을 여러 플랫폼과 Graphics API 지원을 위해 해당 기능을 전처리기 구문으로 감싸놓았는데 Unity 엔진 사용자는 접근을 할수가 없다. 즉 배열의 인덱스에 직접 접근이 불가능하다는 것이다. 이렇게 되면 깔끔하게 코딩이 안되서 굉장히 불편할 뿐만 아니라 데이터도 효율적으로 쓰지 못한다.&lt;/p&gt;

&lt;p&gt;또한 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용하려면 옵션을 하나 붙여주어야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#pragma exclude_renderers d3d9 gles d3d11_9x
#pragma only_renderers d3d11 glcore gles3 metal vulkan

#pragma multi_compile_instancing

#include &quot;UnityCG.cginc&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위와 같이 &lt;em&gt;UnityCG.cginc&lt;/em&gt; 파일을 포함하기 전에 전처리기 옵션 : &lt;em&gt;multi_compile_instancing&lt;/em&gt; 을 붙여주어야 한다. 저 옵션을 안붙이게 되면 컴포넌트 렌더러(&lt;strong&gt;MeshRenderer&lt;/strong&gt;, &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt;)에서 개별로 쓰이는 쉐이더만 컴파일하게 되는데 그 상태에서 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용하게 되면 아예 렌더링이 되지 않는다. 그래서 &lt;em&gt;GPU Instancing&lt;/em&gt; 에 필요한 쉐이더도 동시에 컴파일 하라는 옵션이 &lt;em&gt;multi_compile_instancing&lt;/em&gt; 옵션이다.&lt;/p&gt;

&lt;p&gt;해당 옵션위에 다른 옵션들이 쓰여져 있는데 directX9 버젼이나 OpenGL ES 2.X 버젼에서는 제대로된 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용하지 못하므로 &lt;em&gt;exclude_renderers&lt;/em&gt; 에 명시된 Graphics API 에서 돌아가는 쉐이더는 컴파일하지 말라는 옵션으로 생각하며 된다. 또한 동시에 &lt;em&gt;only_renderers&lt;/em&gt; 옵션도 사용했는데 이는 해당 Graphics API 를 위한 쉐이더만 컴파일하라는 옵션이다. 보통 두가지를 동시에 쓰지는 않지만 정확한 명시를 위해 적어놓았다. 이제 쉐이더 프로그램에서 인스턴싱된 버퍼들을 사용하는 방법과 편법에 대해서 알아보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;struct a2v
{
	float3 uv : TEXCOORD0;
	float4 vertex : POSITION;
	UNITY_VERTEX_INPUT_INSTANCE_ID
};

struct v2f
{
	float4 vertex : SV_POSITION;
	float2 uv : TEXCOORD0;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;여기서 주목할 것은 a2v 구조체에 있는 &lt;em&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/em&gt; 매크로다. 이는 각 쉐이더 별로 &lt;em&gt;instanceID&lt;/em&gt; 를 정의해주는 매크로 인데, 역시나 여러 플랫폼을 위해 전처리기로 처리 되어있다. 그리고 a2v 는 버텍스 쉐이더에 들어가는 인자를 구조체로 묶어놓은 것인데 만약 프래그먼트 쉐이더에서 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 하려면 인자로 들어가는 v2f 구조체에 &lt;em&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/em&gt; 매크로의 정의가 필요할 것이다. 이 쉐이더는 필요가 없어 넣지 않은 상태이다. 이제 버퍼들을 정의하고 사용하는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#define UNITY_MAX_INSTANCE_COUNT 100

UNITY_INSTANCING_CBUFFER_START(_BonePositions)
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition0);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition1);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition2);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition3);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition4);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition5);
UNITY_INSTANCING_CBUFFER_END

float4 GetPosition(uint index)
{
	switch(index)
	{
		case 0:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition0);
		case 1:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition1);
		case 2:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition2);
		case 3:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition3);
		case 4:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition4);
		case 5:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition5);
	}

	return float4(1, 1, 1, 1);
}

UNITY_INSTANCING_CBUFFER_START(_BoneMatrixs) /* 위 선언와 비슷함 */ UNITY_INSTANCING_CBUFFER_END

float4x4 GetMatrix(uint index) { /* 위 함수와 비슷함 */ }

v2f vert (a2v v)
{
	v2f o;

	UNITY_SETUP_INSTANCE_ID(v);

	uint boneIndex = v.uv[2];

	float4 pos = GetPosition(boneIndex);

	o.vertex = UnityObjectToClipPos(
					mul(
						GetMatrix(boneIndex),
						float4(v.vertex.xyz - pos.xyz,1)
					)
					+
					float4(pos.xyz, 0)
				);
	o.uv = v.uv.xy;

	return o;
}
&amp;lt;!-- __) --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;우선 데이터를 저장할 버퍼를 선언해야 한다. 이는 GPU 메모리에 저장되는 버퍼인데 DirectX 에서는 &lt;em&gt;constant buffer&lt;/em&gt; 라고 하고, OpenGL 에서는 &lt;em&gt;uniform buffer object&lt;/em&gt; 라고 한다. 하여튼 이렇게 선언되는 버퍼에 들어가는 정보는 &lt;strong&gt;Material&lt;/strong&gt; 이나 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 저장한 정보들에서 똑같은 변수이름을 가진 변수에게 저장된다. 보통은 쉐이더의 &lt;em&gt;Properties&lt;/em&gt; 에 선언된 변수들은 &lt;strong&gt;Material&lt;/strong&gt; 에 저장하고, 버퍼 오브젝트들은 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 저장된 데이터와 맞춰준다. 둘의 사용용도가 거의 일치하기 때문이라고 보면된다.&lt;/p&gt;

&lt;p&gt;선언하는 방법은 간단하다. &lt;em&gt;UNITY_INSTANCING_CBUFFER_START&lt;/em&gt;, &lt;em&gt;UNITY_INSTANCING_CBUFFER_END&lt;/em&gt; 로 정의할 영역을 정해주고 그 안에 필요한 데이터들을 &lt;em&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/em&gt; 구문을 사용하여 정의해주면 된다. &lt;em&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/em&gt; 구문에는 자료형과 이름을 써주면 알아서 정의가 된다. 이 역시 HLSL 과 GLSL 로 알아서 컨버팅 되도록 한것이다. 그리고 해당 변수에 접근할 때는 &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 를 사용하여 접근하면 된다.  이렇게 해주면 &lt;em&gt;multi_compile_instancing&lt;/em&gt; 때문에 일반적인 컴포넌트 렌더러에서 쓰는 쉐이더와 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 에서 쓰는 쉐이더로 알아서 컴파일된다. &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 로 접근을 한 이유도 여기에 있다. &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용할때는 배열에 접근해야 하고, 컴포넌트 렌더러를 사용할때는 단순 인스턴스에 접근해야한다. 즉 배열의 인덱스로 접근하기위해 &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 를 사용한다고 보면된다.&lt;/p&gt;

&lt;p&gt;근데 위 코드처럼 인스턴싱을 많이하게 되면 아래와 같은 에러를 띄우면서 컴파일이 안될때가 있다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Can't continue validation - aborting. (on d3d11)
Index Dimension 2 out of range (12000 specified, max allowed is 4096) for operand #1 of opcode #5 (counts are 1-based). Aborting. (on d3d11)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;그래서 위 코드에서 바꿔준 것이 맨 위에있는 전처리기 정의 구문이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#define UNITY_MAX_INSTANCE_COUNT 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이는 약간 HACK 한 방식으로 커스터마이징을 한것이다. &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 에서 쓰이는 쉐이더는 배열로 변수들을 선언하는데 기본 배열의 길이가 500 이다. 물론 모바일 같은 플랫폼에서는 4를 나누어줘서 125 이긴 하지만 PC 대상으로 컴파일하면 정의한 변수 한개당 500개씩 정의가 되서 변환 행렬덕분에 엄청난 메모리를 먹게된다. 그리고 배열 아이템의 갯수 4096 개를 초과해서 에러가 나는 것이다. 그래서 전처리기로 처리한 것에 약간의 편법을 써서 &lt;em&gt;UNITY_MAX_INSTANCE_COUNT&lt;/em&gt; 를 필요할때마다 정의해주면 배열의 크기를 맘대로 조정할 수 있다. 위의 코드는 에러를 막기위해 임시적으로 조절한 것이지만 참조한 인스턴스의 갯수가 적으면 직접 조정해주는 편이 낫다. 물론 인덱스를 벗어나지 않는 범위에서 말이다. 이 방법은 Unity 사이트에서 built-in 쉐이더를 받아 확인하여 코딩하였다.&lt;/p&gt;

&lt;p&gt;그리고 굳이 배열로 선언하고 싶지 않고 한번 실행하는 쉐이더당 한개의 변수만 필요한 경우 아래와 같이 단순하게 정의해주면 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;UNITY_INSTANCING_CBUFFER_START(_FragmentBuffer)
	float _TextureIndex;
UNITY_INSTANCING_CBUFFER_END

UNITY_DECLARE_TEX2DARRAY(_MainTexArray);

fixed4 frag (v2f i) : SV_Target
{
	fixed4 col = UNITY_SAMPLE_TEX2DARRAY(_MainTexArray, float3(i.uv, _TextureIndex));
	return col;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;!-- ___)(____) --&gt;

&lt;p&gt;저렇게 하면 단순하게 사용할 수 있다. 물론 컴파일 에러는 안난다. 해당 코드는 &lt;a href=&quot;https://github.com/hrmrzizon/InstancedSkinningExmaple&quot;&gt;Github : InstancedSkinningExmaple&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;자세한 방법은 &lt;a href=&quot;https://docs.unity3d.com/Manual/GPUInstancing.html&quot;&gt;Unity Manual : GPU Instancing&lt;/a&gt; 에 적혀있으니 참고하길 바란다. 글을 쓰는 현재 2017년 6월 12일에는 한글 문서는 존재하지도 않는다. 영어로 읽어야한다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/GPUInstancing.html&quot;&gt;Unity Manual : GPU Instancing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/CassEveritt/approaching-zero-driver-overhead&quot;&gt;Slideshare : Approach Zero Driver Overhead&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/MaterialPropertyBlock.html&quot;&gt;Unity Reference : MaterialPropertyBlock&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">이 글은 Unity 5.6.1f 버젼에서 작성되었습니다. 다른 버젼에서는 에러가 날 수 있으니 참고 바랍니다. Using Texture2DArray in Unity 에 이어 DrawCall 을 줄이기 위한 방법에 대해서 소개하려한다. GPU Instancing 이라는 방법인데 TextureArray 와 같이 응용해서 사용하면 획기적으로 DrawCall 을 줄일 수 있다. 일반적으로 알려진 GPU Instancing 에 대해서 말하자면 컴퓨터의 RAM 에만 저장하던 데이터들을 GPU 메모리에 복사해놓고 GPGPU 나 쉐이더를 실행할 때 빠르게 데이터에 접근하는 것을 GPU Instancing 이라 한다. 만약 GPU Instancing 을 사용하지 않으면 매번 DrawCall 에 데이터를 넣어줘야하기 때문에 수많은 DrawCall 이 걸리게 되고 이는 CPU 의 시간을 뺏어먹게 되어 영 좋지 않은 일이 된다. 보통은 같은 동작을 하는 오브젝트들을 최적화할 때 쓰인다. 사용하게 되면 DrawCall 이 O(오브젝트 갯수) 로 되던것이 O(1) 의 갯수로 줄어든다. 그래서 TextureArray 와 같이 사용하게 되면 DrawCall 이 O(오브젝트 갯수 * 텍스쳐 갯수) 로 계산되던게 O(1) 로 바뀌어 버리니 CPU 시간을 엄청나게 많이벌 수 있다. 다만 GPU 메모리를 많이 잡아먹기 때문에 신경써서 데이터를 구성하지 않으면 무슨일이 일어날지 모른다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Performence And Optimization</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/08/performence-and-optimization/" rel="alternate" type="text/html" title="Performence And Optimization" />
      <published>2017-06-08T00:00:00+00:00</published>
      <updated>2017-06-08T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/08/performence-and-optimization</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/08/performence-and-optimization/">&lt;p&gt;일반적인 응용 프로그램들은 중간중간에 잠시 멈춰도 원하는 결과를 유저에게 보여주면 상관이 없다. 하지만 게임은 ‘게임중’ 에는 어떤 경우에도 렉을 허용하지 않는다. 그만큼 ‘게임중’ 상태에서 렉을 아예 발생시키지 않는 것이 게임 프로그래머의 중요한 능력중 하나다.&lt;/p&gt;

&lt;p&gt;게임은 일반적으로 1초에 60번 이상 업데이트하는 루틴을 유지해야 유저에게 원활한 환경을 제공한다. 여기서 급작스럽게 프레임수가 하락하면 그때 유저들은 순간적으로 끊기거나 부드럽지 않은 경험을 하게된다. 유저들은 그런 것들을 랙으로 통칭한다. 랙이 반복되면 유저들은 게이밍 환경에 불만을 느끼게 된다.&lt;/p&gt;

&lt;p&gt;일반적인 랙은 프로그래머의 실수인 경우가 많다. 런타임에서 많은 것을 한꺼번에 처리하는 경우가 대표적이다. 하지만 이는 여러 리팩토링을 거치면 충분히 해결할 수 있다. 경험이 적은 사람들에게 가장 문제가 되는 것은 엔진을 사용하는 방법이 문제가 되는 경우가 많다. 엔진의 자세한 구현 사항을 파악하지 못했기 때문에 한계를 생각하지 않고 코딩하는 경우 말이다. 몇가지 사항들만 주의하며 코딩한다면 꽤 많은 병목들을 피해갈 수 있다.&lt;/p&gt;

&lt;p&gt;이제 Unity 엔진을 사용할 때 퍼포먼스에 영향을 끼치는 것들과 해결 방안에 대해서 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;만들어진 소프트웨어를 최대한 플랫폼의 자원을 덜 소모하고 빠르게 작업을 수행하게하는 것을 “최적화를 한다” 라고 한다. 게임이라는 소프트웨어의 최적화는 보통 게임 플레이 시간에 매 프레임 별로 최대한 시간을 덜 소모하게 하는 것을 일반적으로 여겨진다.&lt;/p&gt;

&lt;p&gt;그래서 Unity 는 게임 플레이 시간동안 걸리는 작업들의 시간을 측정하는 툴을 지원한다. 이름은 &lt;em&gt;Profiler&lt;/em&gt; 라고 한다. &lt;em&gt;Profiler&lt;/em&gt; 를 통해 시간이 많이 걸리는 부분을 찾을 수 있다. &lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/ProfilerWindow.html&quot;&gt;Unity 메뉴얼&lt;/a&gt;에서 자세한 사용법을 확인하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.unity3d.com/kr/current/uploads/Main/ProfilerTimeline.png&quot; alt=&quot;Unity Profiler&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 일반적인 CPU 시간을 잴 때 사용하는 모드로써 위에서 언급한 스크립트의 실행시간을 체크할 때 쓸 수 있는 모드 중 하나다. 직접 켜보면(Window -&amp;gt; Profiler) 알 수 있듯이 CPU 시간 말고도 다른 특수한 작업들의 디테일한 사항을 볼 수 있다. 실시간으로 렌더링 되는 것들을 체크할 수 있는 &lt;strong&gt;Rendering&lt;/strong&gt; 모드, 메모리를 얼마나 쓰는지 확인할 수 있는 &lt;strong&gt;Memory&lt;/strong&gt; 모드, Unity 에서 가져다 쓰는 물리엔진 &lt;em&gt;PhysX&lt;/em&gt; 에서 주로퍼포먼스에 영향을 끼치는 것들에 대하여 정보를 나타내주는 &lt;strong&gt;Physics&lt;/strong&gt; 모드 등 꽤 많은 것들이 있다. 실시간으로 대부분의 문제를 찾을 수 있기 때문에 꽤 많은 시간들을 줄여준다.&lt;/p&gt;

&lt;p&gt;게다가 더욱더 강력하다고 생각되는 사실은 &lt;strong&gt;Android&lt;/strong&gt; 플랫폼에서 이 &lt;em&gt;Profiler&lt;/em&gt; 를 사용가능 하다는 것이다. &lt;em&gt;ADB&lt;/em&gt; 라는 디버깅 유닛이 있는데, Unity 에서는 이 유닛을 직접 사용하여 연결만 잘 되어있다면 프로파일러를 돌려볼 수 있다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 꽤나 좋은 &lt;em&gt;Profiler&lt;/em&gt; 를 지원한다. 시간이 난다면 게임을 처음부터 끝까지 몇번 돌려보길 바란다. 문제가 생겼을 때 돌려보는 것 보단 되도록 자주 체크하여 항상 문제가 있는지 없는지 체크해보는 것이 좋다. 시간이 없을 떄 처리하려면 골치아픈 문제가 되겠지만 시간이 여유로울 떄 발견하면 아주 큰 문제가 아닌 이상 처리하기는 편할 것이다. 또한 &lt;em&gt;Profiler&lt;/em&gt; 는 자신의 컴퓨터의 처리 속도를 체크하는 것이다. 그러므로 자신의 컴퓨터가 아주 좋은 플랫폼이라면 안좋은 플랫폼에서도 디버깅을 해보는 것도 좋을 것이다.&lt;/p&gt;

&lt;h2&gt;Hierachy and component based development&lt;/h2&gt;

&lt;p&gt;Unity 는 &lt;em&gt;Scene&lt;/em&gt; 이라 불리는 데이터 안에 여러 &lt;em&gt;GameObject&lt;/em&gt; 의 세팅을 넣어놓고 저장된 &lt;em&gt;GameObject&lt;/em&gt; 에 붙어있는 &lt;em&gt;Component&lt;/em&gt; 의 동작에 의해 게임이 돌아간다. 실제로 Unity 에서 동작하는 것들은 &lt;em&gt;Component&lt;/em&gt; 들인데 이렇게 여러 오브젝트들에 각자 &lt;em&gt;Component&lt;/em&gt; 를 붙여 동작하는 개발 방식을 CBD(Comnent based development) 라고 한다. Unity 는 CBD 를 근본적인 개념으로 차용해 정해져 있는 형식 없이 개발하도록 지원한다.&lt;/p&gt;

&lt;p&gt;Unity 는 CBD 를 밑바닥부터 구현하도록 지원하지만 이게 꼭 좋은 것은 아니다. 특히 성능상으로 따졌을 떄 컴포넌트가 많이 존재하면 존재할수록 컴포넌트들 안에 Unity 시스템에서 받는 메세지 메소드들이 많이 구현되어 있을수록 약간의 부하가 발생한다. (물론 절대적인 몇천개, 몇백개의 갯수를 뜻한다. CPU 의 성능에 따라 모바일에서는 간단한 수학 연산을 하는 몇십개의 메소드도 부담스러울수도 있다.) 제일 문제가 되는 부분은 &lt;em&gt;MonoBehaviour.Update&lt;/em&gt; 류의 메소드들이다.(&lt;em&gt;MonoBehaviour.LateUpdate&lt;/em&gt;, &lt;em&gt;MonoBehaviour.FixedUpdate&lt;/em&gt;) 이 메소드들은 매 프레임마다 호출되어야 하는 메소드들인데 이 메소드를 받는 컴포넌트들이 많으면 많을수록 부담되는 것은 사실이다.&lt;/p&gt;

&lt;p&gt;일반적인 상황에서는 한 메소드가 같은 프레임에 몇백번 이상 호출될 일은 없겠지만 그럴 일이 있다면 미리 합쳐주는 것을 추천한다.&lt;/p&gt;

&lt;h2&gt;PhysX&lt;/h2&gt;

&lt;p&gt;Unity 의 물리 기능은 서드파티 라이브러리인 &lt;em&gt;PhysX&lt;/em&gt; 를 탑재하여 기본으로 물리 기능을 지원한다. &lt;em&gt;PhysX&lt;/em&gt; 는 GameWorks 라는 게임 개발을 위한 미들웨어 제품 그룹에 있던 라이브러리 중 하나다. 그래서 우리는 About Unity 창을 열면 꽤 큼지막하게 자리를 차지하는 &lt;em&gt;PhysX&lt;/em&gt; 의 로고를 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/about_unity.png&quot; alt=&quot;About Unity&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unity 에서 PhsyX 는 물리 엔진으로서 자리 잡고 있는 것을 볼 수 있다. 하지만 PhsyX 는 자원이 한정되어 있는 플랫폼에서는 잘 사용해주어야 한다. 몇가지를 세팅해주어 한정적으로 돌아가게 해야되는데 해주어야 세팅들을 살펴보자.&lt;/p&gt;

&lt;h4&gt;Physics Setting : layer collision matrix&lt;/h4&gt;

&lt;p&gt;Unity 에서는 &lt;strong&gt;GameObject&lt;/strong&gt; 별로 &lt;em&gt;layer&lt;/em&gt; 를 설정해주어 여러가지 설정을 한다. 대표적인 예는 카메라에서 어떤 오브젝트를 그릴지 &lt;em&gt;layer&lt;/em&gt; 마스크를 통하는 것이다. 그리고 PhsyX 에서 돌아가는 물리 세팅도 &lt;em&gt;layer&lt;/em&gt; 기반으로 검사를 한다. 충돌 검사를 하는 연산이 많으면 많을수록 성능에 그다지 안좋은 영향을 끼치기에 &lt;em&gt;layer&lt;/em&gt; 별로 검사할 것들을 설정해 줄 수 있다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/physics_settings.png&quot; alt=&quot;Physics setting&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기는 Edit -&amp;gt; Project Settings -&amp;gt; Physics 으로 들어올 수 있는 프로젝트 별로 물리 관련된 옵션을 세팅해주는 곳이다. 여기서 Layer Collision Matrix 를 보면 된다. 이 이상하게 생긴 체크박스들은 해당 레이어와 충돌 체크를 하여 물리 연산을 하는지 안하는지에 대한 세팅 값이다. 이 부분만 체크해주어도 쓸데없는 연산을 없엘 수 있으니 신경써서 잘 체크해주길 바란다.&lt;/p&gt;

&lt;h4&gt;Time Setting : Fixed Timestamp&lt;/h4&gt;

&lt;p&gt;이제 언급하려는 부분은 상당히 게임에서 민감한 부분이다. 물리 기능을 하는 루프는 정확한 계산을 위해 일정 시간마다 체크를 하는데 이 체크를 하는 시간 주기를 Edit -&amp;gt; Project Settings -&amp;gt; Time 에서 변경할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/setting_timer.png&quot; alt=&quot;Timer Setting&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맨 처음에 보이는 Fixed Timestep 을 직접 바꾸어줄 수 있다. 이 숫자를 늘리면 매 프레임별 부하는 줄어들지만 정확성이 줄어든다. 이 숫자를 줄이면 매 프레임별 부하는 커지지만 물리 계산 결과는 정확해진다. 하지만 한가지 명심할 것이 있다. 이 부분은 실제 체크하는 부분을 담당하기 때문에 이미 만들어진 게임에서 이 숫자를 바꾸면 무슨일이 일어날지 모른다. 반드시 만들어진 게임에서, 특히 Collider 를 많이 쓰는 게임에서는 이 숫자를 철저한 검사후에 바꿔주어야 한다. 물론 Unity 의 물리 계산을 아예 안쓸거라면 엄청 크게 해주면 된다.&lt;/p&gt;

&lt;h4&gt;절대적인 Collider 의 갯수&lt;/h4&gt;

&lt;p&gt;위에서 GameObject 의 갯수에 대해서 말했었다. 이와 같이 Collider 의 갯수는 많으면 많을 수록 다른 레이어의 오브젝트들과 비교하는 대상이 많아지므로 더욱더 부하가 커진다. 즉 적절한 Collider 의 갯수도 중요하다.&lt;/p&gt;

&lt;h2&gt;Garbage Collection&lt;/h2&gt;

&lt;p&gt;Unity 는 개발 언어와 여러 환경을 위해 &lt;strong&gt;Mono&lt;/strong&gt; 프레임워크를 사용한다. 그리고 &lt;strong&gt;Mono&lt;/strong&gt; 프레임워크에서는 메모리 관리를 위해 &lt;strong&gt;Garbage Collector&lt;/strong&gt; 를 사용한다. GC 를 사용하게 되면 가끔씩 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 이 발생하는데 이 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 은 게이밍 환경에서는 정말 최악의 행동이다. 대부분 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 은 꽤나 시간이 걸리기 때문에 잠깐 끊기는 현상이 발생할 수 밖에 없다. 결국 게임 중에는 절~~대로 쓰레기(Garbage) 메모리를 만들면 안된다. 게임 시간이 얼마나 길어질지 모르고 플랫폼의 특성도 모르기 때문에 게임 중에는 쓰레기 메모리를 절대 안 만드는게 가장 안전하다. 위에서 언급한 &lt;em&gt;Profiler&lt;/em&gt; 를 통해 쓰레기 메모리들이 얼마나 발생하는지 GC Alloc 탭에서 체크할 수 있다.  &lt;strong&gt;Deep Profile&lt;/strong&gt; 기능까지 사용하면 메소드 단위로 알 수 있기 때문에 쓰레기 메모리를 만드는 부분을 하나하나 체크하여 없에는 것이 중요하다. 쓰레기를 발생시키는 코드의 유형은 꽤나 많기 때문에 여기서는 언급하지 않겠다.&lt;/p&gt;

&lt;h2&gt;Drawcall and Batching&lt;/h2&gt;

&lt;p&gt;Graphics API 에서는 물체를 그릴려면 여러 준비를 해야한다. 이 준비는 어느 정도의 시간이 걸리기 때문에 많으면 많을수록 상당히 부담스럽다. 준비를 마치면 GPU 에 그려달라는 명령을 한다. 이 명령을 &lt;em&gt;Draw Call&lt;/em&gt; 이라고 한다. &lt;em&gt;Draw Call&lt;/em&gt; 의 숫자는 모바일 게임의 경우 아무리 많아도 몇십개로 유지해야하며 고사양 PC 게임은 몇백단위로 유지해야 한다고 한다. 왜냐하면 &lt;em&gt;Draw Call&lt;/em&gt; 의 횟수가 많으면 많을수록 CPU 에서 부담하는 것들이 많아지기 때문에 결국 FPS 하락으로 이어질 수밖에 없다. 그런데 Unity 에서는 &lt;em&gt;Draw Call&lt;/em&gt; 이라는 단어는 엔진을 사용할 때 볼일이 하나도 없다. 이렇게 중요한데 왜 없냐하면 Unity 는 이 &lt;em&gt;Draw Call&lt;/em&gt; 을 줄이기 위해 엔진 내부에서 처리를 하는데 이를 &lt;em&gt;Batching&lt;/em&gt; 이라고 한다. 결국 &lt;em&gt;Draw Call&lt;/em&gt; 과 같은 단어지만 일정한 조건만 지키면 알아서 &lt;em&gt;Batching&lt;/em&gt; 카운트를 줄여준다. Unity 에서 최대한 &lt;em&gt;Batching&lt;/em&gt; 카운트를 줄이는 방법에 대하여 알아보자. 우선은 엔진에서 지원하는 것들에 대하여 알아보자.&lt;/p&gt;

&lt;p&gt;Unity 에서는 &lt;em&gt;Draw Call&lt;/em&gt; 을 줄이기 위해 &lt;em&gt;Static Batching&lt;/em&gt; 과 &lt;em&gt;Dynamic Batching&lt;/em&gt; 이 두가지 기능을 지원한다.  &lt;em&gt;Static Batching&lt;/em&gt; 은 움직이지 않는 오브젝트들을 세팅할 때 한꺼번에 그리는 기능이다. 만약 움직이는 오브젝트라면 항상 위치를 갱신해주어야 하기 때문에 준비를 다시해야 하지만 움직이지 않는 오브젝트라면 미리 움직이지 않는다고 체크를 하고 그대로 위치를 가지고 GPU 에서 그려주면 되기 때문이다.&lt;/p&gt;

&lt;p&gt;또한 전제조건으로 메터리얼을 공유해야 한다는 조건이 있다. 메터리얼에는 여러 인자와 쉐이더가 세팅되어 있는데 이 메터리얼을 공유해야 한다는 조건은 같은 쉐이더를 사용해야 &lt;em&gt;Batching&lt;/em&gt; 카운트를 합칠 수 있다는 이야기다.&lt;/p&gt;

&lt;p&gt;아래는 &lt;em&gt;Static Batching&lt;/em&gt; 을 에디터에서 세팅해주는 사진이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.unity3d.com/kr/current/uploads/Main/StaticTagInspector.png&quot; alt=&quot;Static Tag Inspector&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dynamic Batching&lt;/em&gt; 움직이는 오브젝트들이 같은 메터리얼을 공유하면 한꺼번에 그려주는 기능이다. 하지만 &lt;em&gt;Dynamic Batching&lt;/em&gt; 은 약간의 기능상의 한계가 있다. 아래 레퍼런스 링크로 들어가서 확인해보면 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/DrawCallBatching.html&quot;&gt;DrawCallBatching&lt;/a&gt; 에서 자세한 내용을 확인할 수 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/AlexanderDolbilov/google-i-o-2014&quot;&gt;Google IO 2014 : Optimizing unity games&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://shimans.tistory.com/41&quot;&gt;Optimize shader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/PhysX&quot;&gt;Wikipedia : PhysX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="try" />
      

      

      
        <summary type="html">일반적인 응용 프로그램들은 중간중간에 잠시 멈춰도 원하는 결과를 유저에게 보여주면 상관이 없다. 하지만 게임은 ‘게임중’ 에는 어떤 경우에도 렉을 허용하지 않는다. 그만큼 ‘게임중’ 상태에서 렉을 아예 발생시키지 않는 것이 게임 프로그래머의 중요한 능력중 하나다. 게임은 일반적으로 1초에 60번 이상 업데이트하는 루틴을 유지해야 유저에게 원활한 환경을 제공한다. 여기서 급작스럽게 프레임수가 하락하면 그때 유저들은 순간적으로 끊기거나 부드럽지 않은 경험을 하게된다. 유저들은 그런 것들을 랙으로 통칭한다. 랙이 반복되면 유저들은 게이밍 환경에 불만을 느끼게 된다. 일반적인 랙은 프로그래머의 실수인 경우가 많다. 런타임에서 많은 것을 한꺼번에 처리하는 경우가 대표적이다. 하지만 이는 여러 리팩토링을 거치면 충분히 해결할 수 있다. 경험이 적은 사람들에게 가장 문제가 되는 것은 엔진을 사용하는 방법이 문제가 되는 경우가 많다. 엔진의 자세한 구현 사항을 파악하지 못했기 때문에 한계를 생각하지 않고 코딩하는 경우 말이다. 몇가지 사항들만 주의하며 코딩한다면 꽤 많은 병목들을 피해갈 수 있다. 이제 Unity 엔진을 사용할 때 퍼포먼스에 영향을 끼치는 것들과 해결 방안에 대해서 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Texture2darray In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity/" rel="alternate" type="text/html" title="Using Texture2darray In Unity" />
      <published>2017-06-04T00:00:00+00:00</published>
      <updated>2017-06-04T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity/">&lt;p&gt;Unity 에서 렌더링에 관련된 최적화를 할때는 &lt;em&gt;TextureArray&lt;/em&gt; 를 사용할 수 밖에 없다. 이는 Unity 에서 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄이기 위해 써먹는 &lt;em&gt;Batching&lt;/em&gt; 이라는 개념 때문인데 단순하게 말하면 그리는 새로운 매터리얼과 메쉬의 종류가 많으면 많을 수록 &lt;em&gt;DrawCall&lt;/em&gt; 을 많이 하게 된다. 하지만 이 &lt;em&gt;DrawCall&lt;/em&gt; 의 비용은 싼편이 아니기 때문에 CPU 의 성능을 꽤나 잡아먹게 된다. 그래서 Unity 는 자동으로 &lt;em&gt;Batching&lt;/em&gt; 을 해주게 된다. 같은 메터리얼을 쓰면 자동으로 묶어주고, 같은 메쉬를 쓰면 또 자동으로 묶어준다. 결국 &lt;em&gt;Batching&lt;/em&gt; 이 &lt;em&gt;DrawCall&lt;/em&gt; 의 횟수와 같은 개념이 되는 것이다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;em&gt;Batching&lt;/em&gt; 의 횟수를 줄이기 위해 매터리얼을 줄이는 방법에 대한 것이 &lt;em&gt;TextureArray&lt;/em&gt; 다. 이것보다 일반적으로 알려진 기법은 &lt;em&gt;TexutreAtlas&lt;/em&gt; 인데, 이 방법은 상당히 단순하다. 그냥 텍스쳐 한장에 모든 그림을 때려박고 UV 를 수정해주는 작업을 할때 쓰인다. 보통은 UI 이미지에서 스프라이트를 설정할 때 쓰이며, Unity 는 UGUI 기능에 &lt;em&gt;Sprite&lt;/em&gt; 들을 합쳐서 &lt;em&gt;TextureAtlas&lt;/em&gt; 로 만들어주는 기능이 있다. 하지만 3D 오브젝트의 UV 에서는 말이 조금 달라진다. UV 좌표는 0과 1사이의 값으로 이루어지는데 텍스쳐 여러장과 세팅되어 있던 UV 좌표들을 한장으로 통합해 다시 세팅하려면 굉장히 귀찮아진다. 그리고 합쳐지기전의 텍스쳐의 갯수가 합쳐진 후에 추가된다면 그것또한 굉장히 귀찮아질 것이다. 결국 생산성의 문제가 된다.  그래서 다른 방법을 쓸 수 있는데, 이 방법이 바로 &lt;em&gt;TextureArray&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;TextureArray&lt;/em&gt; 의 개념은 단순하게 텍스쳐를 배열로 묶은 것으로, 인덱스만 있으면 그냥 하나하나 참조하여 사용가능하다. 즉 UV 의 2차원 좌표와 함께 인덱스 한개만 더 있으면 된다. 그리고 &lt;em&gt;TextureArray&lt;/em&gt; 의 장점은 &lt;em&gt;TextureAtlas&lt;/em&gt; 마냥 합쳐주고 UV 를 수정할 일이 없고, 메쉬별로 인덱스를 따로 설정해주는 작업만 해주면 상당히 편하게 할 수 있다. 또한 텍스쳐 갯수가 몇개가 되던간에 메터리얼을 한개로 유지할 수 있기 때문에 굉장히 편하다. 근데 Unity 에서 사용하려면 몇가지 단점이 있다. Asset 생성을 지원하지 않기 때문에 굉장히 불편하고, 보여주는 GUI 또한 Unity 내부에서 지원하지 않는다. 편하게 사용하기 위해선 에디터 코드를 직접 만져야 한다. 물론 직접 생성해주는 것도 상관없지만 생산성 자체만 놓고보면 그다지 좋은 편은 아니다. 또한 &lt;em&gt;Shader&lt;/em&gt; 코드들도 직접 바꿔주어야 하기 때문에 이것저것 세팅해줘야 할것이 많다. 즉 사용하기에 비용이 많이 든다.&lt;/p&gt;

&lt;p&gt;이제 직접 Unity 에서 적용시켜보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;할것들은 세가지다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mesh 안의 단순한 2차원 UV 좌표를 (UV + 텍스쳐 인덱스)를 좌표로 가진 3차원 좌표로 바꾸기&lt;/li&gt;
  &lt;li&gt;TextureArray 생성 및 적용하기&lt;/li&gt;
  &lt;li&gt;Shader 코드에서 TextureArray 를 사용하고 UV 좌표를 3차원 좌표로 바꾸기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/TextureArrayExample&quot;&gt;예제&lt;/a&gt;를 짜놓았으니 볼사람들은 참조하길 바란다.&lt;/p&gt;

&lt;p&gt;UV 좌표를 바꾸는 것은 경우에 따라 다르다. 보통은 2차원 UV 좌표로 설정해놓았으니 프로그래머가 합치는 것만 생각하면 &lt;em&gt;Mesh&lt;/em&gt; 별로 텍스쳐 인덱스를 심어주는 컴포넌트를 넣어주는게 편할 것이다. 시작시에만 UV 정보를 수정해주면 되니 로딩시간이 길어지는 것과 GPU 메모리를 조금 더 먹는 것 외에는 문제 될것은 없다. 초기 로드 시간이 걱정된다면 에디터에서 넣어주면 된다. 예제에서는 처음에 전부 생성하기 때문에 Vector2 로 저장하던 UV좌표를 Vector3 로 바꾸고 텍스쳐 인덱스만 끼워 넣었다.&lt;/p&gt;

&lt;p&gt;TextureArray 부분을 작업하는게 제일 귀찮다. 그냥 컴포넌트에서 동적으로 생성해주면 장땡이긴 하지만 그런식이면 매번 컴포넌트를 건드려야하니 여간 귀찮은게 아니다. 그래서 예제를 보면 알겠지만 간단하게 래핑한 에셋을 만들었다. 근데 귀찮은 점이 하나 있다. 생성후에 에디터에서 텍스쳐 갯수나 여러것들을 수정하는게 안되서 몇가지 조건 중 하나가 문제면 다시 생성한다. 그러면 매터리얼과 연결이 끊기는데.. 혐오스럽지만 여기까지만 해놓았다. 혹시 이 방법 해결책을 아시면 댓글 부탁드립니다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;strong&gt;Texture2D&lt;/strong&gt; 클래스와 &lt;strong&gt;Texture2DArray&lt;/strong&gt; 에 &lt;em&gt;SetPixel&lt;/em&gt; 류 함수들은 픽셀별로 접근하기 때문에 여러 텍스쳐 압축포맷이 먹힌 텍스쳐 복사는 안된다. &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/Graphics.CopyTexture.html&quot;&gt;&lt;em&gt;Graphics.CopyTexture&lt;/em&gt;&lt;/a&gt; 로 하라고 여러 포럼들에 적혀있었다. 조건에 맞아야 사용이 가능하니 레퍼런스에 있는 상세한 설명을 참고바란다. 근데 우리가 사용하려는 간단한 전체복사는 전부 된다.&lt;/p&gt;

&lt;p&gt;쉐이더 코드에서 TextureArray 를 사용하는건 굉장히 간단하다. &lt;a href=&quot;https://docs.unity3d.com/Manual/SL-TextureArrays.html&quot;&gt;Unity Manual : TextureArray&lt;/a&gt;를 참조하면 된다. 크게 어려울 것 없이 예제에 나온대로만 하면 된다.&lt;/p&gt;

&lt;p&gt;전체적으로 사용하기에는 어렵지않다. 하지만 그에 비해 얻는 이득은 많으니 어떤 게임이든 당연히 쓰는게 좋을 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/SL-TextureArrays.html&quot;&gt;Unity Manual : TextureArray&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서 렌더링에 관련된 최적화를 할때는 TextureArray 를 사용할 수 밖에 없다. 이는 Unity 에서 DrawCall 을 줄이기 위해 써먹는 Batching 이라는 개념 때문인데 단순하게 말하면 그리는 새로운 매터리얼과 메쉬의 종류가 많으면 많을 수록 DrawCall 을 많이 하게 된다. 하지만 이 DrawCall 의 비용은 싼편이 아니기 때문에 CPU 의 성능을 꽤나 잡아먹게 된다. 그래서 Unity 는 자동으로 Batching 을 해주게 된다. 같은 메터리얼을 쓰면 자동으로 묶어주고, 같은 메쉬를 쓰면 또 자동으로 묶어준다. 결국 Batching 이 DrawCall 의 횟수와 같은 개념이 되는 것이다. 그래서 Batching 의 횟수를 줄이기 위해 매터리얼을 줄이는 방법에 대한 것이 TextureArray 다. 이것보다 일반적으로 알려진 기법은 TexutreAtlas 인데, 이 방법은 상당히 단순하다. 그냥 텍스쳐 한장에 모든 그림을 때려박고 UV 를 수정해주는 작업을 할때 쓰인다. 보통은 UI 이미지에서 스프라이트를 설정할 때 쓰이며, Unity 는 UGUI 기능에 Sprite 들을 합쳐서 TextureAtlas 로 만들어주는 기능이 있다. 하지만 3D 오브젝트의 UV 에서는 말이 조금 달라진다. UV 좌표는 0과 1사이의 값으로 이루어지는데 텍스쳐 여러장과 세팅되어 있던 UV 좌표들을 한장으로 통합해 다시 세팅하려면 굉장히 귀찮아진다. 그리고 합쳐지기전의 텍스쳐의 갯수가 합쳐진 후에 추가된다면 그것또한 굉장히 귀찮아질 것이다. 결국 생산성의 문제가 된다. 그래서 다른 방법을 쓸 수 있는데, 이 방법이 바로 TextureArray 다. TextureArray 의 개념은 단순하게 텍스쳐를 배열로 묶은 것으로, 인덱스만 있으면 그냥 하나하나 참조하여 사용가능하다. 즉 UV 의 2차원 좌표와 함께 인덱스 한개만 더 있으면 된다. 그리고 TextureArray 의 장점은 TextureAtlas 마냥 합쳐주고 UV 를 수정할 일이 없고, 메쉬별로 인덱스를 따로 설정해주는 작업만 해주면 상당히 편하게 할 수 있다. 또한 텍스쳐 갯수가 몇개가 되던간에 메터리얼을 한개로 유지할 수 있기 때문에 굉장히 편하다. 근데 Unity 에서 사용하려면 몇가지 단점이 있다. Asset 생성을 지원하지 않기 때문에 굉장히 불편하고, 보여주는 GUI 또한 Unity 내부에서 지원하지 않는다. 편하게 사용하기 위해선 에디터 코드를 직접 만져야 한다. 물론 직접 생성해주는 것도 상관없지만 생산성 자체만 놓고보면 그다지 좋은 편은 아니다. 또한 Shader 코드들도 직접 바꿔주어야 하기 때문에 이것저것 세팅해줘야 할것이 많다. 즉 사용하기에 비용이 많이 든다. 이제 직접 Unity 에서 적용시켜보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Various Technique For Rendering</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/02/various-technique-for-rendering/" rel="alternate" type="text/html" title="Various Technique For Rendering" />
      <published>2017-06-02T00:00:00+00:00</published>
      <updated>2017-06-02T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/02/various-technique-for-rendering</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/02/various-technique-for-rendering/">&lt;p&gt;&lt;a href=&quot;/2017/05/29/simple-shader-programming/&quot;&gt;Simple shader programming&lt;/a&gt; 글 에서 간단하게 CG 를 통해 쉐이더를 작성하는 법에 대해서 알아보았다. 텍스쳐와 간단하게 색을 입히는 코드에 대해서 알아보았다. 하지만 이렇게 직접 쉐이더 코드를 변경하는 단계가 오게되면 이렇게 간단한 코드보다는 되게 복잡한 코드를 쓰는 경우가 많을 것이다. 또한 그 복잡한 코드들의 주요 원인은 보통 라이팅에 때문일것이다. 아무리 GPU 가 발전했다해도 빛에 대한 처리는 아직도 난감하다. 실제 빛의 속도는 &lt;em&gt;299792458m/s&lt;/em&gt; 이다. 대략 초당 3억 미터를 간다는 소리인데, 이를 컴퓨터에서 완벽하게 시뮬레이션을 하려면 답이 안나온다. 양자 컴퓨터가 나온다면 모르겠지만 말이다. 게다가 빛은 광자라는 미세한 입자로 나누어져 있고 이와 같이 상호작용하는 물체또한 입자단위로 빛을 반사하는데 모든 것을 똑같이 표현할 수는 없다.&lt;/p&gt;

&lt;p&gt;그래서 컴퓨터 그래픽스 분야에서는 한정된 자원의 컴퓨터를 사용해 빛을 실제와 같이 표현하기 위해 많은 노력을 해왔다. 물론 십몇년 전까지는 실제와는 거리가 멀었다. 대표적인 예전의 컴퓨터 그래픽을 나타내는 것은 아래와 같은 영상이다.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;    &lt;iframe title=&quot;YouTube video player&quot; width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/oRL5durPleI&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;Windows 95 시절의 화면 보호기 영상인데, 컴퓨터 그래픽인 것을 알 수 있는 부분은 맨 마지막에 OpenGL 이라고 쓰여져 있는 부분이다. 물론 이는 OpenGL 이 나온지 얼마 안되었을 때이고 95 년을 기준으로 따졌을 떄 20년이 지난 것들이다. 게다가 여기서는 라이팅도 없다. 하지만 20년이 지나고.. 현재로 돌아와서 최근에 와서는 꽤 실제와 비슷한 것들이 많이 나왔다. 아래 영상을 보자.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;    &lt;iframe title=&quot;YouTube video player&quot; width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/9v4XM8y-8fs&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;최근에 공개된 파크라이5 의 트레일러 영상이다. 자세히 보면 조금은 인위적인게 보이지만 실시간 3D 렌더링으로 이 정도를 나타낸건 지금도 혀를 내두를만한 기술들이 총 집약되어 여태까지 나온 게임들 중에 최고의 실시간 렌더링의 퀄리티를 보여준다. 특히 빛에 대한 묘사들이 더욱더 실제와 비슷하게 느끼게 해준다.&lt;/p&gt;

&lt;p&gt;이 글에서는 위 영상처럼 발전하기 까지의 여러가지 기본적인 렌더링 기법과 라이팅 기법에 대해서 알아볼 것이다. 최신 기술들도 중요하지만 최신 기술들을 이해하기 위해서도 여태까지의 기술들을 알아야 하고, 그 와중에서도 이전에 쓰이던 것을 그대로 쓰는 것도 있기 때문이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;필자는 여태까지 프로그래밍과 여러 아키텍쳐를 공부할 때 전체적인 개괄을 먼저 공부하고, 자세한 것들을 하나하나 공부하는 하향식 공부방법을 택해왔다. 그도 그럴수 밖에 없는 이유가 있다. Unity 만 예로 들어도 가장 맨 처음에는 로드맵을 보고 공부를 시작한다. 그 로드맵에는 디테일한 내용들은 없고 전부다 겉핡기 수준의 지식들만 노출되어 있다. 로드맵을 전부 보고난 후에 게임을 만들면서 필요한 기능들을 하나하나 들여다보기 시작한다.&lt;/p&gt;

&lt;p&gt;이와 같이 렌더링 기술들을 익히기 위해서는 전체적인 과정을 본 다음에 공부하는 것이 좋다. 아래에 렌더링이 한틱마다 이루어지는 과정을 보여주는 그림이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/vulkan_pipeline.svg&quot; alt=&quot;Vulkan pipeline&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 사진은 최근에 나온 Vulkan API 의 렌러링 파이프라인을 그려놓은 사진이다. 근데..  음.. 굉장히 복잡하다. Vulkan 은 DX12 에 대항하기 위해 만들어진 멀티 플랫폼 Graphics API 로써 Graphics API 를 통하여 이전 버젼의 API 들 보다 굉장히 많은 것을 프로그래머가 제어할 수 있게 해주는 API 다. 그러니 복잡할 수 밖에 없다. 하지만 우리는 자세한 것 보다 대략적인 큰 그림을 봐야하기 때문에 다른 간단한 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/sm40_tess.png&quot; alt=&quot;TesselPlusPipe&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전의 Vulkan 파이프라인과는 다르게 간단하게 표현된 그림이다. DirectX10 의 렌더링 파이프라인을 간단하게 보여준다. 연두색은 프로그래머가 제어할 수 있는 것이며(&lt;em&gt;Programmable&lt;/em&gt;) 주황색은 프로그래머가 제어할 수 없는 것들이다. 물론 중간 과정에는 꽤나 복잡한 작업들이 이루어 진다. 하지만 우리가 주목할 것들은 연두색으로 된 &lt;em&gt;Programmable shader&lt;/em&gt; 들이다.&lt;/p&gt;

&lt;p&gt;대부분의 라이팅 처리는 정점 쉐이더(vertex shader, 이하 &lt;em&gt;VS&lt;/em&gt;), 기하 쉐이더(geometry shader, 이하 &lt;em&gt;GS&lt;/em&gt;), 픽셀 쉐이더(pixel shader, 이하 &lt;em&gt;FS&lt;/em&gt;)를 사용해서 처리를 한다. 이 세가지의 쉐이더 조합은 나온지 몇년이 지났음에도 불구하고 엄청많이 사용되는 쉐이더 모델이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;VS&lt;/em&gt; 는  &lt;em&gt;Programmable shader&lt;/em&gt; 중에 가장 맨 처음에 시작되는 쉐이더로 반드시 정점 데이터 한개를 인자로 받아야 한다. 그리고 보통 &lt;em&gt;VS&lt;/em&gt; 는 위치 변환 연산을 하고 정점 별 라이팅에 대한 처리를 한다. 그 이외에는 보통 &lt;em&gt;GS&lt;/em&gt; 나 &lt;em&gt;FS&lt;/em&gt; 에 넘겨줘야할 데이터들이 그대로 넘어간다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GS&lt;/em&gt; 는 &lt;em&gt;Programmable shader&lt;/em&gt; 에서 필수로 있어야할 쉐이더는 아니다. 하지만 &lt;em&gt;VS&lt;/em&gt; 와 &lt;em&gt;FS&lt;/em&gt; 사이의 거쳐가는 쉐이더로써 꽤나 많은 활용성을 가지고 있다. 테셀레이션이라는 기능을 간단하게 사용할 수는 있지만 사실 &lt;em&gt;GS&lt;/em&gt; 는 다른 용도로 많이 사용된다고 한다. 렌더링에 필요한 데이터가 아니더라도 도중에 필요한 데이터들을 연산하는데 사용하거나, 중간에 렌더링 되는 결과를 변환하는 용도로 사용된다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;FS&lt;/em&gt; 는 이미 픽셀별로 조각을 내준 데이터를 따라 픽셀의 색을 변환하는 쉐이더다. 이 과정은 내준 조각별로 실행이 되며 텍스쳐 샘플링 등 색자체를 가져와서 설정하는 작업을 해준다. 보통은 이 과정에서 한 대상에 대한 렌더링은 끝난다.&lt;/p&gt;

&lt;p&gt;이제 라이팅에 대하여 알아보자.&lt;/p&gt;

&lt;p&gt;맨 처음에 등장한 라이팅 기법은 정점 쉐이더에서 모든 정점 마다 빛이 반사되는 값을 계산하여 처리해주는 &lt;em&gt;forward lighting&lt;/em&gt; 이라는 기법이다. 이 기법은 단순하고 오래된 전통적인 기법이며 VR 이나 모바일 같은 GPU 의 퍼포먼스가 조금 딸리는 분야에서 많이 사용된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/forward-v2.png&quot; alt=&quot;forward lighting&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;forward lighting&lt;/em&gt; 방식은 근데 중요한 문제가 하나 있었다. 모든 오브젝트의 정점마다 모든 라이팅을 전부 계산하기 때문에 오브젝트의 수와 라이팅의 갯수가 많으면 많을 수록 렌더링되는 속도는 현저하게 느려졌다. 그래서 최대한 그리는 정점의 갯수를 줄이기 위해 여러 기법들이 나왔다. 아주 기본적인 기법은 &lt;em&gt;Frustom Culling&lt;/em&gt; 이라는 기법이다. 카메라에서 보이는 것들만 그린다는 아이디어로 구현되어 있으며 간단한 충돌처리를 이용해서 구현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/frustum_culling.png&quot; alt=&quot;Frustom Culling&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 방식은 Perspective 형식으로 화면을 렌더링하는 카메라로 그릴 오브젝트와 안그릴 오브젝트를 구분하는 그림이다. 주황색은 그릴 오브젝트들 이며 회색은 안 그릴 오브젝트 들이다. 여기서 더 발전해서 가려져서 안보이는 오브젝트들을 그리지 않는 &lt;em&gt;Occlusion Culling&lt;/em&gt; 이라는 기법이 나왔다.&lt;/p&gt;

&lt;p&gt;카메라에서 가려지는 오브젝트를 아예 그리지 않는 것이다. 이 기법은 Unity 에서도 지원한다. &lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/OcclusionCulling.html&quot;&gt;Unity : Occlusion Culling&lt;/a&gt; 여기를 보면 사용 방법들을 참조할 수 있다. Unity 의 &lt;em&gt;Occlusion Culling&lt;/em&gt; 은 에디터상에서 정육면체들을 미리 설정해서 보이는 정육면체 단위로 메쉬 렌더러를 끄거나 킨다. 조금 이상하다고 느껴지는 점은 왜 맨처음에 귀찮게 설정을 해주어야 하며, 정육면체 단위로 공간을 잘라서 판단하는게 이상하다고 느껴진다. 이렇게 하면 연산량이나 여러모로 귀찮을 것 같기 때문이다. 하지만 이는 절대적인 연산량들을 줄이고 간편하게 &lt;em&gt;Occlusion Culling&lt;/em&gt; 을 구현하기 위한 일종의 꼼수다. 미리 영역을 계산하는 것은 실시간으로 할 필요가 없이 미리 공간을 정해놓고 공간에 해당되는 메쉬 렌더러를 설정하는 과정이고, 정육면체 나눈것은 가려지는 것들을 판단하게 실시간으로 빠르게 계산하기 위한 것이다.&lt;/p&gt;

&lt;p&gt;결국 절대적인 라이팅 연산량을 줄이고자 여러 기법들이 사용되었다. 하지만 근본적인 &lt;em&gt;forward lighting&lt;/em&gt; 의 문제인 라이트의 종류와 갯수는 여러 문제를 일으켰고 다른 기법(다시말해 꼼수) 들을 사용해 어떻게든 구현하였다.&lt;/p&gt;

&lt;p&gt;하이엔드 게임들은 꽤 많은 실시간 라이팅을 사용해 오브젝트의 디테일을 살렸다. 하지만 기존의 라이팅 방식은 논리적 라이트의 갯수에 따라 엄청난 부하를 일으켰고 문제를 해결하기 위해 사람들은 다른 라이팅 방식을 고안해냈다. 이름은 &lt;em&gt;deferred lighting&lt;/em&gt; 이다. 사실 이 &lt;em&gt;deferred lighting&lt;/em&gt; 이 고안되기 전에는 &lt;em&gt;forward lighting&lt;/em&gt; 이라는 단어도 없었다. 단지 개념이 한개가 더 추가되어 두 라이팅 개념을 다르게 통칭하기 위해 서로 이름이 붙혀진 것이다. 그래서 &lt;em&gt;deferred lighting&lt;/em&gt; 은 어떤 식으로 &lt;em&gt;forward lighting&lt;/em&gt; 의 라이트의 갯수의 문제를 해결했는지 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;forward lighting&lt;/em&gt; 에서는 픽셀 쉐이더에서 라이팅의 처리를 했었다. 그래서 &lt;em&gt;deferred lighting&lt;/em&gt; 은 정점 쉐이더는 기본적인 위치 변환만 한 후 새롭게 추가된 지오메트리 쉐이더에서 라이팅을 계산하기 위한 데이터들만 전부 넘겨주어 계산을 하지 않고 픽셀 쉐이더 이후에 넘어온 라이팅에 대한 데이터 전부를 뒤로 쭈~욱 넘겨서 마지막에 픽셀별로 처리해서 라이팅의 연산 비용을 줄인셈이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/deferred-v2.png&quot; alt=&quot;deferred lighting&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;forward lighting&lt;/em&gt; 에 비해 많은 수의 라이팅을 쓸 수 있고 이미 그려놓은 데이터들을 가져다가 후처리를 할 수도 있고, HDR 등 여러 기법들을 사용할 수 있다. 그렇지만 &lt;em&gt;deferred lighting&lt;/em&gt; 은 만능이 아니다. MRT 를 사용하므로 기본적으로 메모리 공간을 많이 잡아먹고, 많이 쓰일 당시에는 MSAA 를 사용하기에 상당히 애매했었다. 그리고 조금이라도 투명한 오브젝트를 처리하기에 굉장히 애매했다. 또한 전체적으로 &lt;em&gt;forward lighting&lt;/em&gt; 에 비해 넘어가는 인자의 크기가 크므로 전체적인 부담이 심했다.&lt;/p&gt;

&lt;p&gt;하드웨어도 꽤나 빠르게 진화하는 PC 플랫폼에서는 &lt;em&gt;deferred lighting&lt;/em&gt; 구조가 더 성능이 좋은 경우가 훨씬 많았지만 모바일 같은 GPU 의 성능도 별로 안좋고 화면만 엄청 큰(=필레이트가 많이 필요함) 환경에서는 부하가 걸릴 수 밖에 없다. 모바일에서는 런타임에서 최대한 기능을 조금만 쓰기 위해 &lt;em&gt;forward lighting&lt;/em&gt; 을 사용하고 빛에 대한 처리는 여러 꼼수를 사용했다.&lt;/p&gt;

&lt;p&gt;아주 가장 기초적인 꼼수인 &lt;em&gt;light map&lt;/em&gt; 이라는 기법을 사용했는데 원리는 상당히 간단하다. 버텍스별 라이트의 정보를 전부 텍스쳐로 저장해두어 uv 좌표를 사용해 텍스쳐 값을 합쳐주어 사용하는 것이다. 이는 노말맵과 비슷한 원리이다. 그래서 라이팅 기능을 모두 해제하고 필요한 빛 데이터들을 라이트맵을 이용하여 사용했다.&lt;/p&gt;

&lt;p&gt;이렇게 기본적인 렌더링 파이프라인들과 라이팅 방식에 대하여 알아보았다. 이 글의 내용이 전부는 아니지만 전체적인 개념을 잡는데 도움이 되었길 바란다.&lt;/p&gt;

&lt;!--
  phong reflecton = Ambient Light, Diffuse Light, Specular Reflection
  physics based rendering = reflection + albedo + refraction
    sRGB
    gamma correction
    bdrf vs bsrf vs btdf

  screen space ambient occlusion
  per-vertex ambient occlution

  global illumination

  shadow mapping
  raytracing shadow
--&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Unified_shader_model&quot;&gt;Unified shader model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gamedevelopment.tutsplus.com/articles/forward-rendering-vs-deferred-rendering--gamedev-12342&quot;&gt;GameDev : forward rendering vs deferred rendering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Deferred_shading&quot;&gt;Wikipedia : Deferred shading&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://learnopengl.com/#!Advanced-Lighting/Deferred-Shading&quot;&gt;LearnOGL : Deferred shading&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://celdee.tistory.com/525&quot;&gt;Ambient Light, Diffuse Light, Specular Reflectio&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://m.blog.naver.com/blue9954/220404249147&quot;&gt;PBR For Artist&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mmikkelsen3d.blogspot.kr/2016/05/fine-pruned-tiled-lighting.html&quot;&gt;Mikkelsen’s Blog : FPTL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/dgtman/hierachical-z-map-occlusion-culling&quot;&gt;Slideshare : hi-z occlusion culling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="cg" />
      
        <category term="try" />
      

      

      
        <summary type="html">Simple shader programming 글 에서 간단하게 CG 를 통해 쉐이더를 작성하는 법에 대해서 알아보았다. 텍스쳐와 간단하게 색을 입히는 코드에 대해서 알아보았다. 하지만 이렇게 직접 쉐이더 코드를 변경하는 단계가 오게되면 이렇게 간단한 코드보다는 되게 복잡한 코드를 쓰는 경우가 많을 것이다. 또한 그 복잡한 코드들의 주요 원인은 보통 라이팅에 때문일것이다. 아무리 GPU 가 발전했다해도 빛에 대한 처리는 아직도 난감하다. 실제 빛의 속도는 299792458m/s 이다. 대략 초당 3억 미터를 간다는 소리인데, 이를 컴퓨터에서 완벽하게 시뮬레이션을 하려면 답이 안나온다. 양자 컴퓨터가 나온다면 모르겠지만 말이다. 게다가 빛은 광자라는 미세한 입자로 나누어져 있고 이와 같이 상호작용하는 물체또한 입자단위로 빛을 반사하는데 모든 것을 똑같이 표현할 수는 없다. 그래서 컴퓨터 그래픽스 분야에서는 한정된 자원의 컴퓨터를 사용해 빛을 실제와 같이 표현하기 위해 많은 노력을 해왔다. 물론 십몇년 전까지는 실제와는 거리가 멀었다. 대표적인 예전의 컴퓨터 그래픽을 나타내는 것은 아래와 같은 영상이다. Windows 95 시절의 화면 보호기 영상인데, 컴퓨터 그래픽인 것을 알 수 있는 부분은 맨 마지막에 OpenGL 이라고 쓰여져 있는 부분이다. 물론 이는 OpenGL 이 나온지 얼마 안되었을 때이고 95 년을 기준으로 따졌을 떄 20년이 지난 것들이다. 게다가 여기서는 라이팅도 없다. 하지만 20년이 지나고.. 현재로 돌아와서 최근에 와서는 꽤 실제와 비슷한 것들이 많이 나왔다. 아래 영상을 보자. 최근에 공개된 파크라이5 의 트레일러 영상이다. 자세히 보면 조금은 인위적인게 보이지만 실시간 3D 렌더링으로 이 정도를 나타낸건 지금도 혀를 내두를만한 기술들이 총 집약되어 여태까지 나온 게임들 중에 최고의 실시간 렌더링의 퀄리티를 보여준다. 특히 빛에 대한 묘사들이 더욱더 실제와 비슷하게 느끼게 해준다. 이 글에서는 위 영상처럼 발전하기 까지의 여러가지 기본적인 렌더링 기법과 라이팅 기법에 대해서 알아볼 것이다. 최신 기술들도 중요하지만 최신 기술들을 이해하기 위해서도 여태까지의 기술들을 알아야 하고, 그 와중에서도 이전에 쓰이던 것을 그대로 쓰는 것도 있기 때문이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Simple Shader Programming</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/29/simple-shader-programming/" rel="alternate" type="text/html" title="Simple Shader Programming" />
      <published>2017-05-29T00:00:00+00:00</published>
      <updated>2017-05-29T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/29/simple-shader-programming</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/29/simple-shader-programming/">&lt;p&gt;이전에 쓴 글(&lt;a href=&quot;/2017/05/15/handling-uv-and-material-in-unity/&quot;&gt;handling uvs and material&lt;/a&gt;)에서 쉐이더에 대한 언급을 한적이 있다. 간단하게 전체적인 의미와 역할에 대해서 설명했었다. 이 글에서는 조금 더 자세하게 알아보고 CG 를 이용해서 직접 다루는 방법에 대해서 알아보겠다.&lt;/p&gt;

&lt;p&gt;3D 오브젝트는 GPU 에서 특정한 연산을 하여 화면상에 실제로 그려진다. 예전에는 그리는 방식이 정해져 있어 그 방식에 맞추어 데이터를 넣어주면 GPU 와 Graphics API 가 알아서 3D 오브젝트를 그렸었다. 하지만 기술은 점점 발전하여 프로그래머들이 직접 많은것을 제어할 수 있게 되었고 현재는 꽤 많은 것들이 가능하게 되었다. 그 발전속에서 나타난 것이 쉐이더다. 쉐이더는 3D 오브젝트를 그리는 방식을 적어놓은 코드라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;3D 오브젝트를 그리는 쉐이더 코드는 두가지로 나뉘는데, 하나는 vertex 를 처리하는 과정 또 하나는 pixel 자체를 처리하는 코드로 나뉜다. 이 두가지 과정을 잘 처리하면 게임에서 원하는 연출과 성능 두가지 토끼를 잡을 수 있다. 물론 잘하기 힘들다. 그래서 두 방법에서 프로그래머가 직접 코드를 짜서 넣으면서 게임의 그래픽을 원하는대로 커스터마이징이 가능하게 되었다. 이로써 꽤 많은 것을 실현 가능하게 되었었다. 하지만 이게 다가 아니였다.&lt;/p&gt;

&lt;p&gt;쉐이더를 사용한 AAA급 3D 게임들과 함께 GPU 도 격렬하게 발전했다. 발전한 만큼 GPU 의 퍼포먼스는 점점 괴물이 되어가고 그 과정에서 vertex shader 와 pixel shader 를 단순하게 그리는 것에만 사용하는 것이 아니라 다른 계산이 필요한 곳에 써먹기 시작했고 편법을 사용한 많은 기술이 나왔었다. (&lt;a href=&quot;http://www.gamedevforever.com/61&quot;&gt;vtf&lt;/a&gt;) 그렇게 프로그래머의 니즈를 파악한 GPU 제조사는 다른 기술을 개발한다. 이름하여 GPGPU 라는 이름의 기술인데 풀어 쓰면 &lt;em&gt;“general purpose computing on graphics processing units”&lt;/em&gt; 이다. &lt;em&gt;GPU 상의 범용 계산&lt;/em&gt; 이라는 뜻이다. 즉 위에서 언급한 병렬 계산이 가능한 것들을 편법을 쓰지말고 직접 이 기술을 사용해서 사용하라는 것이다. 이 GPGPU 기술이 나오면서 GPU 의 하드웨어적인 퍼포먼스에 따라 엄청 많은 것들을 가능하게 되었다. GPGPU 를 통해 불편했던 편법을 사용하던 기법들이 변형되어 쏟아져 나왔으며 새로운 기술 또한 엄청나게 쏟아져 나왔다. 그리고 그 기술들은 일반적으로 알려진 3D 그래픽이 차용된 AAA 급 게임들에 사용되어 일반 사용자들은 엄청난 그래픽을 자랑하는 게임들을 경험할 수 있게 되었다. 또한 최근에 &lt;em&gt;AI&lt;/em&gt; 기술이 대두되면서 GPGPU 가 더욱더 각광받게 되었다.&lt;/p&gt;

&lt;p&gt;이렇게 우리에게 다가오는 것은 꽤 많은 게임들의 발전인데, 다만 우리가 이 게임들의 기술에 접근하려면 꽤 많은 지식과 발상의 전환이 필요하다. 쉐이더만 하더라도 쉐이더 코드는 컴파일되어 GPU 에서 실행된다. CPU 에서 실행되는 일반적인 코드와 조금 다른 점은 CPU 에서 처리되는 것은 멀티스레딩을 하지 않는 이상 상당히 선형적인 코드를 짜게 되고 GPU 에서 돌아가는 쉐이더 코드를 짤 때는 병렬(parallel) 환경에서 돌아가게 짜야한다. 쉐이더 코드를 짤 때 첫번째로 겪게되는 어려움은 이것이다. 쉐이더까지 건드리게되면 경험이 어느정도 있는 상태일텐데, 개념을 조금 깨부수고 아예 병렬적으로 코드를 짜야하니 적응하는 것에 시간이 꽤나 소모된다.&lt;/p&gt;

&lt;p&gt;Unity 에서 Shader 를 직접 만들어 사용하는 것에 대하여 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Unity 는 여러 메인 스트림의 쉐이더 언어를 통해 쉐이더 코딩이 가능하다. 각각 언어마다 큰 차이는 없다. DirectX 와 OpenGL 에서 각각 지원하는 HLSL, GLSL 은 C 기반의 언어이고, Unity 에서 가장 많이 쓰이는 CG 는 NVidia 에서 MS 와 협력하여 만들어졌기 때문에 HLSL 과 비슷할 수 밖에 없다.(&lt;a href=&quot;https://web.archive.org/web/20120824051248/http://www.fusionindustries.com/default.asp?page=cg-hlsl-faq&quot;&gt;Cg &amp;amp; HLSL FAQ&lt;/a&gt;) 또한 쓰이는 문법도 많은 편은 아니라 한가지를 익혀두면 나머지를 사용하는데 크게 불편함은 없을 것이다. 물론 Unity 에서 쓰이는 쉐이더는 ShaderLab 을 기반으로 코딩해야 하기 때문에 네이티브 CG, HLSL, GLSL 과 전체적인 개괄은 다르다. 더 궁금한 사람은 Unity 본사 엔지니어 Aras 가 답변한 &lt;a href=&quot;https://forum.unity3d.com/threads/hlsl-cg-shaderlab.4300/&quot;&gt;질문 링크&lt;/a&gt; 를 보면 된다.&lt;/p&gt;

&lt;p&gt;Unity 의 기본적인 쉐이더 코딩은 ShaderLab 이라는 언어를 사용한다. 아래 ShaderLab 으로 되어있는 예제를 살펴보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Shader &quot;Custom/TextureColor&quot; {
	Properties {
		_Color (&quot;Color&quot;, Color) = (1,1,1,1)
		_MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {}
	}
	SubShader {
    Tags { &quot;Queue&quot;=&quot;Geometry&quot; &quot;RenderType&quot;=&quot;Opaque&quot; }

		Pass {
      Lighting Off

			constantColor[_Color]
			SetTexture[_MainTex] { combine texture * constant }
		}
	}

  FallBack &quot;Diffuse&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;위 예제는 색과 텍스쳐를 인자로 받아 텍스쳐에 색을 입혀서 출력해주는 간단한 예제다. 몇 줄 안되는 코드로 텍스쳐와 색을 입혔다. 언어 자체는 단순하고 간결하다. 다만 우리가 알아야하는 몇가지 문법이 있다. CG 나 HLSL 을 사용해도 결국 인라인, 삽입해서 사용하고 기본은 ShdaderLab 이기 때문에 전체를 감싸는 문법은 반드시 알아야 한다.&lt;/p&gt;

&lt;p&gt;가장 첫 줄에 Shader 이름을 적어주면 Unity 에서 매터리얼의 쉐이더를 선택하는 부분에 적어준 이름이 나온다. 그리고 밑부분을 보면 Properties 라는 항목들이 있다. 이 부분은 실제로 매터리얼에 저장하는 정보들을 정의해주는 부분으로 지정된 자료형들만 세팅이 가능하다. 위 코드에는 색과 텍스쳐를 넣어줄 수 있게 해놓았다. 그 다음부터는 실제로 렌더링을 하는 부분에 대한 코드들이다. 다만 조금의 구조가 있어 기본적인 사항은 숙지해야 한다. 기본만 알면 쉽게 코딩이 가능하다.&lt;/p&gt;

&lt;p&gt;SubShader 는 Shader 안에 여러개가 존재할 수 있는데 이는 꽤나 타당한 이유가 있다. 렌더링은 결국 빛과 여러 색들을 조합해서 화면에 뿌린다. 그리고 GPU 실제로 색을 그려준다. 그런데 낮은 버젼의 GPU 들은 꽤나 지원하지 않는 것들이 많다. GPU 별로 지원하는 Graphics API 버젼이 다른데 최신 기술을 쓰면 낮은 버젼의 Graphics API 를 지원하는 GPU 들은 해당 쉐이더 코드를 실행하지 못한다. 그래서 SubShader 의 개념을 두어 GPU 가 기능을 지원하지 못할 시 코드 상에서 아래 있는 걸로 한계단씩 내려가게 된다. 문제는 모든 SubShader 를 쓰지 못할때다. 그때는 Fallback 키워드에 적혀있는 쉐이더를 사용하여 그리게 한다. 위 예제 코드에서는 Diffuse 쉐이더를 사용하게 했다. 또한 Tag 를 설정해서 SubShader 를 Material 에서 설정할 수도 있다. Standard 쉐이더가 Tag 로 선택하는 기능을 지원한다.&lt;/p&gt;

&lt;p&gt;SubShader 는 전체적인 그리는 방법을 포함하는 개념이고 그 다음 하부로 내려가면 Pass 라는 개념이 있다. 이는 진~~~짜로 렌더링을 하는 구문으로써 이 부분에 그리는 방법을 서술한다. CG 나 HLSL 을 넣어줄 수도 있다. 자세한 문법은 &lt;a href=&quot;http://chulin28ho.tistory.com/159&quot;&gt;링크&lt;/a&gt;를 참조하라.&lt;/p&gt;

&lt;p&gt;특별하게 최적화를 할것이 아니라면 ShdaderLab 을 통해서 코딩을 해도 문제가 없다. 다만 좋은 퀄리티의 게임들은 대부분 쉐이더와 여러가지를 최적화를 시켜 주어야 하기 때문에 ShaderLab 만으로는 무리가 있다.&lt;/p&gt;

&lt;p&gt;결국 모든 것을 제어하려면 CG 나 HLSL 을 사용해야한다. 그래서 우리는 CG 를 통해서 Unity 에서 쉐이더 코딩을 할 것이다. CG 는 두가지 종류로 쉐이더 코딩을 지원한다. 하나는 표면 쉐이더(surface shader) 를 통한 코딩이고, 하나는 정점 쉐이더(vertex shader) 와 픽셀 쉐이더(pixel shader) 의 조합으로 사용된다.&lt;/p&gt;

&lt;p&gt;표면 쉐이더는 실제로는 없는 개념으로 쉐이더를 컴파일하면서 정점/픽셀 쉐이더로 변환되는 쉐이더 기능이다. 보통은 간단하고 빠르게 정점 라이팅을 코딩할 때 쓰인다. 기존에 존재하는 여러 라이팅 모델들을 지원하며 직접 정점 라이팅을 할 수도 있다. 다만 픽셀/프래그먼트 쉐이딩은 안된다. 그래서 상식적으로 생각하면 디퍼드 렌더링에서는 안되겠지만 디퍼드 렌더링에서도 가능하게 만들어 놓았다. 아래 표면 쉐이더의 예제를 보자. Unity 5.5.2f 버젼에서 기본으로 생성되는 쉐이더다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Shader &quot;Custom/NewSurfaceShader&quot; {
	Properties {
		_Color (&quot;Color&quot;, Color) = (1,1,1,1)
		_MainTex (&quot;Albedo (RGB)&quot;, 2D) = &quot;white&quot; {}
		_Glossiness (&quot;Smoothness&quot;, Range(0,1)) = 0.5
		_Metallic (&quot;Metallic&quot;, Range(0,1)) = 0.0
	}
	SubShader {
		Tags { &quot;RenderType&quot;=&quot;Opaque&quot; }

		CGPROGRAM
		#pragma surface surf Standard fullforwardshadows
    sampler2D _MainTex;

		struct Input {
			float2 uv_MainTex;
		};

		half _Glossiness;
		half _Metallic;
		fixed4 _Color;

		void surf (Input IN, inout SurfaceOutputStandard o) {
			// Albedo comes from a texture tinted by color
			fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color;
			o.Albedo = c.rgb;
			// Metallic and smoothness come from slider variables
			o.Metallic = _Metallic;
			o.Smoothness = _Glossiness;
			o.Alpha = c.a;
		}
		ENDCG
	}
	FallBack &quot;Diffuse&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;ShdaderLab 에 비하면 코드가 상당히 길다. 새롭게 변수를 세팅해 주어야 하기도 하고 몇가지 세팅을 해주어야 하기 때문이기도 하다. 이 코드에서는 라이팅을 Unity Standard 의 PBR 라이팅 모델을 사용하고 있다. 몇가지 살펴보면, 처음과 마지막을 CGPROGRAM 과 ENDCG 로 감싸준다. 그리고 바로 아래에 C 계열에서 많이 쓰이는 &lt;em&gt;pragma&lt;/em&gt; 전처리 키워드를 사용하여 뭔가 정의하고 있는데 바로 표면 쉐이더 함수의 정의를 써주는 곳이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#pragma surface surf Standard fullforwardshadows
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;surface 는 표면 쉐이더 함수를 정의한다는 것을, surf 는 코드에 정의되어 있는 함수의 이름을, Standard 는 라이팅 모델을 뜻한다. Unity Standard 쉐이더의 PBR 을 모델이다. 그리고 fullforwardshadows 는 그림자에 대한 옵션이다. 메터리얼의 인자에 들어가는 텍스쳐 등 설정값을 변수로 정의해준다. 변수 이름을 위에 Properties 에 정의와 똑같이 써주면 알아서 Unity 에서는 이 값을들을 접근하게 해준다. 반드시 똑같이 써주어야 작동한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct Input {
	float2 uv_MainTex;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;사이에 Input 구조체가 있다. 이 구조체에는 단순히 uv_MainTex 라는 변수한개만 있다. 단순하게 이름을 풀이해보면 MainTex 텍스쳐의 uv 좌표를 뜻한다. 이 변수 이름 역시 반드시 맞춰주어야 한다. 앞에는 uv 가 붙어야 하며, 그 다음 존재하는 텍스쳐 이름을 붙여주어야 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;void surf (Input IN, inout SurfaceOutputStandard o) {
	// Albedo comes from a texture tinted by color
	fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color;
	o.Albedo = c.rgb;
	// Metallic and smoothness come from slider variables
	o.Metallic = _Metallic;
	o.Smoothness = _Glossiness;
	o.Alpha = c.a;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이제 남은것은 surf 함수만 남아있다. 이는 표면 쉐이더에서 어떻게 정보를 처리하느냐를 적어주는 곳이다. Input 구조체는 위에서 정의해 주었고, &lt;em&gt;SurfaceOutputStandard&lt;/em&gt; 는 Standard 라이팅 모델에서 이미 정의된 구조체이다. 이 구조체의 값을 넣어주는 것으로 쉐이더 연산을 정의한다. 안의 코드를 풀어보자면, 가장 처음에 &lt;em&gt;tex2D&lt;/em&gt; 라는 함수로 &lt;em&gt;_MainTex&lt;/em&gt; 라는 텍스쳐와 &lt;em&gt;IN.uv_MainTex&lt;/em&gt; uv 좌표를 이용해 색을 가져온다. 그리고 &lt;em&gt;_Color&lt;/em&gt; 변수를 가져온 색에 각각에 rgba 별로 곱연산을 해준다. 그렇게 계산된 fixed4 자료형 &lt;em&gt;c&lt;/em&gt; 의 데이터를 스탠다드 라이팅 모델 인자의 Albedo 변수에는 rgb 값을, Alpha 변수에는 a 값을 넘겨준다. 나머지는 입력된 데이터 그대로 넣어준다.&lt;/p&gt;

&lt;p&gt;간단하게 표면 쉐이더 코드에 대해서 살펴보았다. 한가지 짚고 넘어가야 될것은 표면 쉐이더는 Unity 에서 자동으로 원래의 개념으로 컴파일 해주는 일종의  위 예제에서 본 Standard 라이팅 모델 말고도 미리 정의되어 있는 다른 라이팅 모델을 사용할 수도 있고 직접 라이팅 모델을 정의해서 사용할 수도 있다. 이 글에서는 라이팅 모델에 대해서 자세한 것은 다루지 않겠다. 자세한 사항에 대해서는 &lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/SL-SurfaceShaders.html&quot;&gt;Unity 표면 쉐이더 레퍼런스&lt;/a&gt; 를 참조하라.&lt;/p&gt;

&lt;p&gt;다음으로 살펴볼 쉐이더는 정점/픽셀 쉐이더를 조합한 쉐이더다. CG 를 사용하는 가장 낮은 단계의 쉐이더이며 실질적으로 돌아가는 쉐이더다. 그만큼 해야할 것도 많고 신경써야 할것도 많다. 특히 라이팅을 세팅할 때는 꽤나 코드가 길어지고 복잡해진다. 하지만 그만큼 세세하게 조정이 가능하다. 그래서 보통은 특수효과에 많이 쓰이며 최적화를 위한 쉐이딩을 할때도 쓰인다. 또한 여러 다른 쉐이더를 사용할 때에도 쓰인다. 아래 예제를 살펴보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Shader &quot;Custom/ColorTextureCG&quot; {
	Properties {
		_Color (&quot;Color&quot;, Color) = (1,1,1,1)
		_MainTex (&quot;Albedo (RGB)&quot;, 2D) = &quot;white&quot; {}
	}
	SubShader {
		Tags { &quot;RenderType&quot;=&quot;Opaque&quot; }

		Pass {
			CGPROGRAM
			#pragma vertex vert
			#pragma fragment frag

			#include &quot;UnityCG.cginc&quot;

			struct appdata
			{
				float4 vertex : POSITION;
				float2 uv : TEXCOORD0;
			};

			struct v2f
			{
				float4 vertex : SV_POSITION;
        float2 uv : TEXCOORD0;
			};

			v2f vert (appdata v)
			{
				v2f o;
				o.vertex = mul(UNITY_MATRIX_MVP, v.vertex);
				o.uv = v.uv;
				return o;
			}

			fixed4 _Color;
			sampler2D _MainTex;

			fixed4 frag (v2f i) : SV_Target
			{
				fixed4 col = tex2D(_MainTex, i.uv);
				return col * _Color;
			}
			ENDCG
		}
	}

	FallBack &quot;Diffuse&quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;위 예제는 색과 텍스쳐를 입혀주는 쉐이더로 아주 간단한 코드로 이루어져 있다. 한번 살펴보자. 그리고 CG 에서는 픽셀 쉐이더의 픽셀을 &lt;em&gt;fragment&lt;/em&gt; 라고 칭한다.&lt;/p&gt;

&lt;p&gt;역시나 CGPROGRAM 과 ENDCG 로 감싸져 있으며 가장 처음에는 &lt;em&gt;pragma&lt;/em&gt; 구문이 등장한다. 표면 쉐이더에서는 함수와 라이팅 모델을 설정하는데 쓰였는데, 여기서도 정점/픽셀 쉐이더 함수를 설정해주는데 쓰인다. 정점 쉐이더는 vertex 오른쪽에 함수 이름을 넘겨주고, 픽셀 쉐이더는 fragment 오른쪽에 함수 이름을 넘겨준다. 말 그리고 표면 쉐이더가 내부의 동작 원리를 알기 힘든것과는 다르게 정점/픽셀 쉐이더는 보이는 코드와 같이 똑같이 동작한다. 정점/픽셀 별로 처리하는 과정이 다르며 예제에 써준 코드 그대로 실행된다는 뜻이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;pragma&lt;/em&gt; 구문 아래에 표면 쉐이더 코드에서는 못보던 것이 있다. 바로 C 프로그래밍을 했을 떄 보던 &lt;em&gt;include&lt;/em&gt; 키워드다. 우리가 보는것과 같이 해당 위치에 &lt;em&gt;UnityCG.cginc&lt;/em&gt; 라는 이름을 가진 파일의 내용을 넣어주는 역할을 하는데, 이 &lt;em&gt;UnityCG.cginc&lt;/em&gt; 라는 파일에는 Unity 에서 제공하는 파일로 Unity 상에서 필요한 데이터들을 접근하고 데이터을 변환해주는 함수들이 들어있다. 정점이 &lt;em&gt;UnityCG.cginc&lt;/em&gt; 파일은 필수적으로 넣어주어야 한다.&lt;/p&gt;

&lt;p&gt;이제 직접 정점 쉐이더와 픽셀 쉐이더를 계산하는 부분들이 남았다. &lt;em&gt;vert&lt;/em&gt; 함수를 보면 &lt;em&gt;appdata&lt;/em&gt; 라는 구조체 변수를 인자로 받아서 &lt;em&gt;v2f&lt;/em&gt; 구조체 데이터를 반환하는 간단한 함수로 보인다. 이 함수의 코드를 보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;v2f vert (appdata v)
{
	v2f o;
	o.vertex = mul(UNITY_MATRIX_MVP, v.vertex);
	o.uv = v.uv;
	return o;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;첫번째 줄은 실제 Unity 의 위치와 &lt;em&gt;Mesh&lt;/em&gt; 에 저장되어 있던 로컬 정점 위치를 계산하여 정점의 실제 위치를 계산하여 넣어주는 줄이다. 실제로는 행렬 변환을 통해 위치값을 변경한다. 이 줄을 빼버리면 (0,0,0) 을 기준으로 모델이 출력될 것이다. 두번째 줄에서는 UV 좌표값을 그대로 넣어준다. 이 UV 좌표는 픽셀 쉐이더에서 사용한다.&lt;/p&gt;

&lt;p&gt;내부적으로 복잡한 처리가 끝나고 다음으로 픽셀 쉐이더 단계로 넘어간다. 등록된 함수가 호출되며 위의 &lt;em&gt;frag&lt;/em&gt; 함수가 호출되는데 여기서 텍스쳐와 UV 좌표로 폴리곤에 색을 입혀준다. 내용을 보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fixed4 frag (v2f i) : SV_Target
{
	fixed4 col = tex2D(_MainTex, i.uv);
	return col * _Color;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;frag&lt;/em&gt; 함수의 타입이 지정된 첫줄에 마지막에 쓰여있는 &lt;em&gt;SV_TARGET&lt;/em&gt; 은 어떤 곳에 픽셀 쉐이딩의 결과를 저장하는지에 대한 선언이다. Render Target 이라고 한다. &lt;em&gt;SV_TARGET&lt;/em&gt; 을 기본으로 쓰는데 이는 한곳에 모든 데이터를 쓴다는 선언이다. 여러곳에 데이터를 기록하면 Multiple Render Target 이라고 칭하게 되는 기술을 쓰는 것이다. 문법에 더 궁금한 사람은 &lt;a href=&quot;https://docs.unity3d.com/Manual/SL-ShaderSemantics.html&quot;&gt;Semantics&lt;/a&gt; 를 보라. MRT 에 대해 궁금한 사람은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiple_Render_Targets&quot;&gt;Wiki: MRT&lt;/a&gt; 를 보라.&lt;/p&gt;

&lt;p&gt;이제 내용을 보면 tex2D 함수에 &lt;em&gt;_MainTex&lt;/em&gt; 텍스쳐와 &lt;em&gt;i.uv&lt;/em&gt; 데이터를 넣어주어 추출된 색을 &lt;em&gt;col&lt;/em&gt; 변수에 저장한다. 이 안에는 RGBA 데이터가 들어있다. 그리고 &lt;em&gt;col&lt;/em&gt; 변수와 &lt;em&gt;_Color&lt;/em&gt; 변수를 &lt;em&gt;col&lt;/em&gt; 변수에 곱하여 실제 출력되는 픽셀 색을 반환한다. 반환된 색은 이제 실제로 보이게 된다.&lt;/p&gt;

&lt;p&gt;자세한 사항은 &lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/SL-ShaderPrograms.html&quot;&gt;Unity 정점/픽셀 쉐이더 레퍼런스&lt;/a&gt; 를 참조하면 된다.&lt;/p&gt;

&lt;p&gt;여기까지 텍스쳐와 색을 입히는 정점/픽셀 쉐이더에 대해서 알아보았다. 아주 기본적인 것들만 다루었기에 코드는 단순하다. 여기에 여러 효과들과 여러 기법들이 많이 들어가면 들어갈수록 복잡해질 것이다. 게다가 여러 플랫폼을 지원하기 위해 여러개의 SubShader 와 Pass 를 넣게되면 엄~청 긴 코드가 나올 것이다.&lt;/p&gt;

&lt;p&gt;그리고 번외로 Unity 컴포넌트 안에서 픽셀을 직접 만져서 바꿀 수 있는 기능이 있다. &lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/MonoBehaviour.OnRenderImage.html&quot;&gt;링크&lt;/a&gt;를 참조하라. 이 기능을 통해 Standard Asset 에 꽤 많은 효과들을 지원하는 기능들이 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khronos.org/opengl/wiki/Fixed_Function_Pipeline&quot;&gt;Khronos : Fixed function pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/SL-Reference.html&quot;&gt;Unity ref : shader references&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forum.unity3d.com/threads/hlsl-cg-shaderlab.4300/&quot;&gt;Unity forum : hlsl? cg? shaderlab?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forum.unity3d.com/threads/cg-toolkit-legacy.238181/&quot;&gt;Unity forum : CG Toolkit is legacy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/cg-toolkit&quot;&gt;NVidia developer : CG Toolkit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://unity3d.com/kr/learn/tutorials/topics/graphics/gentle-introduction-shaders&quot;&gt;Unity tutorial : Shader tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://chulin28ho.tistory.com/159&quot;&gt;블로그 : Shaderlab Ref&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jinhomang.tistory.com/43&quot;&gt;블로그 : 세이더 기초&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikibooks.org/wiki/Cg_Programming/Unity&quot;&gt;Unity wikibooks : cg programming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="cg" />
      
        <category term="shaderlab" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전에 쓴 글(handling uvs and material)에서 쉐이더에 대한 언급을 한적이 있다. 간단하게 전체적인 의미와 역할에 대해서 설명했었다. 이 글에서는 조금 더 자세하게 알아보고 CG 를 이용해서 직접 다루는 방법에 대해서 알아보겠다. 3D 오브젝트는 GPU 에서 특정한 연산을 하여 화면상에 실제로 그려진다. 예전에는 그리는 방식이 정해져 있어 그 방식에 맞추어 데이터를 넣어주면 GPU 와 Graphics API 가 알아서 3D 오브젝트를 그렸었다. 하지만 기술은 점점 발전하여 프로그래머들이 직접 많은것을 제어할 수 있게 되었고 현재는 꽤 많은 것들이 가능하게 되었다. 그 발전속에서 나타난 것이 쉐이더다. 쉐이더는 3D 오브젝트를 그리는 방식을 적어놓은 코드라고 할 수 있다. 3D 오브젝트를 그리는 쉐이더 코드는 두가지로 나뉘는데, 하나는 vertex 를 처리하는 과정 또 하나는 pixel 자체를 처리하는 코드로 나뉜다. 이 두가지 과정을 잘 처리하면 게임에서 원하는 연출과 성능 두가지 토끼를 잡을 수 있다. 물론 잘하기 힘들다. 그래서 두 방법에서 프로그래머가 직접 코드를 짜서 넣으면서 게임의 그래픽을 원하는대로 커스터마이징이 가능하게 되었다. 이로써 꽤 많은 것을 실현 가능하게 되었었다. 하지만 이게 다가 아니였다. 쉐이더를 사용한 AAA급 3D 게임들과 함께 GPU 도 격렬하게 발전했다. 발전한 만큼 GPU 의 퍼포먼스는 점점 괴물이 되어가고 그 과정에서 vertex shader 와 pixel shader 를 단순하게 그리는 것에만 사용하는 것이 아니라 다른 계산이 필요한 곳에 써먹기 시작했고 편법을 사용한 많은 기술이 나왔었다. (vtf) 그렇게 프로그래머의 니즈를 파악한 GPU 제조사는 다른 기술을 개발한다. 이름하여 GPGPU 라는 이름의 기술인데 풀어 쓰면 “general purpose computing on graphics processing units” 이다. GPU 상의 범용 계산 이라는 뜻이다. 즉 위에서 언급한 병렬 계산이 가능한 것들을 편법을 쓰지말고 직접 이 기술을 사용해서 사용하라는 것이다. 이 GPGPU 기술이 나오면서 GPU 의 하드웨어적인 퍼포먼스에 따라 엄청 많은 것들을 가능하게 되었다. GPGPU 를 통해 불편했던 편법을 사용하던 기법들이 변형되어 쏟아져 나왔으며 새로운 기술 또한 엄청나게 쏟아져 나왔다. 그리고 그 기술들은 일반적으로 알려진 3D 그래픽이 차용된 AAA 급 게임들에 사용되어 일반 사용자들은 엄청난 그래픽을 자랑하는 게임들을 경험할 수 있게 되었다. 또한 최근에 AI 기술이 대두되면서 GPGPU 가 더욱더 각광받게 되었다. 이렇게 우리에게 다가오는 것은 꽤 많은 게임들의 발전인데, 다만 우리가 이 게임들의 기술에 접근하려면 꽤 많은 지식과 발상의 전환이 필요하다. 쉐이더만 하더라도 쉐이더 코드는 컴파일되어 GPU 에서 실행된다. CPU 에서 실행되는 일반적인 코드와 조금 다른 점은 CPU 에서 처리되는 것은 멀티스레딩을 하지 않는 이상 상당히 선형적인 코드를 짜게 되고 GPU 에서 돌아가는 쉐이더 코드를 짤 때는 병렬(parallel) 환경에서 돌아가게 짜야한다. 쉐이더 코드를 짤 때 첫번째로 겪게되는 어려움은 이것이다. 쉐이더까지 건드리게되면 경험이 어느정도 있는 상태일텐데, 개념을 조금 깨부수고 아예 병렬적으로 코드를 짜야하니 적응하는 것에 시간이 꽤나 소모된다. Unity 에서 Shader 를 직접 만들어 사용하는 것에 대하여 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Handling Rig And Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/19/handling-rig-and-skinning/" rel="alternate" type="text/html" title="Handling Rig And Skinning" />
      <published>2017-05-19T00:00:00+00:00</published>
      <updated>2017-05-19T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/19/handling-rig-and-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/19/handling-rig-and-skinning/">&lt;p&gt;앞서 오브젝트들을 그리는 방법에 대해서 알아보았다.(&lt;a href=&quot;/2017/05/14/handling-vertices-and-indices-in-unity/&quot;&gt;hnalding vertices&lt;/a&gt;, &lt;a href=&quot;/2017/05/15/handling-uv-and-material-in-unity/&quot;&gt;handling uvs&lt;/a&gt;) 폴리곤을 그리고 색을 칠하는 방법이었다. 하지만 이런 기능만 가지고 게임을 만들기에는 약간 부족하다. 보통 게임을 만들때 케릭터들의 부드러운 움직임을 표현해야 한다. 2D 게임은 보통 그림을 여러장을 그려서 움직이게 보이게 한다. 하지만 3D 게임에서의 부드러운 움직임은 2D 게임의 표현과는 다르게 표현한다. 일단 부드럽게 움직여야할 단위가 다르다. 메쉬의 정점들을 부드럽게 움직여야하기 때문에 2D 게임의 움직임과는 다른 무언가가 필요하다.&lt;/p&gt;

&lt;p&gt;2D 게임에서 그림을 한꺼번에 움직이는 것처럼 단순하게 메쉬 전체를 부드럽게 움직여서 해결되면 좋겠지만 이 방법은 조금 문제가 있다. 관절같은 접합 부분에서 부드럽게 처리해야 하는 부분 즉 어떤 정점만 부드럽게 움직여야하는 문제가 있다. 그래서 고안된 방법은 특정한 위치를 설정해서 그 위치를 기준으로 정점들을 움직여주는 방법이다.&lt;/p&gt;

&lt;p&gt;언급한 특정한 위치를 &lt;em&gt;Bone&lt;/em&gt; : 뼈라고 한다. 뼈를 움직여서 정점들을 직접 움직이는 것이다. 그리고 뼈를 기준으로 움직이는 것을 &lt;em&gt;Skinning&lt;/em&gt; 이라고 한다. 사람의 뼈가 움직이면 피부도 따라서 움직이듯이 피부를 직접 설정하는 것을 &lt;em&gt;Skinning&lt;/em&gt; 이라고 하는 것이다. 그리고 &lt;em&gt;Bone&lt;/em&gt; 의 위치도 상당히 중요하다. 자연스러운 움직임을 만들려면 만들어진 메쉬에 잘 맞게 위치를 설정해주어야 하기 때문이다. 위치 뿐만아니라 여러 움직이는 범위나 뼈의 계층 구조를 잘 설정해주어야 자연스러운 움직임을 나타낼 수 있다. 이러한 작업을 &lt;em&gt;Rigging&lt;/em&gt; 이라 한다. 보통 3D 오브젝트를 만들고 &lt;em&gt;Rigging&lt;/em&gt; 과 &lt;em&gt;Skinning&lt;/em&gt; 을 하는 작업은 그래픽 아티스트가 직접 해주지만 우리는 이 과정을 이해해야 하기에 Unity 에서 직접 만들어 볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;Unity 에서 직접 리깅, 스키닝하기&lt;/h2&gt;

&lt;p&gt;일반적으로 저장된 메쉬에 &lt;em&gt;Rigging&lt;/em&gt;, 뼈를 위치시키고 기타 설정을 하는 작업을 먼저한다. 그리고 뼈를 전부 위치시킨 다음 정점들과 뼈 사이의 가중치를 주는 &lt;em&gt;Skinning&lt;/em&gt; 작업을 한다. 우리도 이 순서에 맞게 작업을 할 것이다. &lt;a href=&quot;https://github.com/hrmrzizon/3DBasicExample&quot;&gt;3DBasicExample&lt;/a&gt; 의 &lt;em&gt;edu/skin&lt;/em&gt; 브랜치로 이동하면 미리 되어 있는것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이전에 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스를 활용해서 화면에 그릴려면 &lt;strong&gt;MeshFilter&lt;/strong&gt; 컴포넌트와 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 컴포넌트가 필요했다. 그런데 이번에 필요한 컴포넌트는 조금 다르다. 그대로 &lt;strong&gt;MeshFilter&lt;/strong&gt; 와 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 를 그린다면 리깅과 스키닝이 적용이 안된채로 그려진다. 물론 가만히 있는 용도로는 상관없겠지만 리깅과 스키닝이 적용된 결과를 보고싶으면 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 라는 컴포넌트를 사용해야한다. &lt;strong&gt;MeshRenderer&lt;/strong&gt; 처럼 다른 부수적인 컴포넌트는 필요없다. &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 안에 모든 정보를 다 넣기 때문에 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 컴포넌트 하나만 있으면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Rigging&lt;/em&gt; 작업은 &lt;em&gt;Mesh&lt;/em&gt; 복잡도와 뼈의 갯수에 따라 시간이 비례한다. 그래서 복잡한 모델을 작업할때는 &lt;em&gt;Rigging&lt;/em&gt; 하는데 시간이 꽤 많이든다. 하지만 우리는 간단한 마인크래프트 케릭터를 가지고 할 것이기 때문에 그다지 오래 걸리지 않을 것이다. &lt;strong&gt;GameObject&lt;/strong&gt; 를 적당한 좌표, 적당한 &lt;strong&gt;Transform&lt;/strong&gt; 간의 위치에 놓은 다음에 &lt;em&gt;SkinnedMeshRenderer.bones&lt;/em&gt; 배열에 등록해준다. 아래와 비슷하게 해주면된다. 아래 코드에서는 미리 배치가 되어있다는 가정하에 넣어놓았다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;SkinnedMeshRenderer skinnedMeshRenderer = GetComponent&amp;lt;SkinnedMeshRenderer&amp;gt;();

skinnedMeshRenderer.bones = new Transform[] { transform.FindChild(&quot;bone0&quot;), transform.FindChild(&quot;bone1&quot;), transform.FindChild(&quot;bone2&quot;),
                                              transform.FindChild(&quot;bone3&quot;), transform.FindChild(&quot;bone4&quot;), transform.FindChild(&quot;bone5&quot;) };

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;넣어준 &lt;em&gt;Bone&lt;/em&gt; 을 적용시키려면 특별한 행렬이 필요하다. 정점을 &lt;em&gt;Bone&lt;/em&gt; 과 연관시키려면 정점별 &lt;em&gt;Bone&lt;/em&gt; 과의 가중치와 앞에서 말한 행렬이 필요한데, 이 행렬이 단위행렬로(곱연산을 하면 값이 그대로 나오는 행렬이 설정되어 있으면 두가지 문제가 생긴다. &lt;em&gt;Bone&lt;/em&gt; 의 위치값을 정점에서 제외시키지 못해 이상한 거리에 &lt;em&gt;Skinning&lt;/em&gt; 이 되고, 루트 &lt;strong&gt;GameObject&lt;/strong&gt; 의 위치를 제외시키지 못해 한번 더 이상한 위치에 &lt;em&gt;Skinning&lt;/em&gt; 이 되어 버린다. 그래서 반드시 올바른 행렬값을 넣어주어야 한다. 기본 식은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;Transform boneTransform = transform.FindChild(&quot;bone0&quot;);
GameObject rootObject = gameObject;

skinnedMeshRenderer.bindposes[0] = boneTransform.worldToLocalMatrix * rootObject.transform.localToWorldMatrix;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;저 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 의 멤버 &lt;em&gt;bindposes&lt;/em&gt; 는 넣어준 &lt;em&gt;bones&lt;/em&gt; 배열의 갯수와 맞춰주어 넣어주어야 한다. &lt;em&gt;bone&lt;/em&gt; 별로 계산하는 행렬이니 말이다. 다음은 &lt;em&gt;skinning&lt;/em&gt; 이다. 우리가 만들 케릭터는 마인크래프트의 복셀 케릭터이니 상당히 간단하게 데이터를 설정할 것이지만 사실에 가까우면 가까울수록 필요한 가중치가 많아질 것이다. 정점별로 뼈의 기준에 따라서 얼만큼 가깝게 움직일 것이냐를 정해주어야 한다. Unity 는 이를 &lt;strong&gt;BoneWeight&lt;/strong&gt; 라는 구조체로 정의해 놓았다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;public struct BoneWeight
{
    public int boneIndex0 { get; set; }
    public int boneIndex1 { get; set; }
    public int boneIndex2 { get; set; }
    public int boneIndex3 { get; set; }
    public float weight0 { get; set; }
    public float weight1 { get; set; }
    public float weight2 { get; set; }
    public float weight3 { get; set; }

    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;boneIndex&lt;/em&gt; 들은 전부다 위의 &lt;em&gt;SkinnedMeshRenderer.bones&lt;/em&gt; 에 들어간 &lt;strong&gt;Transform&lt;/strong&gt; 의 인덱스들이다. 그리고 &lt;em&gt;weight&lt;/em&gt; 들은 해당 &lt;em&gt;bone&lt;/em&gt; 을 기준으로 얼마만큼 가까워질지에 대한 값이다. 가중치가 한 &lt;em&gt;bone&lt;/em&gt; 에 상대적으로 클수록 해당 &lt;em&gt;bone&lt;/em&gt; 의 위치에 더 가까워질 것이다. 하지만 우리는 여러 가중치를 설정할 필요없이 부위별로 한개의 가중치만 설정해주면 된다. 설정만 해주면 &lt;em&gt;skinning&lt;/em&gt; 은 끝난다. 생각보다 간단하다. 이 과정이 끝나면 직접 &lt;em&gt;bone&lt;/em&gt; 을 움직여 잘 따라가는지 확인할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-c# highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partCount&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertexByPart&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BoneWeight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BoneWeight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partCount&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertexByPart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partCount&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;++)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertexByPart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;++)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertexByPart&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;BoneWeight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boneIndex0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boneWeights&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;마인크래프트의 케릭터들은 한개의 &lt;em&gt;bone&lt;/em&gt; 을 기준으로 케릭터가 움직이기 때문에 &lt;em&gt;bone&lt;/em&gt; 을 정점별로 한개씩 설정해 주었다. 여기까지 설정해주면 설정된 &lt;em&gt;bone&lt;/em&gt; 들을 따라 그려진다. 여기까지 &lt;em&gt;bone&lt;/em&gt; 을 직접 설정해주고, &lt;em&gt;bone&lt;/em&gt; 별 변환 행렬을 설정해주고, 정점별로 가중치를 두어 해당 가중치로 &lt;em&gt;bone&lt;/em&gt; 을 따라가게 해주었다. 그런데 몇가지 짚고 넘어가야할 것들이 있다. &lt;strong&gt;MeshRenderer&lt;/strong&gt; 와 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 의 디테일한 동작의 차이다. 위에서 &lt;em&gt;skinning&lt;/em&gt; 이 적용되냐 마냐의 차이만 있다고 설명했다. 물론 기능상의 차이는 이것 뿐이지만 이 기능 때문에 벌어지는 몇가지 세부사항도 알아야 한다. Unity 시스템에서는 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 가 그리는 정점들이 움직이지 않는다는 가정하에 모든 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 를 모아서 최적화를 해준다. 물론 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스가 가진 데이터가 적어야 한다는 한계가 있지만 복수의 오브젝트가 많아질 수록 이 부분은 꽤나 중요해진다. 하지만 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 는 크게 최적화가 되어있지 않아 많이 쓰면 쓸수록, &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스의 정점의 갯수가 많으면 많을수록 부하는 심해진다. 물론 한두개만 쓰면 크게 문제되는 상황은 없지만 많으면 많을수록 퍼포먼스가 떨어지는 디바이스에서는 문제가 된다. 즉 사용시 주의해서 사용해야 한다.&lt;/p&gt;

&lt;h1&gt;참조&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Skinning&quot;&gt;Wikipedia : Skinning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Skeletal_animation&quot;&gt;Wikipedia : Skeletal animation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/GameEngineStudy/CodeRigging&quot;&gt;코드로 리깅하고 애니메이션 하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/PlayerSettings-gpuSkinning.html&quot;&gt;Unity ref: PlayerSettings.gpuSkinning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="rig" />
      
        <category term="animate" />
      
        <category term="try" />
      

      

      
        <summary type="html">앞서 오브젝트들을 그리는 방법에 대해서 알아보았다.(hnalding vertices, handling uvs) 폴리곤을 그리고 색을 칠하는 방법이었다. 하지만 이런 기능만 가지고 게임을 만들기에는 약간 부족하다. 보통 게임을 만들때 케릭터들의 부드러운 움직임을 표현해야 한다. 2D 게임은 보통 그림을 여러장을 그려서 움직이게 보이게 한다. 하지만 3D 게임에서의 부드러운 움직임은 2D 게임의 표현과는 다르게 표현한다. 일단 부드럽게 움직여야할 단위가 다르다. 메쉬의 정점들을 부드럽게 움직여야하기 때문에 2D 게임의 움직임과는 다른 무언가가 필요하다. 2D 게임에서 그림을 한꺼번에 움직이는 것처럼 단순하게 메쉬 전체를 부드럽게 움직여서 해결되면 좋겠지만 이 방법은 조금 문제가 있다. 관절같은 접합 부분에서 부드럽게 처리해야 하는 부분 즉 어떤 정점만 부드럽게 움직여야하는 문제가 있다. 그래서 고안된 방법은 특정한 위치를 설정해서 그 위치를 기준으로 정점들을 움직여주는 방법이다. 언급한 특정한 위치를 Bone : 뼈라고 한다. 뼈를 움직여서 정점들을 직접 움직이는 것이다. 그리고 뼈를 기준으로 움직이는 것을 Skinning 이라고 한다. 사람의 뼈가 움직이면 피부도 따라서 움직이듯이 피부를 직접 설정하는 것을 Skinning 이라고 하는 것이다. 그리고 Bone 의 위치도 상당히 중요하다. 자연스러운 움직임을 만들려면 만들어진 메쉬에 잘 맞게 위치를 설정해주어야 하기 때문이다. 위치 뿐만아니라 여러 움직이는 범위나 뼈의 계층 구조를 잘 설정해주어야 자연스러운 움직임을 나타낼 수 있다. 이러한 작업을 Rigging 이라 한다. 보통 3D 오브젝트를 만들고 Rigging 과 Skinning 을 하는 작업은 그래픽 아티스트가 직접 해주지만 우리는 이 과정을 이해해야 하기에 Unity 에서 직접 만들어 볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Handling Uv And Material In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/15/handling-uv-and-material-in-unity/" rel="alternate" type="text/html" title="Handling Uv And Material In Unity" />
      <published>2017-05-15T00:00:00+00:00</published>
      <updated>2017-05-15T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/15/handling-uv-and-material-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/15/handling-uv-and-material-in-unity/">&lt;p&gt;&lt;a href=&quot;/2017/05/14/handling-vertices-and-indices-in-unity/&quot;&gt;Handling vertices and indices&lt;/a&gt; 글에서 Unity 에서 정점과 인덱스를 사용해 물체를 그리는 방법에 대해서 알아보았다. 그런데 뭔가 설정해야 할것들이 빠진 것처럼 보인다. 실제로 그려지는 모습은 Unity 에서 아무것도 설정이 안되어 있을 때 나오는 분홍색으로 전부 칠해져 있다. 일반적으로 게임에서 나오는 3D 물체들은 전부 색이 칠해져 있거나 그림이 그려져 있다. 거기다가 빛을 받아서 반짝반짝이기도 할때도 있다. 이번 글에서는 3D 오브젝트에 색을 입히거나 그림을 입히는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;폴리곤은 하나의 면으로써 폴리곤 안의 색으로 무언가를 표현해야 한다. 우리가 앞에서 보던 예제처럼 계속 분홍색으로 내버려 둘순 없지 않은가? 색을 직접 입힐만한 수단이 필요한데 이를 위해서는 몇가지 데이터들이 필요하다.&lt;/p&gt;

&lt;p&gt;제일 먼저 필요한 것은 폴리곤에 색을 입힐 방법을 컴퓨터에게 알려 주어야 한다. 이 방법은 보통 어떤 형식의 코드로 나타내는데 이를 쉐이더(&lt;em&gt;Shader&lt;/em&gt;)라고 한다. Unity 는 매우 다양한 색을 입히는 방법 : 쉐이더를 지원한다. 물론 직접 쉐이더 코드를 만들 수도 있지만 전체적인 것들에 대한 이해가 있어야 쉽게 방법을 고안할 수 있으므로 나중에 직접 쉐이더 코드를 만들어 볼 것이다. 이 글에서는 Unity 에서 제공하는 쉐이더를 사용해 폴리곤에 색을 입힐 것이다.&lt;/p&gt;

&lt;p&gt;쉐이더는 다양한 방식으로 색을 입힐 수 있는데 일반적으로 쓰는 방법은 그림을 하나 가져다가 폴리곤에 그려주는 것이다. 이 그림은 텍스쳐라고 칭한다. 텍스쳐를 그릴 때는 항상 일정한 기준이 필요하다. 무턱대고 텍스쳐의 아무곳이나 그릴순 없지 않은가? 그래서 폴리곤의 정점과 상응되는 텍스쳐의 2차원 좌표가 필요하다. 이를 UV 좌표(Position) 이라고 한다. “U” 와 “V” 가 텍스쳐의 가로, 세로 위치를 나타내는 말이라 UV 좌표라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/texturemapping.png&quot; alt=&quot;Texture mapping&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 UV 좌표와 폴리곤을 구성하는 정점들이 나온 모습을 볼 수 있는데, 우리가 주목할것은 왼쪽 그림이다. 삼각형이 그려져 있는데 실제로 가지고 있는 데이터는 삼각형들의 각 꼭지점을 좌표로 가지고 있다. 그리고 각 UV 좌표들은 폴리곤을 구성하는 정점들과 매칭되어 오른쪽 아래의 결과가 그려진다.&lt;/p&gt;

&lt;p&gt;폴리곤에 색을 입히는 원리에 대하여 간단하게 알아보았다. 이제 Unity 에서 직접 색을 입히는 방법을 알아보자.&lt;/p&gt;

&lt;h2&gt;Mapping object in Unity&lt;/h2&gt;

&lt;p&gt;위에서 색을 입히기 위해서는 총 3가지가 필요하다고 말했다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;쉐이더&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;UV 좌표&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;텍스쳐 및 기타 정보&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unity 에서는 이 3가지를 취급하기 위해 두가지 분류를 만들어 놓았다. 하나는 전 게시글에서 본 &lt;strong&gt;Mesh&lt;/strong&gt; 클래스고 하나는 &lt;strong&gt;Material&lt;/strong&gt; 이라는 개념이다. &lt;strong&gt;Mesh&lt;/strong&gt; 클래스는 복수의 좌표 데이터를 저장하기 위한 목적으로 사용된다. 그래서 정점, 인덱스와 더불어 UV 좌표도 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스 안에 넣는다.&lt;/p&gt;

&lt;p&gt;이제 &lt;strong&gt;Material&lt;/strong&gt; 하나만 남았다. 단어의 뜻은 “재료, 원료” 이런 뜻인데 색을 입히기 위한 재료라고 생각하면 편하다. 설정된 쉐이더와 쉐이더에서 필요한 여러 데이터들을 가지고 있는 Unity 의 애셋이다. 파일로도 존재할 수 있고, 런타임에서 생성해서 가지고 있을 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mesh_and_materials.png&quot; alt=&quot;mesh and materials&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/3DBasicExample&quot;&gt;3DBasicExample&lt;/a&gt; 의 edu/mat 브랜치에 우리가 봐야할 소스들이 있다. 씬안에 MeshToolTest2 스크립트가 붙어있을 텐데 uv 를 설정해주는 라인이 있을것이다.&lt;/p&gt;

&lt;div class=&quot;language-c# highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;AddPlane&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mesh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCube&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;cm&quot;&gt;/*

                  (0,1)       (1,1)
                (0,0,1) 2   3 (1,0,1)
                        * - *
                        | / |
                        * - *
                (0,0,0) 0   1 (1,0,0)
                  (0,0)       (1,0)

            */&lt;/span&gt;

            &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vector2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
                      &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                          &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                          &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                          &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                          &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                      &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이 코드는 정점을 다루는 게시물에서 한번 본 예제다. 크게 달라진 내용은 없다. 면을 정의하기 위해 4개의 점을 만들고, 폴리곤을 만들기 위해 인덱스 배열을 만들어 정점의 인덱스를 넣어준다. 아래 UV 좌표를 넣는 부분이 우리가 알아야할 부분이다. 위에서도 계속 언급했지만 UV 좌표 하나는 정점 하나에 맞춰져야 한다. 즉 정점 한개당 UV 좌표 한개가 무조건 있어야 한다. 만약 같은 좌표에 다른 UV 좌표가 필요하면 같은 정점이 여러개가 필요할 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 UV 좌표를 설정해주면 &lt;strong&gt;Mesh&lt;/strong&gt; 를 건드리는 일은 끝났다. 이제 &lt;strong&gt;Material&lt;/strong&gt; 에셋을 만들거나 런타임에 직접 생성해주어 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 컴포넌트에 넣어주면 된다. 우선 만들어진 &lt;strong&gt;Material&lt;/strong&gt; 에셋을 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 컴포넌트에 넣어보자. 실행시에 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 컴포넌트가 생성되는데 이 안에 &lt;em&gt;materials&lt;/em&gt; 라는 항목이 있다. 한개가 비어있는 배열이 나올텐데, 비어있는 곳에다가 넣어주면 정상적으로 출력이 될것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/empty_material.png&quot; alt=&quot;empty material&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;정상적으로 출력이 되었으면 직접 &lt;strong&gt;Material&lt;/strong&gt; 을 만들어 넣어보자. Assset -&amp;gt; Create -&amp;gt; Material 메뉴를 사용하면 만들 수 있다. 또는 inspector 창에서 우클릭 후 Create -&amp;gt; Material 메뉴를 사용하라.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/create_material.png&quot; alt=&quot;Create material&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 만들면 새로운 &lt;strong&gt;Material&lt;/strong&gt; 이 우리를 기다린다. 위에서 했던 방법으로 직접 넣어보자. 같은 방식으로 넣어주면 똑같이 나올것이다. 이렇게 &lt;strong&gt;Material&lt;/strong&gt; 을 적용하는 방법에 대해 알아보았다. 이제 UV 좌표가 뜻하는 위치를 눈으로 확인 가능하다. UV 좌표를 조작하면서 어떤식으로 동작하는지 확인하는 것도 좋은 방법일 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/UV_mapping&quot;&gt;Wikipedia : UV Mapping&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">Handling vertices and indices 글에서 Unity 에서 정점과 인덱스를 사용해 물체를 그리는 방법에 대해서 알아보았다. 그런데 뭔가 설정해야 할것들이 빠진 것처럼 보인다. 실제로 그려지는 모습은 Unity 에서 아무것도 설정이 안되어 있을 때 나오는 분홍색으로 전부 칠해져 있다. 일반적으로 게임에서 나오는 3D 물체들은 전부 색이 칠해져 있거나 그림이 그려져 있다. 거기다가 빛을 받아서 반짝반짝이기도 할때도 있다. 이번 글에서는 3D 오브젝트에 색을 입히거나 그림을 입히는 방법에 대해서 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Mesh Components In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/14/mesh-components-in-unity/" rel="alternate" type="text/html" title="Mesh Components In Unity" />
      <published>2017-05-14T00:00:00+00:00</published>
      <updated>2017-05-14T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/14/mesh-components-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/14/mesh-components-in-unity/">&lt;p&gt;Unity 에서는 Mesh 를 활용하기 위해 몇가지의 컴포넌트를 지원한다. 간단하게 알아보자.&lt;/p&gt;

&lt;h3&gt;Mesh 를 가지고 있는 컴포넌트 : MeshFilter&lt;/h3&gt;

&lt;p&gt;이 컴포넌트는 Unity 컴퓨넌트가 아닌 &lt;strong&gt;Mesh&lt;/strong&gt; 클래스의 인스턴스를 가지고 있는 목적으로 만들어진 클래스다. &lt;strong&gt;Mesh&lt;/strong&gt; 의 인스턴스를 보관하고 외부에서 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스에 접근할 수도 있다. 다만 조금 유의해야할 사항은 사용법이다. &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/MeshFilter.html&quot;&gt;MeshFilter&lt;/a&gt; 문서를 보면 사용할 수 있는 프로퍼티가 두개가 있는데 하나는 &lt;em&gt;MeshFilter.sharedMesh&lt;/em&gt; 와 &lt;em&gt;MeshFilter.mesh&lt;/em&gt; 두개가 있다.  &lt;em&gt;MeshFilter.sharedMesh&lt;/em&gt; 는 실제 가지고 있는 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스이고 &lt;em&gt;MeshFilter.mesh&lt;/em&gt; 는 원래의 인스턴스를 복사해 새로 생성한 것을 반환하기 때문에 주의해야 한다.&lt;/p&gt;

&lt;h3&gt;Mesh 를 통해 그리는 컴포넌트 : MeshRenderer&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;MeshRenderer&lt;/strong&gt; 컴포넌트는 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스와 등록된 Material 들을 통해 화면상에서 실제로 보여주는 역할을 하는 컴포넌트다. 같은 GameObject 안에 있는 &lt;strong&gt;MeshFilter&lt;/strong&gt; 를 통해 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스에 접근한다. 또한 여러 옵션들을 통해 렌더링을 제어할 수 있다. 중요한 기능은 그림자를 받는 기능과 그림자를 생기게 하는 기능이다. 그 외에도 Unity 에서 지원하는 여러 옵션을 설정할 수 있다. 그리고 여러개의 &lt;strong&gt;Material&lt;/strong&gt; 들을 가지고 있을 수 있는데 &lt;strong&gt;Mesh&lt;/strong&gt; 의 &lt;em&gt;submesh&lt;/em&gt; 별로 &lt;strong&gt;Material&lt;/strong&gt; 을 매칭해주어야 알맞게 그릴 수 있다. 기본값은 한개이므로 특별히 세팅을 안했다면 한개씩만 넣어주면 된다.&lt;/p&gt;

&lt;h3&gt;SkinnedMeshRenderer&lt;/h3&gt;

&lt;p&gt;위에서 설명한 &lt;strong&gt;MeshRenderer&lt;/strong&gt; 와 이름이 매우 비슷하다. 앞에 &lt;em&gt;Skinned&lt;/em&gt; 라는 키워드만 붙어있다. 이름은 비슷하지만 Unity 안에서 처리되는 것은 조금 다르다. &lt;strong&gt;MeshRenderer&lt;/strong&gt; 는 정점이 실시간으로 움직이지 않는 것들을 대상으로 그리는 컴포넌트다. 하지만 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 는 다르다. 이 컴포넌트도 &lt;strong&gt;Mesh&lt;/strong&gt; 를 그리기 위해 만들어진 컴포넌트지만 특정한 &lt;em&gt;Bone&lt;/em&gt; 을 기준으로 위치를 전부 계산하고 그려야 한다.&lt;/p&gt;

&lt;p&gt;특정한 &lt;em&gt;Bone&lt;/em&gt; 을(Unity 에서는 Bone 한개마다 GameObject 하나로 나타낸다.) 기준으로 정점들을 움직이게 하게 해주는 작업을 &lt;em&gt;Rigging&lt;/em&gt; 이라고 하는데 &lt;em&gt;Rigging&lt;/em&gt; 이 적용된 것을 그릴려면 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 컴포넌트를 붙여 주어야 한다. &lt;strong&gt;MeshRenderer&lt;/strong&gt; 를 사용하면 &lt;em&gt;Bone&lt;/em&gt; 을 움직여도 움직임이 적용이 안된채로 그려져서 말짱 꽝이 되버린다.&lt;/p&gt;

&lt;h3&gt;MeshCollider&lt;/h3&gt;

&lt;p&gt;충돌 감지를 &lt;strong&gt;Mesh&lt;/strong&gt; 를 활용해서 하는 컴포넌트로 일반적으로는 안쓴다. 폴리곤의 갯수가 많으면 많을수록 체크에 병목이 생기기 때문이다. 상황에 따라 폴리곤이 적은 경우에는 써도 무방하다. 이 컴포넌트는 생성될 때 &lt;strong&gt;MeshFilter&lt;/strong&gt; 컴포넌트가 존재하면 &lt;em&gt;sharedMesh&lt;/em&gt; 를 통해 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스에 접근한다.&lt;/p&gt;

&lt;p&gt;이렇게 &lt;strong&gt;Mesh&lt;/strong&gt; 를 활용하는 여러가지 컴포넌트들에 대하여 알아보았다. 할말은 많지만 간단한 소개를 위해 쓰여졌기에 여기까지 하겠다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/class-MeshFilter.html&quot;&gt;Unity Manual - MeshFilter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/class-MeshRenderer.html&quot;&gt;Unity Manual - MeshRenderer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/class-SkinnedMeshRenderer.html&quot;&gt;Unity Manual - SkinnedMeshRenderer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/MeshFilter.html&quot;&gt;Unity ref - MeshFilter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/MeshRenderer.html&quot;&gt;Unity ref - MeshRenderer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/SkinnedMeshRenderer.html&quot;&gt;Unity ref - SkinnedMeshRenderer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서는 Mesh 를 활용하기 위해 몇가지의 컴포넌트를 지원한다. 간단하게 알아보자. Mesh 를 가지고 있는 컴포넌트 : MeshFilter 이 컴포넌트는 Unity 컴퓨넌트가 아닌 Mesh 클래스의 인스턴스를 가지고 있는 목적으로 만들어진 클래스다. Mesh 의 인스턴스를 보관하고 외부에서 Mesh 인스턴스에 접근할 수도 있다. 다만 조금 유의해야할 사항은 사용법이다. MeshFilter 문서를 보면 사용할 수 있는 프로퍼티가 두개가 있는데 하나는 MeshFilter.sharedMesh 와 MeshFilter.mesh 두개가 있다. MeshFilter.sharedMesh 는 실제 가지고 있는 Mesh 인스턴스이고 MeshFilter.mesh 는 원래의 인스턴스를 복사해 새로 생성한 것을 반환하기 때문에 주의해야 한다. Mesh 를 통해 그리는 컴포넌트 : MeshRenderer MeshRenderer 컴포넌트는 Mesh 인스턴스와 등록된 Material 들을 통해 화면상에서 실제로 보여주는 역할을 하는 컴포넌트다. 같은 GameObject 안에 있는 MeshFilter 를 통해 Mesh 인스턴스에 접근한다. 또한 여러 옵션들을 통해 렌더링을 제어할 수 있다. 중요한 기능은 그림자를 받는 기능과 그림자를 생기게 하는 기능이다. 그 외에도 Unity 에서 지원하는 여러 옵션을 설정할 수 있다. 그리고 여러개의 Material 들을 가지고 있을 수 있는데 Mesh 의 submesh 별로 Material 을 매칭해주어야 알맞게 그릴 수 있다. 기본값은 한개이므로 특별히 세팅을 안했다면 한개씩만 넣어주면 된다. SkinnedMeshRenderer 위에서 설명한 MeshRenderer 와 이름이 매우 비슷하다. 앞에 Skinned 라는 키워드만 붙어있다. 이름은 비슷하지만 Unity 안에서 처리되는 것은 조금 다르다. MeshRenderer 는 정점이 실시간으로 움직이지 않는 것들을 대상으로 그리는 컴포넌트다. 하지만 SkinnedMeshRenderer 는 다르다. 이 컴포넌트도 Mesh 를 그리기 위해 만들어진 컴포넌트지만 특정한 Bone 을 기준으로 위치를 전부 계산하고 그려야 한다. 특정한 Bone 을(Unity 에서는 Bone 한개마다 GameObject 하나로 나타낸다.) 기준으로 정점들을 움직이게 하게 해주는 작업을 Rigging 이라고 하는데 Rigging 이 적용된 것을 그릴려면 SkinnedMeshRenderer 컴포넌트를 붙여 주어야 한다. MeshRenderer 를 사용하면 Bone 을 움직여도 움직임이 적용이 안된채로 그려져서 말짱 꽝이 되버린다. MeshCollider 충돌 감지를 Mesh 를 활용해서 하는 컴포넌트로 일반적으로는 안쓴다. 폴리곤의 갯수가 많으면 많을수록 체크에 병목이 생기기 때문이다. 상황에 따라 폴리곤이 적은 경우에는 써도 무방하다. 이 컴포넌트는 생성될 때 MeshFilter 컴포넌트가 존재하면 sharedMesh 를 통해 Mesh 인스턴스에 접근한다. 이렇게 Mesh 를 활용하는 여러가지 컴포넌트들에 대하여 알아보았다. 할말은 많지만 간단한 소개를 위해 쓰여졌기에 여기까지 하겠다. 참조 Unity Manual - MeshFilter Unity Manual - MeshRenderer Unity Manual - SkinnedMeshRenderer Unity ref - MeshFilter Unity ref - MeshRenderer Unity ref - SkinnedMeshRenderer</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Handling Vertices And Indices In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/14/handling-vertices-and-indices-in-unity/" rel="alternate" type="text/html" title="Handling Vertices And Indices In Unity" />
      <published>2017-05-14T00:00:00+00:00</published>
      <updated>2017-05-14T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/14/handling-vertices-and-indices-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/14/handling-vertices-and-indices-in-unity/">&lt;p&gt;여태까지 많은 게임들은 Graphics API 를 사용하여 만들어졌다. 1992년에 OpenGL 의 첫버젼이 릴리즈 되었고 이어서 1995년에 DirectX 가 Windows Game SDK 안에 포함되어 릴리즈 되었다. 그 이후로 수많은 게임들이 이 두가지의 Graphics API 를 사용하여 개발되었다. 다만 Graphics API 를 직접 사용하려면 꽤 많은 배경지식과(선형대수학, Graphics 이론 등) 해당 Graphics API 에 대한 경험이 많이 필요했다. 즉 일반적인 프로그래머들이 접근하기 조금 어려운 분야였다. 하지만 이를 꽤 뚫어본 많은 사람들이 게임을 만들기 위한 소프트웨어 이른바 게임 엔진이라는 소프트웨어를 개발하면서 널리 퍼지게 되었고  요즘에는 많은 지식 없이 게임을 만들 수 있게 되었다.&lt;/p&gt;

&lt;p&gt;하지만 프로그래머로써 성장하려면 한계단씩 내려가 보면서 원리를 깨우쳐야 한다. 특히 게임 클라이언트 프로그래머는 결국 Graphics API 를 활용한 프로그램을 짜는 것이기 때문에 지식이 없으면 없을수록 난항을 겪기 마련이다. 수학적인 지식이 부족하면 직접 계산하는 코드를 짤수가 없고, Graphics API 의 구성을 모른다면 최적화를 할때 하나하나 삽질해가며 바꿔보아야 한다.&lt;/p&gt;

&lt;p&gt;이 게시물에서는 Graphics API 를 공부하면 처음 나오게는 지식들(정점, 폴리곤, UV)에 대해서 알아보고 Unity 에서 이 지식들을 시험해보겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;공간을 구성하는 기본 단위 : 정점(vertex)&lt;/h3&gt;

&lt;p&gt;가장 먼저 알아야것은 정점이다. 영어로는 &lt;em&gt;vertex&lt;/em&gt; 인데 이 단어는 다양한 이론에서 상이하게 다뤄지므로 헷갈릴 수도 있다. 우선 그래픽스 분야에서의 정점은 3차원 공간에서 특정 위치를 나타내는 단어다. 수학에서 흔이 쓰이는 점의 정의와 비슷하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/position_p.png&quot; alt=&quot;Position P in math&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또한 정점은 위의 수학의 점 P 의 정의와 같은 말이다. 모든 3차원 상의 물체는 점으로 이루어져 있다. 하나하나의 점이 특정한 구성 방식으로 모여 선과 면을 정의한다. 정점은 모든 물체를 표현하기 위한 기본적인 단위다.&lt;/p&gt;

&lt;h3&gt;그려지는 면의 기본 단위 : 삼각형(polygon, triangle)&lt;/h3&gt;

&lt;p&gt;위에서 정점들은 물체를 표현하기 위한 기본적인 단위라고 설명했다. 그리고 물체를 표현하려면 표면(surface)를 표현할 수 있어야 한다. 정점을 가지고 표면을 정의할 수 있는 방법은 여러가지가 있지만 정점을 최소의 갯수만 가지고 표현하려면 삼각형으로 표현하는 것이 최적의 방법이다. 그리고 Graphics API 에서도 삼각형을 기본 단위로 물체를 그린다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/rabbit_polygons.jpg&quot; alt=&quot;Rabbit&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같이 모든 물체는 삼각형을 기본으로 만들어진다.&lt;/p&gt;

&lt;h3&gt;그려지는 정보의 집합체 : Mesh&lt;/h3&gt;

&lt;p&gt;이 개념은 위에서 언급한 개념들과는 조금 다르다. 점이나 삼각형은 위상 수학에서 나올법한 내용이지만 Mesh 에 대한 내용은 소프트웨어에서 나온 개념이다. Mesh 는 3D 오브젝트가 그려질 때 필요한 정보들을 담아놓고 있는 정보 덩어리라고 할 수 있다. 위에서 언급한 여러개의 정점들과 폴리곤에 대한 여러 정보들을 가지고 있다. 위의 토끼는 결국 여러 정점들과 여러 폴리곤 정보들로 그려진다고 볼 수 있다.&lt;/p&gt;

&lt;p&gt;여기까지 기본적으로 쓰이는 용어에 대한 간단한 설명들을 살펴보았다. 이제 Unity 에서 직접 이것들을 만져볼 차례다. 우선 &lt;a href=&quot;https://github.com/hrmrzizon/3DBasicExample&quot;&gt;3DBasicExample&lt;/a&gt; 을 받아서 &lt;em&gt;edu/plane&lt;/em&gt; 브랜치로 이동한다.&lt;/p&gt;

&lt;p&gt;Unity 에서 직접 정점과 폴리곤을 조작하는 방법에 대해서 알아보기 위해 Scripts 디렉토리에 MeshTest.cs 소스코드를 보자.&lt;/p&gt;

&lt;div class=&quot;language-c# highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ModifyMesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mesh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vector3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Vector3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triangles&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
                     &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                             &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
                     &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

   &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;위 코드는 정점과 폴리곤을 구성하는 정점의 인덱스를 직접 만들어 넣어주는 코드다. &lt;strong&gt;Mesh&lt;/strong&gt; 클래스는 위에서 설명한 정점과 폴리곤의 정보 등 렌더링에 필요한 정보를 가지고 있는 데이터 뭉치다. 여기에 정점과 폴리곤 정보를 넣는다. &lt;em&gt;ModifyMesh&lt;/em&gt; 함수에서는 &lt;strong&gt;Mesh&lt;/strong&gt; 의 프로퍼티에 두개의 배열을 새로 생성하여 넣어준다. &lt;em&gt;vertices&lt;/em&gt; 는 3차원 좌표계의 정점 정보 배열로써 가장 핵심적인 데이터다. 코드에서는 4개의 점을 넣어준다. X,Z축으로 정사각형을 구성하는 정점들을 가지고 있다. &lt;em&gt;triangles&lt;/em&gt; 는 폴리곤을 표현하기 위한 정수 배열인데 여기에는 &lt;em&gt;vertices&lt;/em&gt; 배열의 인덱스들이 들어가 있다. 당연히 3개의 인덱스가 하나의 폴리곤을 구성하며 위의 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스는 두개의 폴리곤을 그리게 될것이다. 아래 소스에 주석으로 위의 정점과 인덱스들이 나타내는 것을 표현해 보았다.&lt;/p&gt;

&lt;div class=&quot;language-c# highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*
  (0,0,1) 2   3 (1,0,1)
          * - *
          | / |
          * - *
  (0,0,0) 0   1 (1,0,0)
*/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Y축에서 아래로 바라보는 뷰로 표현했다. 그리고 폴리곤을 구성하는 인덱스 배열에서 중요한게 하나있다. 바로 인덱스의 순서다. 이 코드에서 인덱스 배열이 각각 가르키는 정점의 순서를 보면 전부다 시계 방향(cw: clockwise)인 것을 알 수 있다. 만약 방향이 반시계 방향(ccw: countclockwise)으로 구성된다면 보이는 방향이 밑으로 바뀔 것이다. &lt;em&gt;mesh.triangles&lt;/em&gt; 에 들어가는 순서를 살짝 바꾸어 실행해보자.&lt;/p&gt;

&lt;div class=&quot;language-c# highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;triangles&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                         &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
                         &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;원래 보이던 방향에서 반대로 바뀐 것을 알 수 있다. 이건 꽤나 중요한 사항이다. 다른 어플리케이션에는 어떤 방향으로 설정하는지 모르겠지만 Unity 에서는 시계 방향을 기준으로 윗 방향을 보이는 기준으로 잡는다. 물론 직접 인덱스를 건드릴일은 거의 없다. 복잡한 모델들은 대부분 파일에서 불러와서 사용하기 때문이다. 하지만 모른다면 꽤나 난처해질 것이다.&lt;/p&gt;

&lt;p&gt;여기까지 직접 정점과 폴리곤을 구성하는 방법에 대해서 알아보았다. 다만 정리가 조금 안된사항들이 있다. Graphics API 에서는 정점의 배열들을 Vertex Buffer 라고 칭한다. 폴리곤을 구성하는 인덱스의 배열은 Index Buffer 라고 칭한다. 그리고 &lt;em&gt;vertices&lt;/em&gt; 는 vertex 의 복수형이다. 비슷한 표현으로는 &lt;em&gt;indcies&lt;/em&gt; 가 있다. 명칭들을 잘 알아두면 문서를 읽거나 소통할때 말하기 편하니 알아두길 바란다.&lt;/p&gt;

&lt;p&gt;자동으로 생성되는 Unity 컴포넌트가 궁금하다면 &lt;a href=&quot;/2017/05/14/mesh-components-in-unity/&quot;&gt;Mesh components in unity&lt;/a&gt;에서 확인하라.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">여태까지 많은 게임들은 Graphics API 를 사용하여 만들어졌다. 1992년에 OpenGL 의 첫버젼이 릴리즈 되었고 이어서 1995년에 DirectX 가 Windows Game SDK 안에 포함되어 릴리즈 되었다. 그 이후로 수많은 게임들이 이 두가지의 Graphics API 를 사용하여 개발되었다. 다만 Graphics API 를 직접 사용하려면 꽤 많은 배경지식과(선형대수학, Graphics 이론 등) 해당 Graphics API 에 대한 경험이 많이 필요했다. 즉 일반적인 프로그래머들이 접근하기 조금 어려운 분야였다. 하지만 이를 꽤 뚫어본 많은 사람들이 게임을 만들기 위한 소프트웨어 이른바 게임 엔진이라는 소프트웨어를 개발하면서 널리 퍼지게 되었고 요즘에는 많은 지식 없이 게임을 만들 수 있게 되었다. 하지만 프로그래머로써 성장하려면 한계단씩 내려가 보면서 원리를 깨우쳐야 한다. 특히 게임 클라이언트 프로그래머는 결국 Graphics API 를 활용한 프로그램을 짜는 것이기 때문에 지식이 없으면 없을수록 난항을 겪기 마련이다. 수학적인 지식이 부족하면 직접 계산하는 코드를 짤수가 없고, Graphics API 의 구성을 모른다면 최적화를 할때 하나하나 삽질해가며 바꿔보아야 한다. 이 게시물에서는 Graphics API 를 공부하면 처음 나오게는 지식들(정점, 폴리곤, UV)에 대해서 알아보고 Unity 에서 이 지식들을 시험해보겠다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Unity Project Setting For Git</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/11/unity-project-setting-for-git/" rel="alternate" type="text/html" title="Unity Project Setting For Git" />
      <published>2017-05-11T00:00:00+00:00</published>
      <updated>2017-05-11T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/11/unity-project-setting-for-git</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/11/unity-project-setting-for-git/">&lt;p&gt;꽤 많은 사람들이 Git 을 사용한다. SVN 보다 더 널리 알려지고 유용하게 쓰이는 VCS 로써 굉장히 많이 쓰이는 시스템이다. Unity 를 사용할 때도 Git 을 이용해 버젼 관리를 할 수 있는데, 아무런 세팅없이 사용하기엔 조금 문제가 있다. 보통 대두되는 문제는 두가지다.&lt;/p&gt;

&lt;p&gt;첫번째는 Git 을 쓰다보면 느끼게 되는데, Git 자체는 텍스트로 구성된 데이터를 취급하려고 만들어졌기 때문에 바이너리 데이터에 대한 솔루션이 없었다. 만약 큰 바이너리 파일이 존재하면 커밋마다 계속 스냅샷을 갱신하기 때문에 커밋에 쓰이는 데이터는 기하급수적으로 늘어나게 된다. 보통 텍스쳐나 영상을 가지고 있게 되면 위의 상황에 부딫친다. 두번째는 조금 귀찮은 경우다. Unity 는 자체적으로 여러 데이터들의 확장자를 지정하여 파일을 사용하는데 커밋을 병합(merge) 할 때 Unity 에서 지원하는 파일에 충돌이 생겨 직접 손봐주어야 할 때, 일정 형식에 맞추지 않으면 끔찍한 사태가 일어나게 된다. 문제가 대표적으로 생기는 파일은 씬(.scene) 파일이다.&lt;/p&gt;

&lt;p&gt;여러가지 세팅을 해주어야 하니 차근차근 살펴보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1&gt;Unity 프로젝트 설정하기&lt;/h1&gt;

&lt;p&gt;우선 외부 파일을 세팅하기전에 Unity 프로젝트에서 간단한 세팅을 해주어야 한다. 우선 상위 메뉴의 Edit -&amp;gt; ProjectSettings -&amp;gt; Editor 를 선택해 Inspector 창을 보자. 아래 방법을 따라하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/unity-edit-ps-editor.png&quot; alt=&quot;Unity Go to editor&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그러면 여러 설정이 뜨는데 여기서 두가지면 살펴보면 된다. 첫번째는 Version control 이라는 항목이다. 이 항목은 VCS 을 설정하거나 Unity 에서 .meta 파일을 사용해 데이터를 저장하는 두가지의 큰 방식으로 나뉘는데 Unity Personal 에서는 VCS 를 설정하는 것은 사용할 수 없다. 그러므로 Personal 라이센스 사용자는 결국 두가지 방식 중 하나만 고르면 된다. .meta 파일을 숨김파일로 지정하느냐 일반 파일로 지정하느냐의 차이인데 Git 에서는 숨김 파일은 취급하지 않기 때문에 Visible Meta Files 옵션을 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/unity_editor_version_control.png&quot; alt=&quot;Unity VCS Setting&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두번째는 Asset Serialization 이라는 항목이다. 이 옵션은 Unity 프로젝트에서 Unity 에서 직접 지정하는 확장자가 붙은 파일들을 어떻게 취급하냐를 설정하는 옵션이다. Unity 프로젝트에서는 두가지 방식으로 파일을 취급할 수 있는데 하나는 텍스트 형식으로 취급하는 것과 하나는 바이너리 형식으로 취급하는 것이다. 옵션의 선택지를 보면 총 3가지 인데 맨처음 Mixed 는 Unity 에서 파일마다 지정한 방식대로 텍스트냐 바이너리냐를 따라가는 것이고 나머지 두개(Force Text, Force Binary)는 무조건 한가지 방식으로 모든 파일들을 통일하는 것이다. 여러 용도로 텍스트를 사용하므로 Force Text 옵션을 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/unity_editor_asset_serialization.png&quot; alt=&quot;Unity Asset Serialization&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 Unity 프로젝트에서 설정해주어야 하는 것들은 끝이다. 다음은 외부에서 설정해주어야 하는 것들을 살펴보자.&lt;/p&gt;

&lt;h1&gt;Git 설정 파일 추가하기&lt;/h1&gt;

&lt;p&gt;Git 에서는 여러 방식의 설정을 지원한다. 그 중에서도 우리는 많이 쓰이는 두가지 방식의 설정에 대해서 알아볼 것이다. 두가지 방식 모두 파일에 설정 정보를 저장한 후 해당 파일이 스테이징 공간에 들어가게 되면 로컬 레포지토리에 바로 적용된다. 보통은 맨 처음 커밋에 넣어주어 앞으로의 커밋들에 대비한다.&lt;/p&gt;

&lt;h2&gt;스테이징 공간의 이름 필터 : .gitignore&lt;/h2&gt;

&lt;p&gt;Git 에서 새로운 커밋을 만들 때, 파일들을 임시로 담아놓는 공간이 있다. 이 공간을 스테이징 영역이라 하는데 Git 로컬 레포지토리에 등록되어 있고 내용이 변경된 파일이나, 아예 등록되지 않은 파일을 넣어서 커밋으로 만드는 임시 공간이다. 비유를 하자면 장바구니(stage area)에 미리 커밋할 것을 넣어놓고 사는(commit) 행위로 비유할 수 있겠다. 하여튼 스테이징 영역에서 무언가 필터 역할을 하는 특수 옵션 파일이 .gitignore 인데 무언가 무시한다는 것만 알 수 있다.&lt;/p&gt;

&lt;p&gt;위 문단에서도 말했지만 스테이징 영역에 들어갈 수 있는 것들은 파일이 등록되어 변경된 파일이나, 아예 등록되지 않은 파일인데 .gitignore 안에 패턴에 해당되고, 로컬 레포지토리 안에 등록되지 않은 파일은 스테이징 영역의 후보에서도 아예 사라진다. 즉 패턴을 .gitignore 파일안에 등록하면 앞으로 등록되지 않은 파일 중에 패턴에 맞는 파일들은 스테이징 영역에도 저장할 수 없다. 더 쉽게 말하자면 어떤 특정한 이름을 가지면 아예 커밋을 못하게 할 수 있다는 것이다.&lt;/p&gt;

&lt;p&gt;Unity 프로젝트에서 아주 중요한 패턴이 몇개 있다. 이를 예로 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Library/*
*/Library/*
Temp/*
*/Temp/*&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 예시들은 Unity 프로젝트에서 Git 리모트 레포지토리에 보내면 안되는 부모 디렉토리 이름들이다. Library 디렉토리는 프로젝트의 캐시 데이터로써 프로젝트를 실행하려면 Unity 에서 계산을 해서 만드는 파일이지만 굳이 없어도 알아서 만들어지기에 꼭 필요는 없는 파일이다. 자세한 사항은 &lt;a href=&quot;/2017/04/02/unity-project-directory-structue/&quot;&gt;링크&lt;/a&gt;에서 확인하라. * 의 뜻은 앞에 적어도 한개 이상의 아무 글자가 있어야 한다는 뜻이다. 즉 Library 디렉토리의 하위의 파일들을 포함한다는 뜻이고, .gitignore 파일안에 있으니 하위의 파일들을 전부 제외한다는 뜻이다.&lt;/p&gt;

&lt;p&gt;이런 여러 패턴들을 저장해 쓸데없는 파일들을 스테이징 영역에 들어갈 후보에서 제외해 편하게 스테이징 작업을 할 수 있게 해준다. 거의 모든 프로젝트에서 메타파일들을 제외하기 위해 쓴다. 그만큼 굉장히 유용한 옵션이다. 그리고 굳이 하나하나 패턴을 추가해줄 필요 없이 자동으로 패턴을 가져올 수 있는 사이트가 있다. 바로 &lt;a href=&quot;https://www.gitignore.io/&quot;&gt;https://www.gitignore.io/&lt;/a&gt; 다. 여러 플랫폼을 설정해줄 수 있으니 사용하는 것에 따라 다르게 설정해주면 된다.&lt;/p&gt;

&lt;h2&gt;디렉토리별 속성 지정 : .gitattributes&lt;/h2&gt;

&lt;p&gt;Git 시스템은 텍스트 파일을 기준으로 만들어져 있다고 위에서 설명했었다. 그래서 파일을 병합(merge)를 할때나 비교(diff) 할 때 바이너리 파일이면 문제가 있다고도 말했다. .gitattributes 는 디렉토리나 파일 단위로 Git 에서 설정한 것과 다른 설정을 할수도 있다. 파일이 위치하는 디렉토리부터 병합 도구(mergetool)과 비교 도구(difftool) 을 확장자별로 설정할 수도 있고, 파일의 유형을 설정해서 Git 시스템이 다르게 동작하게도 할 수 있다. 즉 디렉토리별로 설정을 하는 방법이라 보면 될듯하다.&lt;/p&gt;

&lt;p&gt;갑자기 .gitattributes 에 대해 설명을 하는 이유는 .gitattributes 에 Unity 에서 사용하는 전용 파일이나 용량이 큰 텍스쳐, 사운드, 영상 파일을 따로 효율적으로 관리할 수 있기 때문이다. &lt;a href=&quot;https://gist.github.com/nemotoo/b8a1c3a0f1225bb9231979f389fd4f3f&quot;&gt;링크&lt;/a&gt; 에 쓰여있는 내용을 조금 잘라서 확인해보자. 실제 파일로도 직접 사용하면 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;…&lt;/p&gt;

  &lt;p&gt;*.unity merge=unityyamlmerge eol=lf&lt;/p&gt;

  &lt;p&gt;*.prefab merge=unityyamlmerge eol=lf&lt;/p&gt;

  &lt;p&gt;…&lt;/p&gt;

  &lt;p&gt;*.jpg filter=lfs diff=lfs merge=lfs -text&lt;/p&gt;

  &lt;p&gt;*.jpeg filter=lfs diff=lfs merge=lfs -text&lt;/p&gt;

  &lt;p&gt;…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 텍스트는 Unity 프로젝트에서 사용하는 .gitattributes 파일 내용의 일부분이다. 다만 다른 내용은 없고 전부 중복되는 내용이기에 일부분만 가져왔다. 여기서도 * 을 사용해 파일의 패턴을 표현했다. .gitattributes 에서는 전부 확장자만 체크를 해서 파일의 타입을 지정했다. 여기서 지정한 파일의 타입은 두가지로 나뉘는데 Unity 에서 사용하는 파일의 확장자와 큰 크기의 파일 확장자를 지정해 주었다. Unity 에서 지정한 파일 확장자는 병합(merge)시에 사용하는 툴을 git 기본 mergetool 이 아닌 Unity 에서 기본으로 지원해주는 UnityYAMLMerge 라는 커맨드라인 툴을 사용하도록 지정하고 추가로 줄끝을 어떻게 구분하는지 옵션값을 넣어준다. 큰 크기의 파일 확장자는 기본 병합 도구와(mergetool) 비교 도구(difftool) 그리고 필터라는 것을 lfs 라는것으로 전부 설정해 주었다. lfs 라는 것은 큰 크기의 파일을 취급하는 것이다. 정확히는 매 커밋마다 큰 파일을 가지고 있는 것이 아니라 큰 파일의 포인터를 저장해서 변경시에만 새로운 파일을 저장한다.&lt;/p&gt;

&lt;p&gt;이렇게 파일을 설정하면 끝이라고 생각하겠지만 아직은 아니다. 위에서 설정한 UnityYAMLMerge 와 LFS 정보를 설정시켜주어야 한다. &lt;a href=&quot;https://docs.unity3d.com/Manual/SmartMerge.html&quot;&gt;링크&lt;/a&gt; 에서 UnityYAMLMerge 의 정보를 설정시켜주는 방법이 나온다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[mergetool “unityyamlmerge”]&lt;/p&gt;

  &lt;p&gt;trustExitCode = false&lt;/p&gt;

  &lt;p&gt;cmd = “path to UnityYAMLMerge” merge -p “$BASE” “$REMOTE” “$LOCAL” “$MERGED”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 텍스트를 사용자 홈 디렉토리에 존재하는 .gitconfig(–global) 에 직접 위와같이 써넣거나 bash 에서 직접 설정해주면 된다. 중간에 &lt;em&gt;“path to UnityYAMLMerge”&lt;/em&gt; 는 설치된 Unity 디렉토리 안에 “/Editor/Data/Tools/UnityYAMLMerge.exe” 위치에 있다. 그리고 기본으로 쓰는 merge.tool 정보는 바꾸지 않는다. .gitattributes 에서 확장자별로 바꿔주기 때문에 굳이 쓰지 않는다.&lt;/p&gt;

&lt;p&gt;LFS 의 설정방법은 매우 단순하다. &lt;a href=&quot;https://git-lfs.github.com/&quot;&gt;링크&lt;/a&gt;에서 설치파일을 받아서 설치를 완료하면 알아서 설정을 해준다. 굉장히 편하다. ‘git config –system –list’ 명령어로 lfs 가 설정된 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/gitconfigsystem.png&quot; alt=&quot;Git config for lfs&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 세팅하면 lfs 자체의 세팅은 간단하게 끝이 난다. 하지만 계속 사용하다 보면 상당히 귀찮은게 한가지 있다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/openssh_re-authorize.png&quot; alt=&quot;OpenSSH - authorize&quot; /&gt;&lt;/p&gt;

&lt;p&gt;lfs 가 설정되어 있고, lfs 필터를 사용하는 파일이 존재하면 파일마다 서명을 하는지는 모르겠지만 저 창이 뜨면서 계~속 비밀번호를 치라고 한다. 굉장히 귀찮다. 그래서 Github 에서는 사용자들을 위한 Credential-Manager 를 사용하라고 권고한다. 여러 방법이 있지만 가장 좋은 방법은 OS 자체에서 제공하는 방법을 사용하는 것이다. Windows 사용자들은 이 &lt;a href=&quot;https://help.github.com/articles/caching-your-github-password-in-git/&quot;&gt;링크&lt;/a&gt;를 OSX 나 리눅스 사용자들은 이 &lt;a href=&quot;https://help.github.com/articles/updating-credentials-from-the-osx-keychain/&quot;&gt;링크&lt;/a&gt;를 확인하면 된다.&lt;/p&gt;

&lt;p&gt;여기까지 두가지 옵션을 설정하는 방법에 대해서 알아보았다. UnityYAMLMerge 와 LFS 설정이 되어 있으면 &lt;a href=&quot;https://gist.github.com/nemotoo/b8a1c3a0f1225bb9231979f389fd4f3f&quot;&gt;.gitattributes&lt;/a&gt; 와 &lt;a href=&quot;https://www.gitignore.io&quot;&gt;.gitignore&lt;/a&gt; 파일만 Git 시스템에 넣어주면 앞으로 편하게 설정이 가능하다. 파일을 구할 수 있는 링크를 이름에 넣어놓았으니 직접 받아서 가져가면 된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gitignore.io&quot;&gt;www.gitignore.io&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/nemotoo/b8a1c3a0f1225bb9231979f389fd4f3f&quot;&gt;Gist : Unity .gitattributes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://git-lfs.github.com/&quot;&gt;Git-lfs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/SmartMerge.html&quot;&gt;Unity ref : SmartMerge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://git-scm.com/book/ko/v2/Git%EB%A7%9E%EC%B6%A4-Git-Attributes&quot;&gt;git-scm : .gitattributes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="git" />
      
        <category term="merge" />
      
        <category term="unity" />
      

      

      
        <summary type="html">꽤 많은 사람들이 Git 을 사용한다. SVN 보다 더 널리 알려지고 유용하게 쓰이는 VCS 로써 굉장히 많이 쓰이는 시스템이다. Unity 를 사용할 때도 Git 을 이용해 버젼 관리를 할 수 있는데, 아무런 세팅없이 사용하기엔 조금 문제가 있다. 보통 대두되는 문제는 두가지다. 첫번째는 Git 을 쓰다보면 느끼게 되는데, Git 자체는 텍스트로 구성된 데이터를 취급하려고 만들어졌기 때문에 바이너리 데이터에 대한 솔루션이 없었다. 만약 큰 바이너리 파일이 존재하면 커밋마다 계속 스냅샷을 갱신하기 때문에 커밋에 쓰이는 데이터는 기하급수적으로 늘어나게 된다. 보통 텍스쳐나 영상을 가지고 있게 되면 위의 상황에 부딫친다. 두번째는 조금 귀찮은 경우다. Unity 는 자체적으로 여러 데이터들의 확장자를 지정하여 파일을 사용하는데 커밋을 병합(merge) 할 때 Unity 에서 지원하는 파일에 충돌이 생겨 직접 손봐주어야 할 때, 일정 형식에 맞추지 않으면 끔찍한 사태가 일어나게 된다. 문제가 대표적으로 생기는 파일은 씬(.scene) 파일이다. 여러가지 세팅을 해주어야 하니 차근차근 살펴보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Recommand About Gpu</title>
      
      <link href="https://hrmrzizon.github.io/2017/05/06/recommand-about-gpu/" rel="alternate" type="text/html" title="Recommand About Gpu" />
      <published>2017-05-06T00:00:00+00:00</published>
      <updated>2017-05-06T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/05/06/recommand-about-gpu</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/05/06/recommand-about-gpu/">&lt;h2&gt;Graphics?&lt;/h2&gt;

&lt;p&gt;예전부터 꽤 많은 게임들이 GPU 를 활용하는 Graphics API 를 사용하여 만들어졌다. 그래서 예전에는 직접 게임을 만드려면 Graphics API 를 사용하여 기본적인 렌더링 기능을 구현한 후에 만들어야 했었다. 단순한 2D 게임조차 말이다. 하지만 요즘은 Unity 와 Unreal Engine 4 가 게임 엔진의 쌍두마차를 이루며 게임 엔진의 기능들을 한껏 활용해 비교적 간단하고 빠르게 게임을 만든다. 그렇기에 요즘 꽤 많은 게임 프로그래머들이 Graphics API 를 직접 마주할일은 적어지고 아랫단에서 이루어지는 여러 현상들에 대해 무지해질 가능성이 매우 높아졌다. 또한 기성세대의 게임 프로그래머들은 이 현상에 대해 부정적인 의견들을 분출하고 있다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;필자 또한 현세대의 주니어 게임 프로그래머로써 Graphics API 를 직접 마주할일은 없다. 거의 모든 부분의 처리를 엔진에서 해주기 때문이다. 하지만 한계가 올때도 있다. 렌더링 성능으로 문제가 생겼을 때 이를 고칠 수 있는 사람은 당연히 기본적인 지식이 있고 이에 대해 많은 경험이 있는 사람이 고칠 수 있다. 아주 간단한 문제라도 지식이 없는 사람과 있는 사람의 차이는 질적으로나 시간적으로나 꽤 많은 차이가 난다.&lt;/p&gt;

&lt;p&gt;간단한 예시를 들자면 일반적인 forward rendering 구조에서는 광원(lighting)이 많아질 수록 병목이 심해진다. 그래서 대부분 라이트맵, 노말맵을 활용하고 광원은 최소의 갯수로 유지하려고 한다. 하지만 이런 지식이 없는 채로 Unity 에서 간단히 light 컴포넌트를 여러개 놓고 한참 개발하다가 나중에 성능이 안나오는걸 확인 했을 때 엄청난 시간적 손실을 보게 될것이다.&lt;/p&gt;

&lt;p&gt;한가지 예시를 더 들어보자면, GPU 는 빠른 렌더링을 위해 GPU 전용 RAM 에 정점, 텍스쳐 정보들을 저장한다. 즉 컴퓨터의 RAM 과 다른 물리적 임시 공간이 있다는 소리다. 그래서 Graphics API 를 사용해보면 여러 정보들(정점, 인덱스, uv 등)을 정보들을 참조할 때 따로 API 를 사용해 저장한다. 그런데 게임 엔진의 사용자가 변환을 통한 이동이 아닌 정점을 직접 이동시키고 싶다는 생각을 했을 때 이런 내부적인 상황을 고려하지 못한다면 잘 동작할 수도 있지만 성능이 좋지 않게 나올 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/app_layer_by_programmers_view.jpg&quot; alt=&quot;app layer&quot; class=&quot;center-image&quot; /&gt;
출처 : &lt;a href=&quot;http://slideplayer.com/slide/8511485/&quot; class=&quot;center&quot;&gt;Introduction to OpenGL in SlidePlayer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;결국 게임을 만들다보면 이런 것들에 부딫힐 수 밖에 없기 때문에 게임 프로그래머를 그만두지 않는한 결국 직면 해야한다. Graphics API 에 대한 자료들은 상당히 많기에 관련된 자료들은 배제하고 더 아래에 있는 GPU 에서 이루어지는 현상에 대해 다루는 자료를 소개해보려 한다. 위 그림의 hardware and software 단계의 “hardware” 부분의 설명들이라 보면 된다.&lt;/p&gt;

&lt;h2&gt;1. &lt;a href=&quot;https://simonschreibt.de/gat/renderhell/&quot;&gt;Render Hell&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;이 페이지는 프로그래머 입장에서 알아야할 GPU 의 동작 정보를 정리해놓은 영문 웹 페이지다. 꽤나 깔끔하고 이해를 위한 영상도 많다. 영어를 못한다면 구글 번역기와 함께 동영상을 보면서 이해하면 충분히 내용을 숙지할 수 있다. 저자는 Game Artist 로써 본인도 정리되어 있는 자료가 없기에 만들었다고 서론이 쓰여있다. 또한 이 블로그를 조금 더 살펴보면 재미있는 자료들이 꽤 있으니 잘 활용하길 바란다.&lt;/p&gt;

&lt;h2&gt;2. &lt;a href=&quot;http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;amp;ejkGb=KOR&amp;amp;barcode=9788994774008&quot;&gt;대규모 병렬 프로세서 프로그래밍&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;2011년에 초판이 인쇄된 몇년이 지난 책이다. 하지만 이 책안의 내용은 NVidea 기준의 GPU 의 동작원리를 설명하고 CUDA 를 이해하게 해준다. 또한 한글로 번역된 책은 거의 없고, 이렇게 자세하게 내용이 적힌 책은 몇권 되지도 않는다. 게임 프로그래머로써 GPU 의 동작을 이해한다는 이 글의 범주는 약간 벗어났으나 내용을 포함하고 있기에 추천한다.&lt;/p&gt;

&lt;p&gt;GPU 의 동작이 적혀진 자료는 많지 않다. 수요가 많은 자료도 아닐 뿐더러 지식들의 가치도 높기 때문이다. 그래서 이 글을 지속적으로 업데이트를 할 예정이다. 자료를 모으는 용도도 있지만 제일 중요한건 필자도 지식이 별로 없는 편이라 공부 용도로 쓸려고 한다.&lt;/p&gt;

&lt;h2&gt;3. &lt;a href=&quot;https://developer.nvidia.com/content/life-triangle-nvidias-logical-pipeline&quot;&gt;Life of triangle&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;NVidea 공식 블로그 홈페이지에 올라온 글이다. NVidea GPU Architecture 들과 함께 폴리곤 하나가 어떻게 그려지는지에 대해 쓰여져 있는 간단한 글타래다. 이 사이트 역시 꽤 많은 글들이 올라와 있으니 궁금할때 보면 좋을 듯 하다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://pixeljetstream.blogspot.kr/2015/02/life-of-triangle-nvidias-logical.html&quot;&gt;개인 블로그 링크&lt;/a&gt; : 같은 글이 있다. 검은색 배경/흰 글씨를 선호하면 여기서 보면된다.&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-hyeok Kim</name>
          
          
        </author>
      

      
        <category term="common" />
      
        <category term="game" />
      
        <category term="try" />
      

      

      
        <summary type="html">Graphics? 예전부터 꽤 많은 게임들이 GPU 를 활용하는 Graphics API 를 사용하여 만들어졌다. 그래서 예전에는 직접 게임을 만드려면 Graphics API 를 사용하여 기본적인 렌더링 기능을 구현한 후에 만들어야 했었다. 단순한 2D 게임조차 말이다. 하지만 요즘은 Unity 와 Unreal Engine 4 가 게임 엔진의 쌍두마차를 이루며 게임 엔진의 기능들을 한껏 활용해 비교적 간단하고 빠르게 게임을 만든다. 그렇기에 요즘 꽤 많은 게임 프로그래머들이 Graphics API 를 직접 마주할일은 적어지고 아랫단에서 이루어지는 여러 현상들에 대해 무지해질 가능성이 매우 높아졌다. 또한 기성세대의 게임 프로그래머들은 이 현상에 대해 부정적인 의견들을 분출하고 있다.</summary>
      

      
      
    </entry>
  
  
</feed>
