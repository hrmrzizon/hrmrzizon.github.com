<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko">
  <generator uri="http://jekyllrb.com" version="3.6.2">Jekyll</generator>
  
  
  <link href="https://hrmrzizon.github.io/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://hrmrzizon.github.io/" rel="alternate" type="text/html" hreflang="ko" />
  <updated>2017-11-03T04:43:39+00:00</updated>
  <id>https://hrmrzizon.github.io//</id>

  
    <title type="html">Appocrypha</title>
  

  
    <subtitle>store limitless knowledges</subtitle>
  

  
    <author>
        <name>Su-Hyeok Kim</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Shader Pipeline 4 Geometry Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader/" rel="alternate" type="text/html" title="Shader Pipeline 4 Geometry Shader" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-4-geometry-shader/">&lt;p&gt;“&lt;a href=&quot;/2017/10/31/shader-pipeline-3-fragment-shader0/&quot;&gt;Fragemnt Shader&lt;/a&gt;” 에서 &lt;em&gt;Fragment Shader&lt;/em&gt; 에 대해 알아보았다. 다음은 &lt;em&gt;Geometry Shader&lt;/em&gt; 에 대해서 써보려 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Geometry Shader&lt;/em&gt; 는 쉐이더 파이프라인에서 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 넘어가기 전의 &lt;em&gt;Geometry Stage&lt;/em&gt; 의 마지막 단계로써 이전 쉐이더에서 넘긴  &lt;em&gt;Primitive&lt;/em&gt; 데이터(point, line, triangle..)를 프로그래머가 원하는 복수의 &lt;em&gt;Primitive&lt;/em&gt; 데이터로 변환할 수 있다. 삼각형을 삼각형의 중심을 나타내는 점으로 변환하는 쉐이더를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;[maxvertexcount(1)]
void geom(vertexOutput input[3], inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream)
{
    geometryShaderOutput o;

    o.vertex = (input[0].vertex + input[1].vertex + input[2].vertex) / 3;

    pointStream.Append(o);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;매우 간단한 코드다. 간략하게 설명하자면, 맨 윗줄의 &lt;em&gt;maxvertexcount&lt;/em&gt; 는 해당 지오메트리 쉐이더에서 &lt;em&gt;Stream&lt;/em&gt; 으로 넘길 정점별 데이터의 갯수를 뜻한다. &lt;em&gt;Geometry Shader&lt;/em&gt; 한번당 &lt;em&gt;Stream&lt;/em&gt; 으로 넘길 &lt;em&gt;maxvertexcount&lt;/em&gt; 의 한계는 정해지지 않았지만 크기는 1024 바이트로 정해져 있기 때문에 적절하게 사용해야 겠다. 그 다음줄의 인자들에 대해서 설명하면, 첫번째 &lt;em&gt;vertexOutput input[3]&lt;/em&gt; 은 정해진 프리미티브의 값들을 뜻한다. 여기서는 삼각형을 기준으로 만들었기 때문에 정점별 정보가 3개가 있다. _inout PointStream&lt;geometryOutput&gt; pointStream_ 은 _Geometry Shader_ 의 최종 출력을 해주는 오브젝트다. _PointStream_ 은 점 프리미티브의 데이터를 받는 _Stream_ 으로써, 프리미티브가 다르면 각자 다른것을 사용할 수 있다.([MSDN : Getting Started with the Stream-Output Stage](https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx)) 부등호 안에 있는 것은 일반적으로 알려진 제너릭이나 템플릿의 형태와 같으니 안에 출력으로 넘길 구조체를 넘겨주면 된다. 함수의 내용은 삼각형을 구성하는 각 정점의 위치의 평균을 구해 하나의 정점 정보만 _Stream_ 에 넘긴다.&lt;/geometryOutput&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stream&lt;/em&gt; 은 총 두가지의 역할을 한다. 하나는 &lt;em&gt;Rasterizer&lt;/em&gt; 단계로 넘겨서 쉐이더에서 처리를 할 수 있게 하는 통로 역할을 하고, 다른 하나는 드라이버 레벨에서 데이터를 출력해주는 통로 역할을 한다. 두가지의 일을 하기 때문에 &lt;em&gt;Stream&lt;/em&gt; 의 개념으로 추상화한 것인가 싶다. 그리고 하나의 &lt;em&gt;Geometry Shader&lt;/em&gt; 에서 여러개의 &lt;em&gt;Stream&lt;/em&gt; 으로 출력이 가능하긴 하다. 최대 4개의 &lt;em&gt;Stream&lt;/em&gt; 을 사용할 수 있다. &lt;em&gt;Stream&lt;/em&gt; 을 선택해서 데이터를 받아올 수도 있으며, &lt;em&gt;Rasterizer&lt;/em&gt; 로 보낼수도 있다. 자세한 사항은 &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471424.aspx&quot;&gt;MSDN : How To: Index Multiple Output Streams &lt;/a&gt; 에서 확인하면 되겠다.&lt;/p&gt;

&lt;p&gt;활용할 수 있는 다른 기능이 하나 더 있다. &lt;em&gt;instance&lt;/em&gt; 기능이다. 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;[instance(3)]
[maxvertexcount(1)]
void geom(vertexOutput input[3], uint InstanceID : SV_GSInstanceID, inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream)
{
    geometryShaderOutput o;

    o.vertex = input[InstanceID].vertex;

    pointStream.Append(o);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 코드는 삼각형의 세개의 정점 위치를 넘기는 코드다. 달라진 것은 &lt;em&gt;instance(3)&lt;/em&gt; 코드가 붙고, &lt;em&gt;uint InstanceID : SV_GSInstanceID&lt;/em&gt; 파라미터가 생겨 코드 안에서 이를 활용한다. &lt;em&gt;instance(x)&lt;/em&gt; 에 들어가는 x 는 반복하는 횟수를 뜻하고, &lt;em&gt;InstanceID&lt;/em&gt; 파라미터는 반복하는 인덱스를 뜻한다. 같은 입력을 여러번 받아서 일정한 수만큼 반복하는 것이다.  &lt;em&gt;instance&lt;/em&gt; 속성에 들어가는 숫자의 한계는 32까지다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Geometry Shader&lt;/em&gt; 는 &lt;em&gt;Shader Model 4.0&lt;/em&gt; 에서 추가되었으며 뒤에 추가적으로 알아본 &lt;em&gt;multiple stream&lt;/em&gt; 과 &lt;em&gt;instance&lt;/em&gt; 키워드는 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 에서 확장된 기능들이다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509609.aspx&quot;&gt;MSDN : Geometry-Shader Object&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx&quot;&gt;MSDN : Getting Started with the Stream-Output Stage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471424.aspx&quot;&gt;MSDN : How To: Index Multiple Output Streams&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471425.aspx&quot;&gt;MSDN : How To: Instance a Geometry Shader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/600141-limit-on-maxvertexcount-gs/&quot;&gt;GameDev : limit on maxvertexcount() GS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">“Fragemnt Shader” 에서 Fragment Shader 에 대해 알아보았다. 다음은 Geometry Shader 에 대해서 써보려 한다. Geometry Shader 는 쉐이더 파이프라인에서 Rasterizer Stage 넘어가기 전의 Geometry Stage 의 마지막 단계로써 이전 쉐이더에서 넘긴 Primitive 데이터(point, line, triangle..)를 프로그래머가 원하는 복수의 Primitive 데이터로 변환할 수 있다. 삼각형을 삼각형의 중심을 나타내는 점으로 변환하는 쉐이더를 보자. [maxvertexcount(1)] void geom(vertexOutput input[3], inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream) { geometryShaderOutput o; o.vertex = (input[0].vertex + input[1].vertex + input[2].vertex) / 3; pointStream.Append(o); } 매우 간단한 코드다. 간략하게 설명하자면, 맨 윗줄의 maxvertexcount 는 해당 지오메트리 쉐이더에서 Stream 으로 넘길 정점별 데이터의 갯수를 뜻한다. Geometry Shader 한번당 Stream 으로 넘길 maxvertexcount 의 한계는 정해지지 않았지만 크기는 1024 바이트로 정해져 있기 때문에 적절하게 사용해야 겠다. 그 다음줄의 인자들에 대해서 설명하면, 첫번째 vertexOutput input[3] 은 정해진 프리미티브의 값들을 뜻한다. 여기서는 삼각형을 기준으로 만들었기 때문에 정점별 정보가 3개가 있다. _inout PointStream pointStream_ 은 _Geometry Shader_ 의 최종 출력을 해주는 오브젝트다. _PointStream_ 은 점 프리미티브의 데이터를 받는 _Stream_ 으로써, 프리미티브가 다르면 각자 다른것을 사용할 수 있다.([MSDN : Getting Started with the Stream-Output Stage](https://msdn.microsoft.com/en-us/library/windows/desktop/bb205122.aspx)) 부등호 안에 있는 것은 일반적으로 알려진 제너릭이나 템플릿의 형태와 같으니 안에 출력으로 넘길 구조체를 넘겨주면 된다. 함수의 내용은 삼각형을 구성하는 각 정점의 위치의 평균을 구해 하나의 정점 정보만 _Stream_ 에 넘긴다. Stream 은 총 두가지의 역할을 한다. 하나는 Rasterizer 단계로 넘겨서 쉐이더에서 처리를 할 수 있게 하는 통로 역할을 하고, 다른 하나는 드라이버 레벨에서 데이터를 출력해주는 통로 역할을 한다. 두가지의 일을 하기 때문에 Stream 의 개념으로 추상화한 것인가 싶다. 그리고 하나의 Geometry Shader 에서 여러개의 Stream 으로 출력이 가능하긴 하다. 최대 4개의 Stream 을 사용할 수 있다. Stream 을 선택해서 데이터를 받아올 수도 있으며, Rasterizer 로 보낼수도 있다. 자세한 사항은 MSDN : How To: Index Multiple Output Streams 에서 확인하면 되겠다. 활용할 수 있는 다른 기능이 하나 더 있다. instance 기능이다. 아래 코드를 보자. [instance(3)] [maxvertexcount(1)] void geom(vertexOutput input[3], uint InstanceID : SV_GSInstanceID, inout PointStream&amp;lt;geometryOutput&amp;gt; pointStream) { geometryShaderOutput o; o.vertex = input[InstanceID].vertex; pointStream.Append(o); } 해당 코드는 삼각형의 세개의 정점 위치를 넘기는 코드다. 달라진 것은 instance(3) 코드가 붙고, uint InstanceID : SV_GSInstanceID 파라미터가 생겨 코드 안에서 이를 활용한다. instance(x) 에 들어가는 x 는 반복하는 횟수를 뜻하고, InstanceID 파라미터는 반복하는 인덱스를 뜻한다. 같은 입력을 여러번 받아서 일정한 수만큼 반복하는 것이다. instance 속성에 들어가는 숫자의 한계는 32까지다. Geometry Shader 는 Shader Model 4.0 에서 추가되었으며 뒤에 추가적으로 알아본 multiple stream 과 instance 키워드는 Shader Model 5.0 에서 확장된 기능들이다. 참조 자료 MSDN : Geometry-Shader Object MSDN : Getting Started with the Stream-Output Stage MSDN : How To: Index Multiple Output Streams MSDN : How To: Instance a Geometry Shader GameDev : limit on maxvertexcount() GS</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 3 Fragment Shader0</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader0/" rel="alternate" type="text/html" title="Shader Pipeline 3 Fragment Shader0" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader0</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-3-fragment-shader0/">&lt;p&gt;이전 글 : “&lt;a href=&quot;/2017/10/31/shader-pipeline-2-rasterizer/&quot;&gt;Rasterizer&lt;/a&gt;” 에서 &lt;em&gt;Rasterizer&lt;/em&gt; 에 대해 알아보았다. 이번에는 &lt;em&gt;Fragment Shader&lt;/em&gt; 을 알아보자.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인에서 &lt;em&gt;Rasterizer&lt;/em&gt; 다음에 실행되는 것은 &lt;em&gt;Programmable Shader&lt;/em&gt; 중에서 &lt;em&gt;Fragment Shader&lt;/em&gt; 이다. &lt;em&gt;Fragment Shader&lt;/em&gt; 은 &lt;em&gt;Pixel Shader&lt;/em&gt; 라고도 불리는데, 이전에 &lt;em&gt;Rasterizer&lt;/em&gt; 에서 조각낸 픽셀들을 단위로 실행되기 때문에 &lt;em&gt;Pixel Shader&lt;/em&gt; 라고 불리기도 한다. 또한 각 픽셀은 조각난 단위이기 때문에 조각의 뜻을 가진 &lt;em&gt;Fragment Shader&lt;/em&gt; 라고도 불린다. 이 글에서는 &lt;em&gt;Fragment Shader&lt;/em&gt; 로 사용할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Fragment Shader&lt;/em&gt; 의 역할은 굉장히 단순하다. &lt;em&gt;Geometry Stage&lt;/em&gt; 에서 넘어와 &lt;em&gt;Rasterizer&lt;/em&gt; 단계에서 정리된 파라미터를 받고, 해당 픽셀의 색을 반환하면 끝난다. 역할은 단순하지만 그만큼 중요한 것이 &lt;em&gt;Fragment Shader&lt;/em&gt; 다. 마지막으로 픽셀 단위로 보여주는 색을 바꿀 수 있는 &lt;em&gt;Programmable Shader&lt;/em&gt; 로써 반복하는 비용이 꽤나 많아 일반적으로 오래 걸린다고 평가되지만 색을 바꿀 수 있어 그만큼 잘쓰면 굉장한 효과를 낼 수 있는 &lt;em&gt;Programmable Shader&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/fragment_shader.jpg&quot; alt=&quot;Fragment Shader&quot; /&gt;&lt;/p&gt;

&lt;p&gt;가장 단순한 형태의 Unity 에서 사용하는 CG/HLSL 쉐이더를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#pragma fragment frag

struct v2f
{
    float4 vertex : SV_POSITION;
    float4 tangent : TANGENT;
    float3 normal : NORMAL;
    float4 texcoord : TEXCOORD0;
}

/*
  다른 코드 들..
*/

fixed4 frag(v2f i)
{
  return float4(1,1,1,1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 쉐이더는 단순하게 흰색만 출력해주는 쉐이더다. 그만큼 매우 단순하고 쉽다. 하지만 많은 것들을 표현하려면 &lt;em&gt;frag&lt;/em&gt; 함수의 코드는 점점 길어질 것이다.&lt;/p&gt;

&lt;p&gt;또한 &lt;em&gt;Fragment Shader&lt;/em&gt; 가 실행되는 시점에서 하드웨어, 드라이버 단계에서 지원하는 기능들도 있다. 일반적인 것들에 대해서 이야기 하자면 &lt;em&gt;Depth Buffer&lt;/em&gt; 와 &lt;em&gt;Stencil Buffer&lt;/em&gt; 가 있다. 두가지의 공통점은 각 픽셀 단위별로 데이터를 저장하는 버퍼들이다. &lt;em&gt;Depth Buffer&lt;/em&gt; 는 &lt;em&gt;Clip-Space&lt;/em&gt; 로 변환된 정점 값의 Z 값을 저장하는 용도로 쓰이는 버퍼로, 요즘 개발되거나 쓰이는 기술들은 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 엄청 많이 쓴다. 대표적으로 &lt;em&gt;Depth Pre-Pass&lt;/em&gt; 가 있다. &lt;em&gt;Stencil Buffer&lt;/em&gt; 는 픽셀별로 정수 데이터를 저장해서 사용하는 버퍼로써, 대부분 마스킹을 할 때 쓰인다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/kyruie/everything-about-earlyz&quot;&gt;SlideShader : Everything about Early-Z&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">이전 글 : “Rasterizer” 에서 Rasterizer 에 대해 알아보았다. 이번에는 Fragment Shader 을 알아보자. 쉐이더 파이프라인에서 Rasterizer 다음에 실행되는 것은 Programmable Shader 중에서 Fragment Shader 이다. Fragment Shader 은 Pixel Shader 라고도 불리는데, 이전에 Rasterizer 에서 조각낸 픽셀들을 단위로 실행되기 때문에 Pixel Shader 라고 불리기도 한다. 또한 각 픽셀은 조각난 단위이기 때문에 조각의 뜻을 가진 Fragment Shader 라고도 불린다. 이 글에서는 Fragment Shader 로 사용할 것이다. Fragment Shader 의 역할은 굉장히 단순하다. Geometry Stage 에서 넘어와 Rasterizer 단계에서 정리된 파라미터를 받고, 해당 픽셀의 색을 반환하면 끝난다. 역할은 단순하지만 그만큼 중요한 것이 Fragment Shader 다. 마지막으로 픽셀 단위로 보여주는 색을 바꿀 수 있는 Programmable Shader 로써 반복하는 비용이 꽤나 많아 일반적으로 오래 걸린다고 평가되지만 색을 바꿀 수 있어 그만큼 잘쓰면 굉장한 효과를 낼 수 있는 Programmable Shader 다. 가장 단순한 형태의 Unity 에서 사용하는 CG/HLSL 쉐이더를 보자. #pragma fragment frag struct v2f { float4 vertex : SV_POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; } /* 다른 코드 들.. */ fixed4 frag(v2f i) { return float4(1,1,1,1); } 해당 쉐이더는 단순하게 흰색만 출력해주는 쉐이더다. 그만큼 매우 단순하고 쉽다. 하지만 많은 것들을 표현하려면 frag 함수의 코드는 점점 길어질 것이다. 또한 Fragment Shader 가 실행되는 시점에서 하드웨어, 드라이버 단계에서 지원하는 기능들도 있다. 일반적인 것들에 대해서 이야기 하자면 Depth Buffer 와 Stencil Buffer 가 있다. 두가지의 공통점은 각 픽셀 단위별로 데이터를 저장하는 버퍼들이다. Depth Buffer 는 Clip-Space 로 변환된 정점 값의 Z 값을 저장하는 용도로 쓰이는 버퍼로, 요즘 개발되거나 쓰이는 기술들은 Depth Buffer 를 엄청 많이 쓴다. 대표적으로 Depth Pre-Pass 가 있다. Stencil Buffer 는 픽셀별로 정수 데이터를 저장해서 사용하는 버퍼로써, 대부분 마스킹을 할 때 쓰인다. 참조 자료 SlideShader : Everything about Early-Z</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 2 Rasterizer</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer/" rel="alternate" type="text/html" title="Shader Pipeline 2 Rasterizer" />
      <published>2017-10-31T00:00:00+00:00</published>
      <updated>2017-10-31T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/31/shader-pipeline-2-rasterizer/">&lt;p&gt;이전 포스트 “&lt;a href=&quot;/2017/10/30/shader-pipeline-1-vertex-shader/&quot;&gt;Vertex Shader&lt;/a&gt;” 에서 &lt;em&gt;Vertex Shader&lt;/em&gt; 에 대해 간단히 알아보았다. 이번 글에서는 &lt;em&gt;Rasterizer&lt;/em&gt; 에 대해서 간단히 써보려 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Rasterizer&lt;/em&gt; 는 쉐이더 파이프라인에 존재하는 고정 기능 단계이다. 간단하게 정의하면, &lt;em&gt;Rasterizer&lt;/em&gt; 이전 단계를 거쳐 나온 Geometry 데이터들(vertex, mesh, …)을 정해진 해상도에 맞춰 픽셀별로 조각내어 주는 단계다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i-msdn.sec.s-msft.com/dynimg/IC520311.png&quot; alt=&quot;MSDN : Traignel Rasterization Rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이는 일반적인 삼각형 폴리곤을 &lt;em&gt;Rasterizer&lt;/em&gt; 단계에서 어떻게 픽셀로 변환하는지 한눈에 알게 해놓은 사진이다. 겹치는 정도에 따라 검은색에 가깝게 해놓은 것을 볼 수있다. &lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/cc627092.aspx&quot;&gt;MSDN : Rasterization Rules&lt;/a&gt; 에서 다른 프리미티브의 &lt;em&gt;Rasterize&lt;/em&gt; 과정도 살펴볼 수 있다.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인에서 &lt;em&gt;Rasterizer&lt;/em&gt; 가 가지는 의미도 조금 특별하다. 이는 3차원 메시 데이터를 2차원 이미지 데이터로 바꿔주는 과정이기 때문에 &lt;em&gt;Geometry Stage&lt;/em&gt; 에서 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 로 넘어가는 관문이다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/cc627092.aspx&quot;&gt;MSDN : Rasterization Rules&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">이전 포스트 “Vertex Shader” 에서 Vertex Shader 에 대해 간단히 알아보았다. 이번 글에서는 Rasterizer 에 대해서 간단히 써보려 한다. Rasterizer 는 쉐이더 파이프라인에 존재하는 고정 기능 단계이다. 간단하게 정의하면, Rasterizer 이전 단계를 거쳐 나온 Geometry 데이터들(vertex, mesh, …)을 정해진 해상도에 맞춰 픽셀별로 조각내어 주는 단계다. 아래 그림을 보자. 이는 일반적인 삼각형 폴리곤을 Rasterizer 단계에서 어떻게 픽셀로 변환하는지 한눈에 알게 해놓은 사진이다. 겹치는 정도에 따라 검은색에 가깝게 해놓은 것을 볼 수있다. MSDN : Rasterization Rules 에서 다른 프리미티브의 Rasterize 과정도 살펴볼 수 있다. 쉐이더 파이프라인에서 Rasterizer 가 가지는 의미도 조금 특별하다. 이는 3차원 메시 데이터를 2차원 이미지 데이터로 바꿔주는 과정이기 때문에 Geometry Stage 에서 Rasterizer Stage 로 넘어가는 관문이다. 참조 자료 MSDN : Rasterization Rules</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 1 Vertex Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader/" rel="alternate" type="text/html" title="Shader Pipeline 1 Vertex Shader" />
      <published>2017-10-30T00:00:00+00:00</published>
      <updated>2017-10-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-1-vertex-shader/">&lt;p&gt;이번 글에서 언급할 쉐이더는 &lt;em&gt;Vertex Shader&lt;/em&gt; 다. 한글로는 &lt;em&gt;정점 쉐이더&lt;/em&gt; 라고 보통 말한다. &lt;em&gt;Vertex Shader&lt;/em&gt; 에서 할 수 있는 것은, 정점별로 들어온 정보들을 코딩을 해서 프로그래머가 원하는대로 바꾸어 다음 쉐이더에서 처리할 수 있도록 해주는 &lt;em&gt;Shader&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;Unity 에서의 CG/HLSL 일반적인 &lt;em&gt;Vertex Shader&lt;/em&gt; 코드는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#pragma vertex vert
#include &quot;UnityCG.cginc&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appdata_tan&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TANGENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NORMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXCOORD0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SV_POSITION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TANGENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NORMAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;float4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TEXCOORD0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appdata_tan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v2f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UNITY_MATRIX_MVP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tangent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texcoord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  기타 코드들..
*/&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;굉장히 단순한 &lt;em&gt;Vertex Shader&lt;/em&gt; 코드다. 코드가 단순한 만큼 이 &lt;em&gt;Shader&lt;/em&gt; 는 최소한의 역할만 하고 있다. &lt;em&gt;model-space&lt;/em&gt; 에 있는 정점을 &lt;em&gt;clipping-space&lt;/em&gt; 의 정점으로 변환 시켜 다음으로(fragment shader) 넘긴다. 위에서 위치 데이터를 바꿀 수 있다고 언급했는데, 이 변환은 정상적인 메커니즘을 통해 오브젝트를 출력하려면 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 로 넘어가기전에 반드시 정점값에 적용시켜주어야 하는 변환이다. 해당 변환에 대해서는 &lt;a href=&quot;https://docs.google.com/presentation/d/10VzsjfifKJlRTHDlBq7e8vNBTu4D5jOWUF87KYYGwlk/edit?usp=sharing&quot;&gt;Model, View, Projection&lt;/a&gt;에 설명해 놓았으니 간단하게 참고하길 바란다.&lt;/p&gt;

&lt;p&gt;위 코드에서 보여준 것들은 최소한의 것들이다. 코드를 짜는 것은 프로그래머의 역량이기 때문에 더 창의적인 것들을 할 수 있다. 쉬운 것들 중에서는 표면에서 웨이브를 주어 표면이 일렁이는 것처럼 보이게 할 수 있다. 이는 시간을 키값으로 두어 삼각함수를 이용해 할 수 있겠다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;float time;

struct appdata
{
    float4 vertex : POSITION;
};

struct v2f
{
    float4 vertex : SV_POSITION;
}

v2f vert(appdata i)
{
    v2f o;

    i.vertex = i.vertex + i.normal * sin(time + i.vertex.x + i.vertex.z);
    o.vertex = mul(UNITY_MATRIX_MVP, i.vertex);

    return o;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;메쉬는 여러개의 정사각형 모양으로 잘라진 평평한 판의 형태의 메쉬를 준비하고, 간단하게 x 좌표와 z 좌표를 기준으로 오브젝트가 일렁이는 것을 만들어 보았다. 이렇게 &lt;em&gt;Vertex Shader&lt;/em&gt; 를 응용해서 정점 데이터를 프로그래머가 원하는데로 움직일 수 있다. 정점 쉐이더는 사용하기에 크게 어려운점은 없기에 &lt;em&gt;Shader&lt;/em&gt; 를 처음 다룰 때 가지고 놀만하다. 또한 &lt;em&gt;Vertex Shader&lt;/em&gt; 가 가장 응용되기 쉬운 것은 바로 &lt;em&gt;skinning&lt;/em&gt; 이다. &lt;em&gt;skinning&lt;/em&gt; 자체가 정점 데이터들을 움직이고 움직임을 기반으로 바꾸는 것이기 때문에 &lt;em&gt;Vertex Shader&lt;/em&gt; 의 형태가 &lt;em&gt;skinning&lt;/em&gt; 을 적용하기 가장 알맞다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="cg" />
      
        <category term="hlsl" />
      
        <category term="unity" />
      

      

      
        <summary type="html">이번 글에서 언급할 쉐이더는 Vertex Shader 다. 한글로는 정점 쉐이더 라고 보통 말한다. Vertex Shader 에서 할 수 있는 것은, 정점별로 들어온 정보들을 코딩을 해서 프로그래머가 원하는대로 바꾸어 다음 쉐이더에서 처리할 수 있도록 해주는 Shader 다. Unity 에서의 CG/HLSL 일반적인 Vertex Shader 코드는 아래와 같다. #pragma vertex vert #include &quot;UnityCG.cginc&quot; struct appdata_tan { float4 vertex : POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; float4 tangent : TANGENT; float3 normal : NORMAL; float4 texcoord : TEXCOORD0; } v2f vert(appdata_tan i) { v2f o; o.vertex = mul(UNITY_MATRIX_MVP, i.vertex); o.tangent = i.tangent; o.normal = i.normal; o.texcoord = i.texcoord; return o; } /* 기타 코드들.. */ 굉장히 단순한 Vertex Shader 코드다. 코드가 단순한 만큼 이 Shader 는 최소한의 역할만 하고 있다. model-space 에 있는 정점을 clipping-space 의 정점으로 변환 시켜 다음으로(fragment shader) 넘긴다. 위에서 위치 데이터를 바꿀 수 있다고 언급했는데, 이 변환은 정상적인 메커니즘을 통해 오브젝트를 출력하려면 Rasterizer Stage 로 넘어가기전에 반드시 정점값에 적용시켜주어야 하는 변환이다. 해당 변환에 대해서는 Model, View, Projection에 설명해 놓았으니 간단하게 참고하길 바란다. 위 코드에서 보여준 것들은 최소한의 것들이다. 코드를 짜는 것은 프로그래머의 역량이기 때문에 더 창의적인 것들을 할 수 있다. 쉬운 것들 중에서는 표면에서 웨이브를 주어 표면이 일렁이는 것처럼 보이게 할 수 있다. 이는 시간을 키값으로 두어 삼각함수를 이용해 할 수 있겠다. float time; struct appdata { float4 vertex : POSITION; }; struct v2f { float4 vertex : SV_POSITION; } v2f vert(appdata i) { v2f o; i.vertex = i.vertex + i.normal * sin(time + i.vertex.x + i.vertex.z); o.vertex = mul(UNITY_MATRIX_MVP, i.vertex); return o; } 메쉬는 여러개의 정사각형 모양으로 잘라진 평평한 판의 형태의 메쉬를 준비하고, 간단하게 x 좌표와 z 좌표를 기준으로 오브젝트가 일렁이는 것을 만들어 보았다. 이렇게 Vertex Shader 를 응용해서 정점 데이터를 프로그래머가 원하는데로 움직일 수 있다. 정점 쉐이더는 사용하기에 크게 어려운점은 없기에 Shader 를 처음 다룰 때 가지고 놀만하다. 또한 Vertex Shader 가 가장 응용되기 쉬운 것은 바로 skinning 이다. skinning 자체가 정점 데이터들을 움직이고 움직임을 기반으로 바꾸는 것이기 때문에 Vertex Shader 의 형태가 skinning 을 적용하기 가장 알맞다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Shader Pipeline 0 Opening</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening/" rel="alternate" type="text/html" title="Shader Pipeline 0 Opening" />
      <published>2017-10-30T00:00:00+00:00</published>
      <updated>2017-10-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/30/shader-pipeline-0-opening/">&lt;h3&gt;쉐이더 프로그래밍 환경&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Programmable Shader&lt;/em&gt; 들을 정리하기 위해 각 쉐이더별로 한개씩 글을 써보기로 했다. 그 전에 미리 알아야될 것들에 대해 알아보려고 한다. 각각의 &lt;em&gt;Shader&lt;/em&gt; 들은 코더의 입장에서 바라보았을 때는 단지 몇개의 파라미터를 받고 값을 반환하는 함수들이다. 하지만 일반적으로 알고있는 함수들과는 조금 다르게 실행된다. 첫번째로 일반적인 바이너리들은 CPU 에서 직렬로 실행된다. 멀티 스레드 기능을 따로 쓰지 않는한 말이다. 하지만 &lt;em&gt;Shader&lt;/em&gt; 는 기본적으로 병렬로 실행된다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/cpucore_vs_gpucore.jpg&quot; alt=&quot;CPU core vs GPU core&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CPU 와 GPU 의 차이를 간단하게 보여주는 그림이다. 다만 위 그림이 전부는 아니니 간단하게 알고 넘어가도록 하자. 우리가 주목해야 할 것은 바로 &lt;em&gt;core&lt;/em&gt; 갯수의 차이다. 요즘의 CPU 는 &lt;em&gt;core&lt;/em&gt; 의 갯수가 많지 않다. 최근에 나온 &lt;a href=&quot;https://ark.intel.com/ko/products/126684/Intel-Core-i7-8700K-Processor-12M-Cache-up-to-4_70-GHz&quot;&gt;i7-8700k&lt;/a&gt; 를 보면 코어의 갯수가 6개 인것을 확인할 수 있다. 다만 OS 스케줄링이 있어서 실질적으로 실행되는 것은 &lt;em&gt;core&lt;/em&gt; 의 갯수에 엄격하게 제한되지는 않는다. 중요한 것은 개인용 PC 에 들어가는 CPU 는 아직은 &lt;em&gt;core&lt;/em&gt; 의 갯수가 10개를 넘어가지 않는다는 것이다. 반면에 실제 GPU 의 코어의 갯수를 꽤나 많다. 그림에서는 &lt;em&gt;hundreds of cores&lt;/em&gt;, 몇백개의 &lt;em&gt;core&lt;/em&gt; 라고 하지만 요즘 개인용 PC 에 들어가는 GPU 코어는 몇천개나(&lt;a href=&quot;https://www.geforce.co.uk/hardware/desktop-gpus/geforce-gtx-1080/specifications&quot;&gt;gtx1080&lt;/a&gt;) 된다. GPU 의 코어가 많은 이유는 간단하다. CPU 에서 돌아가는 프로그램에 비해 간단한 프로그램 바이너리(쉐이더 혹은 GPGPU 프로그램)를 동시에 실행하는게 최근의 GPU 가 쓰이는 목적이기 때문이다.&lt;/p&gt;

&lt;p&gt;일반적으로 CPU 에서 코딩하는 프로그램과 다르게 GPU 에서 실행되는 프로그램들은 이러한 병렬적인 실행 환경 때문에 특수한 사항들과 제약사항들이 존재한다. 퍼포먼스를 염두하고 프로그램을 코딩하다 보면 처음 경험하는 프로그래머는 조금 당황스러울 수도 있다.&lt;/p&gt;

&lt;h3&gt;쉐이더 파이프라인&lt;/h3&gt;

&lt;p&gt;GPU 의 여태까지의 주요한 역할은 기하학적(geometry) 성격을 띄고있는 데이터들을(mesh, vertex …) 이차원 이미지로 계산하여 보여주는 일이였다. 그렇게 3D 에셋 저작툴이나(3dsmax, maya, …) 게임에서 GPU 를 활용해 보다 많은 것들을 표현할 수 있게 해주었다. 우리가 이번에 살펴볼 것은 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 의 쉐이더가 실행되는 단계다. 이 단계는 위에서 언급한 기하학적 성격을 띄고 있는 데이터를 이차원 이미지로 계산하는 단계를 나타낸 것이다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/sm_5-0_pipeline.jpg&quot; alt=&quot;Shader Model 5_0 pipeline&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 그림에는 여러가지 항목들이 있다. &lt;em&gt;Programmable Shader&lt;/em&gt; 를 제외하면 전부 고정된 기능을 가진 단계로써 프로그래머가 완전히 제어를 할 수 없는 단계다. 우리가 살펴볼 것은 이름 끝에 &lt;em&gt;Shader&lt;/em&gt; 가 붙은 것들이다. 차례대로 &lt;em&gt;Vertex Shader&lt;/em&gt;, &lt;em&gt;Hull Shader&lt;/em&gt;, &lt;em&gt;Domain Shader&lt;/em&gt;, &lt;em&gt;Geometry Shader&lt;/em&gt;, &lt;em&gt;Pixel Shader&lt;/em&gt; 가 있다. 위의 단계들은 두가지로 분류할 수 있다. &lt;em&gt;Geometry Stage&lt;/em&gt; 와 &lt;em&gt;Rasterizer Stage&lt;/em&gt; 다. &lt;em&gt;Geometry Stage&lt;/em&gt; 는 일반적인 3D 상의 위치나 벡터를 가지고 있는 데이터를 처리하는 단계를 말한다. 위 그림에서는 &lt;em&gt;Rasterizer&lt;/em&gt; 전 까지의 단계를 뜻한다. &lt;em&gt;Rasterizer Stage&lt;/em&gt; 는 2D 이미지로 처리된 상태에서 데이터를 처리하는 단계를 말한다. &lt;em&gt;Rasterizer&lt;/em&gt; 단계 부터 오른쪽 끝까지의 단계다. 각 단계에 대한 자세한 설명은 해당 글에서 하겠다.&lt;/p&gt;

&lt;p&gt;쉐이더 파이프라인을 알고 있어야 여러 이론들을 구현할 수 있다. 쉐이더를 다루려면 이 쉐이더 파이프라인을 아는 것은 필수라고 할 수 있겠다.&lt;/p&gt;

&lt;h3&gt;각종 버퍼들의 활용&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Shader Model 4.0&lt;/em&gt; 과 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 를 통해 여러 버퍼들을 사용하여 &lt;em&gt;Shader&lt;/em&gt; 안에서 돌고도는 &lt;em&gt;varying data&lt;/em&gt; (쉐이더들의 파라미터들) 와 함께 응용을 할 수 있게 되었다. 이는 함수 한개씩을 파라미터와 반환값만 바꾸면서 코딩하는 환경에서 참조할 전역 변수를 만들어주어 훨씬 더 많은 데이터들을 접근할 수 있게 해준것이다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">쉐이더 프로그래밍 환경 Programmable Shader 들을 정리하기 위해 각 쉐이더별로 한개씩 글을 써보기로 했다. 그 전에 미리 알아야될 것들에 대해 알아보려고 한다. 각각의 Shader 들은 코더의 입장에서 바라보았을 때는 단지 몇개의 파라미터를 받고 값을 반환하는 함수들이다. 하지만 일반적으로 알고있는 함수들과는 조금 다르게 실행된다. 첫번째로 일반적인 바이너리들은 CPU 에서 직렬로 실행된다. 멀티 스레드 기능을 따로 쓰지 않는한 말이다. 하지만 Shader 는 기본적으로 병렬로 실행된다. 아래 그림을 보자. CPU 와 GPU 의 차이를 간단하게 보여주는 그림이다. 다만 위 그림이 전부는 아니니 간단하게 알고 넘어가도록 하자. 우리가 주목해야 할 것은 바로 core 갯수의 차이다. 요즘의 CPU 는 core 의 갯수가 많지 않다. 최근에 나온 i7-8700k 를 보면 코어의 갯수가 6개 인것을 확인할 수 있다. 다만 OS 스케줄링이 있어서 실질적으로 실행되는 것은 core 의 갯수에 엄격하게 제한되지는 않는다. 중요한 것은 개인용 PC 에 들어가는 CPU 는 아직은 core 의 갯수가 10개를 넘어가지 않는다는 것이다. 반면에 실제 GPU 의 코어의 갯수를 꽤나 많다. 그림에서는 hundreds of cores, 몇백개의 core 라고 하지만 요즘 개인용 PC 에 들어가는 GPU 코어는 몇천개나(gtx1080) 된다. GPU 의 코어가 많은 이유는 간단하다. CPU 에서 돌아가는 프로그램에 비해 간단한 프로그램 바이너리(쉐이더 혹은 GPGPU 프로그램)를 동시에 실행하는게 최근의 GPU 가 쓰이는 목적이기 때문이다. 일반적으로 CPU 에서 코딩하는 프로그램과 다르게 GPU 에서 실행되는 프로그램들은 이러한 병렬적인 실행 환경 때문에 특수한 사항들과 제약사항들이 존재한다. 퍼포먼스를 염두하고 프로그램을 코딩하다 보면 처음 경험하는 프로그래머는 조금 당황스러울 수도 있다. 쉐이더 파이프라인 GPU 의 여태까지의 주요한 역할은 기하학적(geometry) 성격을 띄고있는 데이터들을(mesh, vertex …) 이차원 이미지로 계산하여 보여주는 일이였다. 그렇게 3D 에셋 저작툴이나(3dsmax, maya, …) 게임에서 GPU 를 활용해 보다 많은 것들을 표현할 수 있게 해주었다. 우리가 이번에 살펴볼 것은 Shader Model 5.0 의 쉐이더가 실행되는 단계다. 이 단계는 위에서 언급한 기하학적 성격을 띄고 있는 데이터를 이차원 이미지로 계산하는 단계를 나타낸 것이다. 아래 그림을 보자. 이 그림에는 여러가지 항목들이 있다. Programmable Shader 를 제외하면 전부 고정된 기능을 가진 단계로써 프로그래머가 완전히 제어를 할 수 없는 단계다. 우리가 살펴볼 것은 이름 끝에 Shader 가 붙은 것들이다. 차례대로 Vertex Shader, Hull Shader, Domain Shader, Geometry Shader, Pixel Shader 가 있다. 위의 단계들은 두가지로 분류할 수 있다. Geometry Stage 와 Rasterizer Stage 다. Geometry Stage 는 일반적인 3D 상의 위치나 벡터를 가지고 있는 데이터를 처리하는 단계를 말한다. 위 그림에서는 Rasterizer 전 까지의 단계를 뜻한다. Rasterizer Stage 는 2D 이미지로 처리된 상태에서 데이터를 처리하는 단계를 말한다. Rasterizer 단계 부터 오른쪽 끝까지의 단계다. 각 단계에 대한 자세한 설명은 해당 글에서 하겠다. 쉐이더 파이프라인을 알고 있어야 여러 이론들을 구현할 수 있다. 쉐이더를 다루려면 이 쉐이더 파이프라인을 아는 것은 필수라고 할 수 있겠다. 각종 버퍼들의 활용 Shader Model 4.0 과 Shader Model 5.0 를 통해 여러 버퍼들을 사용하여 Shader 안에서 돌고도는 varying data (쉐이더들의 파라미터들) 와 함께 응용을 할 수 있게 되었다. 이는 함수 한개씩을 파라미터와 반환값만 바꾸면서 코딩하는 환경에서 참조할 전역 변수를 만들어주어 훨씬 더 많은 데이터들을 접근할 수 있게 해준것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Loop Attributes For Dynamic Branching</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching/" rel="alternate" type="text/html" title="Loop Attributes For Dynamic Branching" />
      <published>2017-10-26T00:00:00+00:00</published>
      <updated>2017-10-26T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/26/loop-attributes-for-dynamic-branching/">&lt;p&gt;&lt;em&gt;Programmable Shader&lt;/em&gt; 를 작성할 때에는 한가지 유의해야 할 점이 있다. 이는 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이라는 개념이다. &lt;em&gt;Dynamic Branching&lt;/em&gt; 은 조건 분기문이 &lt;em&gt;Programmable Shader&lt;/em&gt; 에서 사용될 때 나타나는 현상을 말한다. &lt;em&gt;Programmable Shader&lt;/em&gt; 는 직렬이 아닌 병렬로 실행되기 때문에 나타나는 특성이다. 반복문에서도 조건 분기를 사용한다. 간단한 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;int i = 0;
while(i &amp;lt; 5)
{
  i++;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드는 프로그래밍을 입문할때 볼 수 있는 코드다. 중요한 것은 &lt;em&gt;while&lt;/em&gt; 단어가 있는 줄에 있는 조건 식이다. &lt;em&gt;(i &amp;lt; 5)&lt;/em&gt; 조건식 때문에 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이 발생한다. 이 &lt;em&gt;Dynamic Branching&lt;/em&gt; 을 명시적으로 없에거나 만들기 위해 &lt;em&gt;hlsl&lt;/em&gt; 에서 &lt;em&gt;attribute&lt;/em&gt; 를 지원한다. 아래를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;[Attribute] for ( Initializer; Conditional; Iterator )
{
  Statement Block;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;해당 구문은 &lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509602.aspx&quot;&gt;MSDN : for Statement&lt;/a&gt; 에서 가져왔다. 일반적으로 프로그래머이 정말 많이본 &lt;em&gt;for&lt;/em&gt; 반복문이다. 우리가 봐야할 것은 &lt;em&gt;for&lt;/em&gt; 구문 왼쪽의 &lt;em&gt;[Attribute]&lt;/em&gt; 라는 구문이다. 이 부분에는 총 4가지의 옵션을 넣을 수 있는데, 이 글에서 언급할 &lt;em&gt;[Attribute]&lt;/em&gt; 는 두가지다. &lt;em&gt;unroll&lt;/em&gt; 과 &lt;em&gt;loop&lt;/em&gt; 이 두가지이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;hlsl&lt;/em&gt; 로 정상적인 반복문 실행을 하게되면, 매번 반복을 할때 마다 조건식을 검사하게 되고, 해당 반복문의 범위를 마음대로 조정하여 코딩을 할 수 있다. 다만 조건식의 범위가 매번 달라진다면 &lt;em&gt;Dynamic Branching&lt;/em&gt; 이 발생하게 된다. 그리고 반복문이 매번 &lt;em&gt;Programmable Shader&lt;/em&gt; 가 실행될 때 상수로 반복을 한다면 쉐이더 컴파일러는 최적화를 위해 특정한 행동을 하게 된다. 아래 코드를 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;for(int i = 0; i &amp;lt; 5; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 코드는 루프를 다섯번 실행시키는 코드다. 따로 안에 인덱스 &lt;em&gt;i&lt;/em&gt; 를 건드리지 않는다면 쉐이더 컴파일러는 컴파일 시점에 최적화를 한다. 이를 &lt;em&gt;unroll&lt;/em&gt; 이라고 부를 수 있는데, 실행할 반복문을 반복문으로 해석하는게 아닌 5번 연속해서 같은 행동을 하게 하는 것이다. 조건 자체도 없어지고 그저 인덱스를 풀어쓰게 된다. 이는 상수(constant)로 반복문을 제어하면 쉐이더 컴파일러가 알아서 해주기 때문에 신경써주지 않아도 된다. 다만 &lt;em&gt;unroll&lt;/em&gt; 이라는 키워드를 써서 바뀔 때는 변수를 사용해 반복문을 제어할 때다. 변수를 사용하면 컴파일 시점에서는 추측할 수 없기 때문에 암시적으로 &lt;em&gt;unroll&lt;/em&gt; 을 할 수 없다. 이 때 &lt;em&gt;unroll&lt;/em&gt; 키워드를 사용하여 제어할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;int count = ...;
[unroll(5)]
for(int i = 0; i &amp;lt; count; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;또한 암시적으로 &lt;em&gt;unroll&lt;/em&gt; 된 반복문을 명시적으로 반복문으로 실행되게 할 수도 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-hlsl&quot;&gt;[loop]
for(int i = 0; i &amp;lt; 5; i++)
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509602.aspx&quot;&gt;MSDN : for Statement&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/649408-can-someone-explain-loop-and-unroll-to-me/&quot;&gt;GameDev : Can someone explain [loop] and [unroll] to me?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/543541-hlsl-warning-gradient-based-operations-must-be-moved-out-of-flow-control-to-prevent/&quot;&gt;GameDev : HLSL warning: Gradient-based operations must be moved out of flow control to prevent
 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">Programmable Shader 를 작성할 때에는 한가지 유의해야 할 점이 있다. 이는 Dynamic Branching 이라는 개념이다. Dynamic Branching 은 조건 분기문이 Programmable Shader 에서 사용될 때 나타나는 현상을 말한다. Programmable Shader 는 직렬이 아닌 병렬로 실행되기 때문에 나타나는 특성이다. 반복문에서도 조건 분기를 사용한다. 간단한 아래 코드를 보자. int i = 0; while(i &amp;lt; 5) { i++; } 위 코드는 프로그래밍을 입문할때 볼 수 있는 코드다. 중요한 것은 while 단어가 있는 줄에 있는 조건 식이다. (i &amp;lt; 5) 조건식 때문에 Dynamic Branching 이 발생한다. 이 Dynamic Branching 을 명시적으로 없에거나 만들기 위해 hlsl 에서 attribute 를 지원한다. 아래를 보자. [Attribute] for ( Initializer; Conditional; Iterator ) { Statement Block; } 해당 구문은 MSDN : for Statement 에서 가져왔다. 일반적으로 프로그래머이 정말 많이본 for 반복문이다. 우리가 봐야할 것은 for 구문 왼쪽의 [Attribute] 라는 구문이다. 이 부분에는 총 4가지의 옵션을 넣을 수 있는데, 이 글에서 언급할 [Attribute] 는 두가지다. unroll 과 loop 이 두가지이다. hlsl 로 정상적인 반복문 실행을 하게되면, 매번 반복을 할때 마다 조건식을 검사하게 되고, 해당 반복문의 범위를 마음대로 조정하여 코딩을 할 수 있다. 다만 조건식의 범위가 매번 달라진다면 Dynamic Branching 이 발생하게 된다. 그리고 반복문이 매번 Programmable Shader 가 실행될 때 상수로 반복을 한다면 쉐이더 컴파일러는 최적화를 위해 특정한 행동을 하게 된다. 아래 코드를 보자. for(int i = 0; i &amp;lt; 5; i++) { } 위의 코드는 루프를 다섯번 실행시키는 코드다. 따로 안에 인덱스 i 를 건드리지 않는다면 쉐이더 컴파일러는 컴파일 시점에 최적화를 한다. 이를 unroll 이라고 부를 수 있는데, 실행할 반복문을 반복문으로 해석하는게 아닌 5번 연속해서 같은 행동을 하게 하는 것이다. 조건 자체도 없어지고 그저 인덱스를 풀어쓰게 된다. 이는 상수(constant)로 반복문을 제어하면 쉐이더 컴파일러가 알아서 해주기 때문에 신경써주지 않아도 된다. 다만 unroll 이라는 키워드를 써서 바뀔 때는 변수를 사용해 반복문을 제어할 때다. 변수를 사용하면 컴파일 시점에서는 추측할 수 없기 때문에 암시적으로 unroll 을 할 수 없다. 이 때 unroll 키워드를 사용하여 제어할 수 있다. int count = ...; [unroll(5)] for(int i = 0; i &amp;lt; count; i++) { } 또한 암시적으로 unroll 된 반복문을 명시적으로 반복문으로 실행되게 할 수도 있다. [loop] for(int i = 0; i &amp;lt; 5; i++) { } 참조 자료 MSDN : for Statement GameDev : Can someone explain [loop] and [unroll] to me? GameDev : HLSL warning: Gradient-based operations must be moved out of flow control to prevent</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Introduce Of Wave Programming</title>
      
      <link href="https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming/" rel="alternate" type="text/html" title="Introduce Of Wave Programming" />
      <published>2017-10-16T00:00:00+00:00</published>
      <updated>2017-10-16T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/10/16/introduce-of-wave-programming/">&lt;p&gt;Windows 10 Fall Creators Update 가 나오면서 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 이 추가되었다. 여태까지의 &lt;em&gt;Shader Model&lt;/em&gt; 업데이트는 대부분 DirectX 버젼이 올라가면서 같이 업데이트 된 경우가 많으나 이번의 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 따로 업데이트 되었다. &lt;em&gt;Shader Model 6.0&lt;/em&gt; 에서의 가장 큰 기능 추가는 당연히 &lt;em&gt;Wave Intrisic&lt;/em&gt; 이라고 할 수 있겠다. &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 제외하면 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 바뀐게 없다.&lt;/p&gt;

&lt;p&gt;여태까지의 HLSL 을 사용한 쉐이더 작성은 거의 대부분 &lt;em&gt;Single-Threading&lt;/em&gt; 으로 작동되었다. &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 ddx, ddy instrisic 을 사용하여 Gradient 데이터를 가져올 수 있긴 했지만 이 것을 제외하면 거의 없었다고 보면 되겠다. 그래서 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 에서는 다른 &lt;em&gt;Thread&lt;/em&gt; 와 인터렉션 할 수 있는 &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 지원한다. &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt; 을 살펴보면 알겠지만 단순한 API 들을 제공하는 것이다. 하지만 내부에서 동작하는 것은 조금 다르다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt; 에서 나온 용어에 대한 설명이 필요하다. &lt;em&gt;Lane&lt;/em&gt; 은 일반적으로 생각되는 한개의 &lt;em&gt;Thread&lt;/em&gt; 가 실행되는 것이다. &lt;em&gt;Shader Model 6.0&lt;/em&gt; 이전의 쉐이더 모델은 단순히 &lt;em&gt;Lane&lt;/em&gt; 개념 안에서 코딩을 해야 했다. &lt;em&gt;Lane&lt;/em&gt; 은 상황에 따라 실행되고 있는 상태일 수도 있고, 쉬고 있는 상태일 수도 있다. &lt;em&gt;Wave Intrisic&lt;/em&gt; 을 사용해 이를 각각의 &lt;em&gt;Lane&lt;/em&gt; 에서도 알 수 있다. &lt;em&gt;Wave&lt;/em&gt; 는 GPU 에서 실행되는 &lt;em&gt;Lane&lt;/em&gt; 의 묶음을 뜻한다. 즉 여러개의 &lt;em&gt;Lane&lt;/em&gt; 이라고 할 수 있겠다. 같은 &lt;em&gt;Wave&lt;/em&gt; 안의 &lt;em&gt;Lane&lt;/em&gt; 들은 &lt;em&gt;Barrier&lt;/em&gt; 라는게 없다. 필자가 알고 있는 &lt;em&gt;Barrier&lt;/em&gt; 는 &lt;em&gt;Memory Barrier&lt;/em&gt; 인데, 이는 &lt;em&gt;Thread&lt;/em&gt;(&lt;em&gt;Lane&lt;/em&gt;)끼리의 같은 메모리에 접근하는 것에 대한 동기화를 위해 있는 개념이다. 동기화를 위한 &lt;em&gt;Barrier&lt;/em&gt; 는 속도를 늦출 수 밖에 없다. 하지만 &lt;em&gt;Wave&lt;/em&gt; 로 묶여진 &lt;em&gt;Lane&lt;/em&gt; 들은 서로 &lt;em&gt;Barrier&lt;/em&gt; 가 명시적으로 존재하지 않기 때문에 &lt;em&gt;Wave&lt;/em&gt; 별로 빠른 메모리 접근이 가능하다는 것이다. &lt;em&gt;Wave&lt;/em&gt; 는 &lt;em&gt;Warp&lt;/em&gt;, &lt;em&gt;WaveFront&lt;/em&gt; 라고도 불리울 수 있다고 한다.&lt;/p&gt;

&lt;p&gt;그리고 이 API 들을 통해 약간의 드라이버 내부를 엿볼 수 있다. &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 &lt;em&gt;Render Lane&lt;/em&gt; 과 &lt;em&gt;Helper Lane&lt;/em&gt; 이 구분되어져 있는데, 이는 ddx,ddy 를 통해 픽셀의 Gradient 를 계산하는 것에 대한 보다 디테일한 개념을 생각할 수 있게 해준다. GPU 드라이버 시스템에서는 픽셀을 처리하기 위해 단순히 한개의 픽셀만 처리하는게 아닌 2x2 의 픽셀을 엮어 계산한다. 이를 MSDN 문서에서는 2x2 의 픽셀 뭉치를 &lt;em&gt;Quad&lt;/em&gt; 라고 명칭한다. &lt;em&gt;Quad&lt;/em&gt; 는 두가지 종류에 스레드가 실행된다. 하나는 우리가 잘 알고 있는 &lt;em&gt;Pixel Shader&lt;/em&gt; 를 실행하는 &lt;em&gt;Render Lane&lt;/em&gt; 이다. &lt;em&gt;Render Lane&lt;/em&gt; 은 화면에 보여주는 색을 결과로 내놓게 된다. 그리고 나머지 한가지는 &lt;em&gt;Helper Lane&lt;/em&gt; 인데, 이는 Pixel 별로 Gradient 를 계산하기 위해 실행되는 &lt;em&gt;Lane&lt;/em&gt; 으로써 아무런 결과를 내놓지 않고 단순히 계산을 위한 &lt;em&gt;Lane&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 DirectX12 과 Vulkan 에서 지원한다. DirectX 에서는 &lt;em&gt;Pixel Shader&lt;/em&gt; 와 &lt;em&gt;Computer Shader&lt;/em&gt; 에서 지원한다. Vulkan 에서는 모든 쉐이더 단계에서 지원한다. 그래픽 카드 벤더별로 조금씩 다른게 있으니 &lt;a href=&quot;http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2017/07/GDC2017-Wave-Programming-D3D12-Vulkan.pdf&quot;&gt;GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan &lt;/a&gt; 에서 참고 바란다.&lt;/p&gt;

&lt;p&gt;이 API 는 여러 쓰레드들 끼리 쉽게 협력하여 보다 효율적인 쉐이더 병렬 프로그래밍을 가능하게 해줄듯하다. 다만 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 에서 소개된 &lt;em&gt;ComputeShader&lt;/em&gt; 만큼의 임팩트는 없다. 패러다임의 아주 큰 변화는 없다는 뜻이다. DirectX12 가 지향하는 드라이버 시스템에서의 부담을 줄이는 것과 &lt;em&gt;Shader Model 6.0&lt;/em&gt; 은 서로 방향이 비슷하다고 생각된다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.gdcvault.com/play/1024732/Advanced-Graphics-Tech-D3D12-and&quot;&gt;GDCVault(GDC 2017) : D3D12 &amp;amp; Vulkan Done Right&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://32ipi028l5q82yhj72224m8j.wpengine.netdna-cdn.com/wp-content/uploads/2017/07/GDC2017-Wave-Programming-D3D12-Vulkan.pdf&quot;&gt;GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/mt733232.aspx&quot;&gt;MSDN : HLSL Shader Model 6.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://optocrypto.com/2017/09/20/microsofts-program-shader-model-6-0-completed/&quot;&gt;Optocrypto : Microsoft’s first example program for shader model 6.0 was completed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="render" />
      
        <category term="shader" />
      

      

      
        <summary type="html">Windows 10 Fall Creators Update 가 나오면서 Shader Model 6.0 이 추가되었다. 여태까지의 Shader Model 업데이트는 대부분 DirectX 버젼이 올라가면서 같이 업데이트 된 경우가 많으나 이번의 Shader Model 6.0 은 따로 업데이트 되었다. Shader Model 6.0 에서의 가장 큰 기능 추가는 당연히 Wave Intrisic 이라고 할 수 있겠다. Wave Intrisic 을 제외하면 Shader Model 6.0 은 바뀐게 없다. 여태까지의 HLSL 을 사용한 쉐이더 작성은 거의 대부분 Single-Threading 으로 작동되었다. Pixel Shader 에서 ddx, ddy instrisic 을 사용하여 Gradient 데이터를 가져올 수 있긴 했지만 이 것을 제외하면 거의 없었다고 보면 되겠다. 그래서 Shader Model 6.0 에서는 다른 Thread 와 인터렉션 할 수 있는 Wave Intrisic 을 지원한다. MSDN : HLSL Shader Model 6.0 을 살펴보면 알겠지만 단순한 API 들을 제공하는 것이다. 하지만 내부에서 동작하는 것은 조금 다르다. MSDN : HLSL Shader Model 6.0 에서 나온 용어에 대한 설명이 필요하다. Lane 은 일반적으로 생각되는 한개의 Thread 가 실행되는 것이다. Shader Model 6.0 이전의 쉐이더 모델은 단순히 Lane 개념 안에서 코딩을 해야 했다. Lane 은 상황에 따라 실행되고 있는 상태일 수도 있고, 쉬고 있는 상태일 수도 있다. Wave Intrisic 을 사용해 이를 각각의 Lane 에서도 알 수 있다. Wave 는 GPU 에서 실행되는 Lane 의 묶음을 뜻한다. 즉 여러개의 Lane 이라고 할 수 있겠다. 같은 Wave 안의 Lane 들은 Barrier 라는게 없다. 필자가 알고 있는 Barrier 는 Memory Barrier 인데, 이는 Thread(Lane)끼리의 같은 메모리에 접근하는 것에 대한 동기화를 위해 있는 개념이다. 동기화를 위한 Barrier 는 속도를 늦출 수 밖에 없다. 하지만 Wave 로 묶여진 Lane 들은 서로 Barrier 가 명시적으로 존재하지 않기 때문에 Wave 별로 빠른 메모리 접근이 가능하다는 것이다. Wave 는 Warp, WaveFront 라고도 불리울 수 있다고 한다. 그리고 이 API 들을 통해 약간의 드라이버 내부를 엿볼 수 있다. Pixel Shader 에서 Render Lane 과 Helper Lane 이 구분되어져 있는데, 이는 ddx,ddy 를 통해 픽셀의 Gradient 를 계산하는 것에 대한 보다 디테일한 개념을 생각할 수 있게 해준다. GPU 드라이버 시스템에서는 픽셀을 처리하기 위해 단순히 한개의 픽셀만 처리하는게 아닌 2x2 의 픽셀을 엮어 계산한다. 이를 MSDN 문서에서는 2x2 의 픽셀 뭉치를 Quad 라고 명칭한다. Quad 는 두가지 종류에 스레드가 실행된다. 하나는 우리가 잘 알고 있는 Pixel Shader 를 실행하는 Render Lane 이다. Render Lane 은 화면에 보여주는 색을 결과로 내놓게 된다. 그리고 나머지 한가지는 Helper Lane 인데, 이는 Pixel 별로 Gradient 를 계산하기 위해 실행되는 Lane 으로써 아무런 결과를 내놓지 않고 단순히 계산을 위한 Lane 이다. Shader Model 6.0 은 DirectX12 과 Vulkan 에서 지원한다. DirectX 에서는 Pixel Shader 와 Computer Shader 에서 지원한다. Vulkan 에서는 모든 쉐이더 단계에서 지원한다. 그래픽 카드 벤더별로 조금씩 다른게 있으니 GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan 에서 참고 바란다. 이 API 는 여러 쓰레드들 끼리 쉽게 협력하여 보다 효율적인 쉐이더 병렬 프로그래밍을 가능하게 해줄듯하다. 다만 Shader Model 5.0 에서 소개된 ComputeShader 만큼의 임팩트는 없다. 패러다임의 아주 큰 변화는 없다는 뜻이다. DirectX12 가 지향하는 드라이버 시스템에서의 부담을 줄이는 것과 Shader Model 6.0 은 서로 방향이 비슷하다고 생각된다. 참조 자료 GDCVault(GDC 2017) : D3D12 &amp;amp; Vulkan Done Right GDCVault(GDC 2017) : Wave Programming D3D12 Vulkan MSDN : HLSL Shader Model 6.0 Optocrypto : Microsoft’s first example program for shader model 6.0 was completed</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Rendering To Cubemap</title>
      
      <link href="https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap/" rel="alternate" type="text/html" title="Using Rendering To Cubemap" />
      <published>2017-09-29T00:00:00+00:00</published>
      <updated>2017-09-29T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/09/29/using-rendering-to-cubemap/">&lt;p&gt;&lt;a href=&quot;/2017/09/29/using-relplacement-shader/&quot;&gt;using replacement shader&lt;/a&gt; 에서 &lt;em&gt;Camera.RenderWithShader&lt;/em&gt; 와 같은 렌더링을 코드에서 직접해주면서 기능을 커스터마이징 할 수 있는 것을 살펴보았는데, 이 게시물에서는 비슷한 메서드인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 여러 렌더링 커스터마이징 기능을 제공하는데, 이 게시물에서는 그 중 하나인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 에 대해서 알아볼 것이다. 일반적으로 &lt;em&gt;Cubemap&lt;/em&gt; 은 SkyBox 나 주변의 Irradiance 를 나타낼 때 쓴다. 다만 이를 직접 구현할 때의 문제점은 각 모서리별로 &lt;em&gt;Aliasing&lt;/em&gt; 이 일어나는 경우다. 매우 매끄러운 표면의 Specular 에서 &lt;em&gt;Aliasing&lt;/em&gt; 이 나타난 Irradiance 를 표현하면 굉장히 티가 많이 나기 때문에 이는 굉장히 신경써야할 문제다.&lt;/p&gt;

&lt;p&gt;그래서 Unity 에서는 &lt;em&gt;Cubemap&lt;/em&gt; 에 렌더링을 하는 기능인 &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 을 지원한다. 이를 통해 할 수 있는 것은 실시간으로 &lt;em&gt;Cubemap&lt;/em&gt; 에 렌더링된 결과를 저장해 &lt;em&gt;Irradiance&lt;/em&gt; 의 소스로 쓰거나, 실시간으로 바뀌는 &lt;em&gt;Skybox&lt;/em&gt; 렌더링을 할 수도 있다. 사용 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;RenderTexture cubmapRT = ...;
camera.RenderToCubemap(cubemapRT, 63);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 의 두번째로 들어가는 인자는 어떤 면을 그릴건지에 대한 비트마스크다. &lt;em&gt;Camera.RenderToCubemap&lt;/em&gt; 를 쓸때 주의할 점은 일부 하드웨어에서는 동작하지 않는 기능이라고 한다. 다만 특정한 하드웨어를 기술해 놓지않아서 추측하기는 어렵다. 단순히 추측할 수 있는 것은 MRT 를 지원하지 않거나 아니면 다른 &lt;em&gt;ComputeShader&lt;/em&gt; 같은 기능을 사용해 일부 하드웨어에서 안된다고 하는 정도 밖에 없다.&lt;/p&gt;

&lt;p&gt;위 예제에서는 RenderTexture 를 사용하였는데, 저렇게 코드에서 처리할 수도 있지만 CustomRenderTexture 를 통해 간편하게 처리할 수도 있다. CustomRenderTexture 는 업데이트 주기를 사용자 임의대로 정할 수 있으므로 꽤나 유용하게 쓰일 수 있다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/Camera.RenderToCubemap.html&quot;&gt;Unity Reference : Camera.RenderToCubemap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="render" />
      

      

      
        <summary type="html">using replacement shader 에서 Camera.RenderWithShader 와 같은 렌더링을 코드에서 직접해주면서 기능을 커스터마이징 할 수 있는 것을 살펴보았는데, 이 게시물에서는 비슷한 메서드인 Camera.RenderToCubemap 에 대해서 알아볼 것이다. Unity 에서는 여러 렌더링 커스터마이징 기능을 제공하는데, 이 게시물에서는 그 중 하나인 Camera.RenderToCubemap 에 대해서 알아볼 것이다. 일반적으로 Cubemap 은 SkyBox 나 주변의 Irradiance 를 나타낼 때 쓴다. 다만 이를 직접 구현할 때의 문제점은 각 모서리별로 Aliasing 이 일어나는 경우다. 매우 매끄러운 표면의 Specular 에서 Aliasing 이 나타난 Irradiance 를 표현하면 굉장히 티가 많이 나기 때문에 이는 굉장히 신경써야할 문제다. 그래서 Unity 에서는 Cubemap 에 렌더링을 하는 기능인 Camera.RenderToCubemap 을 지원한다. 이를 통해 할 수 있는 것은 실시간으로 Cubemap 에 렌더링된 결과를 저장해 Irradiance 의 소스로 쓰거나, 실시간으로 바뀌는 Skybox 렌더링을 할 수도 있다. 사용 방법은 아래와 같다. RenderTexture cubmapRT = ...; camera.RenderToCubemap(cubemapRT, 63); Camera.RenderToCubemap 의 두번째로 들어가는 인자는 어떤 면을 그릴건지에 대한 비트마스크다. Camera.RenderToCubemap 를 쓸때 주의할 점은 일부 하드웨어에서는 동작하지 않는 기능이라고 한다. 다만 특정한 하드웨어를 기술해 놓지않아서 추측하기는 어렵다. 단순히 추측할 수 있는 것은 MRT 를 지원하지 않거나 아니면 다른 ComputeShader 같은 기능을 사용해 일부 하드웨어에서 안된다고 하는 정도 밖에 없다. 위 예제에서는 RenderTexture 를 사용하였는데, 저렇게 코드에서 처리할 수도 있지만 CustomRenderTexture 를 통해 간편하게 처리할 수도 있다. CustomRenderTexture 는 업데이트 주기를 사용자 임의대로 정할 수 있으므로 꽤나 유용하게 쓰일 수 있다. 참조 자료 Unity Reference : Camera.RenderToCubemap</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Relplacement Shader</title>
      
      <link href="https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader/" rel="alternate" type="text/html" title="Using Relplacement Shader" />
      <published>2017-09-29T00:00:00+00:00</published>
      <updated>2017-09-29T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/09/29/using-relplacement-shader/">&lt;p&gt;Unity 는 &lt;em&gt;Replacement Shader&lt;/em&gt; 라는 렌더링 기능을 지원한다. 이는 Unity 가 Rendering 기능에서 지원하는 약간 Hack 한 테크닉이며 이 기능을 잘 사용하면 쉐이더를 바꿔치기 해서 재미있는 것들을 할 수 있다. &lt;em&gt;Replacement Shader&lt;/em&gt; 는 렌더링할 MeshRenderer 들이 가지고 있는 &lt;strong&gt;Material&lt;/strong&gt; 의 Shader 를 사용자가 원하는 것으로 바꾸는 기능이다. 이 기능을 통해 그림자 같은 여러 부가적인 처리를 할 수 있다.&lt;/p&gt;

&lt;p&gt;사용하는 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;Shader shader = Shader.Find(&quot;CustomShaderName&quot;);
string replacementTag = &quot;replace&quot;;

// tag is optional. if dont need tag, insert null.
camera.RenderWithShader(shader, replacementTag);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 간단한 예제는 &lt;em&gt;Replacement Shader&lt;/em&gt; 를 사용해 한번 그려주는 예제다. 단순히 &lt;em&gt;Camera.RenderWithShader&lt;/em&gt; 를 사용하기 때문에 직접 값을 컨트롤할 때 사용하기 좋다. &lt;em&gt;Replacement Shader&lt;/em&gt; 를 영구적으로 세팅하여 자동으로 그려주면 아래와 같이 하면된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;Shader shader = Shader.Find(&quot;CustomShaderName&quot;);
string replacementTag = &quot;replace&quot;;

// tag is optional. if dont need tag, insert null.
camera.SetReplacementShader(shader, replacementTag);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;사용 방법은 굉장히 단순하다. 다만 이 &lt;em&gt;Replacement Shader&lt;/em&gt; 기능에서 중요한 것은 쉐이더를 단순히 치환하는 것만 포인트가 아니다. 치환된 쉐이더들은 기존 &lt;strong&gt;Material&lt;/strong&gt; 이 가지고 있던 데이터들과 쉐이더 코드에서 이름만 똑같이 맞추어주면 자동으로 데이터들이 쉐이더로 들어온다. 즉 쉐이더를 갈아치우지 않고도 데이터를 공유할 수 있는 것이다. 이는 Unity 의 렌더링에서 굉장히 강력한 시스템으로 초기에는 이해하기도 힘들고 잔머리가 필요하지만 이를 잘 사용만 한다면 굉장히 유용하게 쓰일 수 있다.&lt;/p&gt;

&lt;p&gt;필자는 Github 에서 OIT 예제를 보면서 처음 보았다. &lt;a href=&quot;https://github.com/candycat1992/OIT_Lab&quot;&gt;Github : OIT_Lab&lt;/a&gt; 에서 OIT 를 처리하는 코드에서 구경할 수 있다. 또한 일본 Unity 지사에서 일하는 유명한 keijiro 의 &lt;a href=&quot;https://github.com/keijiro/Skinner&quot;&gt;Skinner&lt;/a&gt; 에서 위치를 처리하는데 쓰이기도 한다.&lt;/p&gt;

&lt;h1&gt;참조 자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/SL-ShaderReplacement.html&quot;&gt;Unity Reference : Replaced Shaders 에서의 렌더링&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="render" />
      

      

      
        <summary type="html">Unity 는 Replacement Shader 라는 렌더링 기능을 지원한다. 이는 Unity 가 Rendering 기능에서 지원하는 약간 Hack 한 테크닉이며 이 기능을 잘 사용하면 쉐이더를 바꿔치기 해서 재미있는 것들을 할 수 있다. Replacement Shader 는 렌더링할 MeshRenderer 들이 가지고 있는 Material 의 Shader 를 사용자가 원하는 것으로 바꾸는 기능이다. 이 기능을 통해 그림자 같은 여러 부가적인 처리를 할 수 있다. 사용하는 방법은 아래와 같다. Shader shader = Shader.Find(&quot;CustomShaderName&quot;); string replacementTag = &quot;replace&quot;; // tag is optional. if dont need tag, insert null. camera.RenderWithShader(shader, replacementTag); 위의 간단한 예제는 Replacement Shader 를 사용해 한번 그려주는 예제다. 단순히 Camera.RenderWithShader 를 사용하기 때문에 직접 값을 컨트롤할 때 사용하기 좋다. Replacement Shader 를 영구적으로 세팅하여 자동으로 그려주면 아래와 같이 하면된다. Shader shader = Shader.Find(&quot;CustomShaderName&quot;); string replacementTag = &quot;replace&quot;; // tag is optional. if dont need tag, insert null. camera.SetReplacementShader(shader, replacementTag); 사용 방법은 굉장히 단순하다. 다만 이 Replacement Shader 기능에서 중요한 것은 쉐이더를 단순히 치환하는 것만 포인트가 아니다. 치환된 쉐이더들은 기존 Material 이 가지고 있던 데이터들과 쉐이더 코드에서 이름만 똑같이 맞추어주면 자동으로 데이터들이 쉐이더로 들어온다. 즉 쉐이더를 갈아치우지 않고도 데이터를 공유할 수 있는 것이다. 이는 Unity 의 렌더링에서 굉장히 강력한 시스템으로 초기에는 이해하기도 힘들고 잔머리가 필요하지만 이를 잘 사용만 한다면 굉장히 유용하게 쓰일 수 있다. 필자는 Github 에서 OIT 예제를 보면서 처음 보았다. Github : OIT_Lab 에서 OIT 를 처리하는 코드에서 구경할 수 있다. 또한 일본 Unity 지사에서 일하는 유명한 keijiro 의 Skinner 에서 위치를 처리하는데 쓰이기도 한다. 참조 자료 Unity Reference : Replaced Shaders 에서의 렌더링</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Compute Buffer In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/" rel="alternate" type="text/html" title="Using Compute Buffer In Unity" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/using-compute-buffer-in-unity/">&lt;p&gt;Unity 에서의 확실한 GPU Instancing 은 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 라는 구현체에서 시작될 것이다. 이 구현체는 &lt;strong&gt;UnityEngine.ComputeBuffer&lt;/strong&gt; 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 와 함께 등장했다. &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 구현해 놓았다. 하지만 이 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 &lt;em&gt;Shader Model 5.0&lt;/em&gt; 이상이다. PC 플랫폼에서는 당연히 사용 가능하다.&lt;/p&gt;

&lt;p&gt;사용하는 방법 자체는 어렵지 않다. 스크립트에서 &lt;em&gt;size&lt;/em&gt; 와 &lt;em&gt;stride&lt;/em&gt; 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 &lt;strong&gt;System.Array&lt;/strong&gt; 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C#&quot;&gt;int dataLen = ...;  // length of data
int[] dataArray = new int[dataLen];

// record data in dataArray..

ComputeShader computeShader = ...;
ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int));
dataBuffer.SetData(dataArray);

computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드는 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에서 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(&lt;em&gt;length&lt;/em&gt;)와 각 데이터별 크기(&lt;em&gt;stride&lt;/em&gt;)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(&lt;em&gt;write&lt;/em&gt;) 그리고 마지막으로 데이터가 세팅된 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 &lt;strong&gt;ComputeShader&lt;/strong&gt; 에 연결해준다. 이러면 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드에서 &lt;em&gt;dataBuffer&lt;/em&gt; 라는 변수명을 가진 변수에 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 가 연결된다. 아래에 &lt;strong&gt;ComputeShader&lt;/strong&gt; 코드가 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-HLSL&quot;&gt;StructuredBuffer&amp;lt;int&amp;gt; dataBuffer;

[numthreads(8,8,1)]
void Process (uint3 id : SV_DispatchThreadID)
{
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;맨 처음에 있는 &lt;em&gt;dataBuffer&lt;/em&gt; 에 연결된다. &lt;a href=&quot;{ post_url 2017-07-06-structured-buffer-vs-constant-buffer }&quot;&gt;StructuredBuffer vs ConstantBuffer&lt;/a&gt; 에서본 &lt;em&gt;StructuredBuffer&lt;/em&gt; 타입이 가능하다. 또한 &lt;em&gt;RWStructuredBuffer&lt;/em&gt;, &lt;em&gt;ConsumeStructuredBuffer&lt;/em&gt;, &lt;em&gt;AppendStructuredBuffer&lt;/em&gt; 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/data-process-pipeline.png&quot; alt=&quot;data process&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞의 두가지 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 세팅하고 &lt;strong&gt;ComputeShader&lt;/strong&gt; 를 실행하는 코드는 대충 보았다, 뒷 부분의 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 스키닝의 계산을 &lt;strong&gt;ComputeShader&lt;/strong&gt; 로 넘겨서 계산한다. 또한 메시 데이터 전체를 &lt;strong&gt;ComputeBuffer&lt;/strong&gt; 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/ComputeBuffer.html&quot;&gt;Unity Reference : ComptuteBuffer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="gpuinstancing" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서의 확실한 GPU Instancing 은 ComputeBuffer 라는 구현체에서 시작될 것이다. 이 구현체는 UnityEngine.ComputeBuffer 라는 Unity 의 구현체이며 하는 역할은 GPU 메모리를 사용하게 해주는 역할을 한다. ComputeBuffer 는 ComputeShader 와 함께 등장했다. ComputeShader 에서 데이터를 읽고 쓰는것을 요구하기 때문에 Unity 는 GPU 메모리를 사용하는 컨테이너로서 ComputeBuffer 를 구현해 놓았다. 하지만 이 ComputeBuffer 는 ComputeShader 뿐만아니라 일반 쉐이더에서도 폭넓게 사용가능하다. 이 말의 뜻은 우리가 생각하는 Unity 에서 지원하는 일반적인 메쉬 데이터를 사용하지 않아도 사용자가 직접 메쉬 데이터를 커스터마이징해서 사용할 수 있다는 이야기이다. 지원하는 플랫폼은 일반적으로 말하는 Shader Model 5.0 이상이다. PC 플랫폼에서는 당연히 사용 가능하다. 사용하는 방법 자체는 어렵지 않다. 스크립트에서 size 와 stride 를 설정해주고, 데이터의 배열을 만들어 GPU 메모리 안에 있는 데이터를 읽거나 쓸 수 있다. 메모리 단위에서 하는것처럼 보이기 때문에 크기와 타입은 맞춰주어야 한다. C# 에서는 System.Array 형으로 넣어주니 형태에 주의하기 바란다. 방법은 아래와 같다. int dataLen = ...; // length of data int[] dataArray = new int[dataLen]; // record data in dataArray.. ComputeShader computeShader = ...; ComptueBuffer dataBuffer = new ComputeBuffer(dataLen, sizeof(int)); dataBuffer.SetData(dataArray); computeShader.SetBuffer(&quot;dataBuffer&quot;, dataBuffer); 위 코드는 ComputeShader 에서 ComputeBuffer 를 사용하기 위해 세팅하는 코드다. 가장 맨처음에는 초기에 세팅할 정수 배열을 만들고, 그 다음 ComputeBuffer 인스턴스를 생성한다. 생성자에서 넣어주는 인자는 데이터의 길이(length)와 각 데이터별 크기(stride)이다. 그 다음 같은 크기의 배열의 데이터를 GPU 메모리로 쓴다.(write) 그리고 마지막으로 데이터가 세팅된 ComputeBuffer 를 ComputeShader 에 연결해준다. 이러면 ComputeShader 코드에서 dataBuffer 라는 변수명을 가진 변수에 ComputeBuffer 가 연결된다. 아래에 ComputeShader 코드가 있다. StructuredBuffer&amp;lt;int&amp;gt; dataBuffer; [numthreads(8,8,1)] void Process (uint3 id : SV_DispatchThreadID) { ... } 맨 처음에 있는 dataBuffer 에 연결된다. StructuredBuffer vs ConstantBuffer 에서본 StructuredBuffer 타입이 가능하다. 또한 RWStructuredBuffer, ConsumeStructuredBuffer, AppendStructuredBuffer 가능하다. 다른 렌더러 쉐이더 코드에서도 사용가능하다. 그래서 일반적으로 고려되는 파이프라인은 아래와 같다. 앞의 두가지 ComputeBuffer 를 세팅하고 ComputeShader 를 실행하는 코드는 대충 보았다, 뒷 부분의 ComputeBuffer 를 통해 렌더링을 하는 것은 그다지 어렵지 않다. 중요한 것은 참신하게, 효율적으로 렌더링하는 것이다. Github : CustomSkinningExample 에서 스키닝의 계산을 ComputeShader 로 넘겨서 계산한다. 또한 메시 데이터 전체를 ComputeBuffer 로 넘겨서 렌더링하기 때문에 꽤나 괜찮은 예가 될것이다. 참조 Unity Reference : ComptuteBuffer</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Darboux Frame</title>
      
      <link href="https://hrmrzizon.github.io/2017/08/01/darboux-frame/" rel="alternate" type="text/html" title="Darboux Frame" />
      <published>2017-08-01T00:00:00+00:00</published>
      <updated>2017-08-01T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/08/01/darboux-frame</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/08/01/darboux-frame/">&lt;p&gt;여러 공간 법선 벡터(&lt;em&gt;tangent space normal&lt;/em&gt;, &lt;em&gt;object space normal&lt;/em&gt;)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. &lt;em&gt;darboux frame&lt;/em&gt; 이라는 놈이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;우선 &lt;em&gt;tangent space normal&lt;/em&gt; 과 &lt;em&gt;object space normal&lt;/em&gt; 에 대해서 설명해야 한다. 그래픽스에서는 빛을 표현하기 위해 노말벡터를 사용한다. 처음에 나온식은 매우 간단하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(빛의 방향 벡터) * (노말 벡터) = (빛이 표현하는 색의 범위(-1~1))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 벡터곱은 내적을 뜻한다. 이 식의 결과값은 반사광을 표현하는데 쓰인다. 일반적으로 말하는 &lt;em&gt;Specular&lt;/em&gt; 를 뜻한다. 하여튼 빛을 표현하는 것은 그래픽스에서는 굉장히 중요한 일이기 때문에 이 노말벡터를 어떻게 관리하는지가 엄청나게 중요하다. 그래서 여러 방법이 있는데 제일 많이 쓰이는건 &lt;em&gt;tangent space normal&lt;/em&gt; 이다. 그런데 &lt;em&gt;object space normal&lt;/em&gt; 은 갑자기 왜 튀어나왔느냐? 이유는 간단하다. 두개가 가장 비교가 많이 되는 방법이기 때문이다. &lt;em&gt;object space normal&lt;/em&gt; 은 굉장히 간단하다. 저장된 메시 데이터의 노말 벡터값이다. 기본 단위가 저장된 한 개체의 메시의 노말이기 때문에 &lt;em&gt;object spoce&lt;/em&gt; 라는 접두사가 붙은 것이다. 그래서 그런지 아래 그림에서 나오는 &lt;em&gt;object spoce normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 굉장히 다양하다. 하지만 옆에 &lt;em&gt;tangent space normal&lt;/em&gt; 이 저장된 텍스쳐는 색이 거의 일정하다. 왜 그럴까? 우선 앞의 &lt;em&gt;object space normal&lt;/em&gt; 은 그냥 오브젝트 기준의 좌표계에서의 정점별 노말값을 저장한 데이터다. 하지만 &lt;em&gt;tangent space normal&lt;/em&gt; 은 모델에서 추출한 &lt;em&gt;tangent&lt;/em&gt; 값을 통해 &lt;em&gt;normal&lt;/em&gt; 값을 구하는 방법이다. &lt;a href=&quot;/2017/07/30/normal-tangent-binormal/&quot;&gt;normal tangent binormal&lt;/a&gt; 에서 설명했었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ssloy/tinyrenderer/gh-pages/img/06b-tangent-space/nm_textures.jpg&quot; alt=&quot;tangent-space vs objcet-space&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그런데 &lt;em&gt;tangent space normal&lt;/em&gt; 에서의 &lt;em&gt;tangent&lt;/em&gt; 가 뜻하는 것은 표면의 접선 값이다. 이렇게 표면을 기준으로 하는 것을 &lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;&lt;em&gt;darboux frame&lt;/em&gt;&lt;/a&gt; 이라고 한다. 프랑스 사람의 이름이라 한글로 읽으면 &lt;em&gt;다르부-프레임&lt;/em&gt; 이다. 위키에서는 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이 표면 기하학에서 적용된 것이라 한다. 그만큼 대부분의 정의들이 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 과 매우 비슷하다. 다른 점은 곡선에서 표면으로 확장시켰다는 점이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ssloy/tinyrenderer/wiki/Lesson-6bis:-tangent-space-normal-mapping&quot;&gt;Github : tinyrenderer Wiki - tangent-space-normal-mapping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Darboux_frame&quot;&gt;Wikipedia : darvoux frame&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">여러 공간 법선 벡터(tangent space normal, object space normal)에 대하여 알아보던 도중 모르는 것이 하나있어 정리해볼겸 포스팅해보려 한다. darboux frame 이라는 놈이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Normal Tangent Binormal</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/" rel="alternate" type="text/html" title="Normal Tangent Binormal" />
      <published>2017-07-30T00:00:00+00:00</published>
      <updated>2017-07-30T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/30/normal-tangent-binormal/">&lt;p&gt;Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;노말 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;탄젠트 벡터&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;바이노말 벡터&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;법선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;접선 벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;이중법선(또는 종법선)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;하지만 이게 뭔지, 어디서 나온지에 대해서 설명한건 그다지 많이 본적이 없다. 물론 필자는 인터넷에 있는 레퍼런스만 보고 공부해서 그럴 수도 있다. 그래서 간단하게 지식의 뿌리만 살펴보려고 한다.&lt;/p&gt;

&lt;p&gt;이 세가지는 이름도 무시무시한 &lt;em&gt;미분기하학&lt;/em&gt; 에서 소개되는 &lt;em&gt;“프레네-세레 공식”(Frene-seret formula)&lt;/em&gt; 에서 정의된 것들이다. 정식 이름은 &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 이라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 은 일반적으로 우리가 알고있는 실수 공간의 곡률이 있는 곡선 &lt;em&gt;r(t)&lt;/em&gt; 에서 유도된다. 중간에 있는 &lt;em&gt;t&lt;/em&gt; 는 시간을 나타내며 이는 이동한 거리, 곡선의 호 &lt;em&gt;s&lt;/em&gt; 로 매개화 시킨다고 한다. 그래서 그 곡선 &lt;em&gt;r(t(s))&lt;/em&gt; 를 미분해서 방향을 나타내는 말들이 우리가 평상시에 많이 들어왔던 노말, 탄젠트, 바이노말인 것이다.&lt;/p&gt;

&lt;p&gt;탄젠트는 곡선 공식을 그대로 미분한 값. 우리가 알고있는 일반적인 순간 가속도를 뜻한다. 이게 결국 방향을 나타내기 때문에 한글로는 비슷하게 접선벡터 라고 하는 듯하다. 그리고 현재 방향의 수직을 나타내는 노말은 탄젠트를 미분한 값을 정규화시켜서 표현한다. 필자는 이 값이 수학적으로 어떤 것을 나타내는지 몰라서 직관적으로 수식을보고 법선벡터인지 모르겠다. 마지막으로 바이노말은 탄젠트와 노말을 외적해서 구한다.&lt;/p&gt;

&lt;p&gt;여기까지는 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 을 위한 정의들이다. 사실 &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 보다는 앞에서 말한  &lt;em&gt;“프레네-세레 프레임”&lt;/em&gt; 의 정의가 훨씬 더 많이 알려져 있다. 빛을 나타내기 위한 노말과 탄젠트를 그래픽스 이론에서는 끊임없이 보기 때문이다. &lt;em&gt;“프레네-세레 공식”&lt;/em&gt; 에 대한 자세한건 이 글에서는 쓰지 않겠다. 이 글을 쓴 이유는 우리가 흔히 쓰는 용어의 뿌리를 찾기위함이였다. (자세한 설명은 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;을 참조)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas&quot;&gt;Wikipedia : Frene-seret formula&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%ED%94%84%EB%A0%88%EB%84%A4-%EC%84%B8%EB%A0%88_%EA%B3%B5%EC%8B%9D&quot;&gt;위키피디아 : 프레네-세레 공식&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://gall.dcinside.com/board/view/?id=mathematics&amp;amp;no=134445&quot;&gt;디시인사이드 수학 갤러리&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="study" />
      

      

      
        <summary type="html">Graphics 를 공부하다보면 노말(normal), 탄젠트(tangent), 바이노말(binormal) 를 굉장히 많이보게 된다. 특히 노말이라는 단어는 꽤나 많이 보인다. 보통은 어떤 역할을 하는 벡터앞에 이름을 붙여서 말한다. 아래와 같이 정리된다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Optimized Center Of Rotation</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/" rel="alternate" type="text/html" title="Optimized Center Of Rotation" />
      <published>2017-07-22T00:00:00+00:00</published>
      <updated>2017-07-22T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/22/optimized-center-of-rotation/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;dual quaternion skinning&lt;/a&gt; 글에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 설명해 보았다. 이전 글에서는 단순히 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 의 단점에 대해서 언급했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dqs_ocor_bent.png&quot; alt=&quot;both bent&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 표현한 그림이고, 오른쪽은 곧 소개할 &lt;em&gt;optimized center of rotation&lt;/em&gt; 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 &lt;em&gt;dual quternion skinning&lt;/em&gt; 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 &lt;em&gt;joint bulging artifact&lt;/em&gt; 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 은 약간 움푹 들어간 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 &lt;em&gt;Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/em&gt; 이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;이 방식은 간단한 아이디어로 접근하면서도 기존의 &lt;em&gt;Weight Blending&lt;/em&gt; 데이터와 호환되며, 런타임에서도 꽤나 쓸만한 방식이다. 또한 처리하는 데이터도 &lt;em&gt;linear bleding skinning&lt;/em&gt; 과 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 에 비해서도 조금 늘었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 의 기본적인 아이디어는 기존의 방식은 회전 축의 위치가 뼈의 가중치로 결정되어 문제가 생기는 것을 알아채서 각 정점별로 다른 회전의 위치(&lt;em&gt;center of rotation&lt;/em&gt;)를 정해 주는 것이다. 앞에 붙은 &lt;em&gt;optimized&lt;/em&gt; 가 내포한 의미도 있다. 사실 모든 정점별로 &lt;em&gt;center of rotation&lt;/em&gt; 을 정해주면 굉장히 번거롭다. 또한 이 논문에서 소개하는 계산방식은 실시간으로 계산하기에는 너무 느리다. 그래서 이 논문에서는 각 정점별로 기본 포즈(보통 T 포즈를 뜻함.)를 기준으로 &lt;em&gt;center of rotatoin&lt;/em&gt; 을 미리 데이터를 계산해서 실시간으로는 데이터를 참조해서 &lt;em&gt;skinning&lt;/em&gt; 을 한다.&lt;/p&gt;

&lt;p&gt;그런데 이 스키닝 방식을 구현하려면 먼저 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산해주는 코드를 직접 짜야한다. 아직은 3D 에디팅 툴에서 지원을 하지 않기 때문이다. 게임 엔진들 또한 마찬가지다. 또한 일반적인 싱글 스레드 프로그램으로 짜기에는 너무 데이터가 많아서 여러 스레드를 이용하는 멀티 스레딩이나 GPGPU 기술을 사용해서 구현해야 한다. 필자는 구현의 편의성을 위해 멀티 스레딩을 사용했지만 조금 느렸다. 꽤나 괜찮은 GPU 를 가지고 있으면 GPGPU 를 사용하는것이 훨씬 빠를 것이다.&lt;/p&gt;

&lt;p&gt;자세한 방법을 알고 싶으면 논문을 참고하라.(&lt;a href=&quot;https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20160705174939/Real-time-Skeletal-Skinning-with-Optimized-Centers-of-Rotation-Paper.pdf&quot;&gt;논문 링크&lt;/a&gt;) 논문에서 나오는 첫번째로 소개되는 정점과 정점간에 &lt;em&gt;similarity&lt;/em&gt; 를 계산하는 식과 &lt;em&gt;center of rotation&lt;/em&gt; 위치를 계산하는 네번째 식, 그 아래에 있는 Intergration 항목을 참조하면 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 코드를 짤 수 있다. &lt;em&gt;center of rotation&lt;/em&gt; 을 계산하는 방식의 아이디어는 꽤나 간단하다. &lt;em&gt;bone weight&lt;/em&gt; 들의 연관성(&lt;em&gt;similarity&lt;/em&gt;) 를 계산해 이 숫자를 각 정점간의 가중치로 설정한다. 이 연관성(&lt;em&gt;similarity&lt;/em&gt;)를 계산하기 위해서는 최소 두개의 같은 뼈의 가중치를 가지고 있어야 한다. 만약 아무것도 연관성이 없다면 &lt;em&gt;linear blending skinning&lt;/em&gt; 으로 계산하게 하면 된다. 그리고 각각 폴리곤의 세 정점의 평균 &lt;em&gt;similarity&lt;/em&gt; 와 폴리곤의 세 정점의 평균 위치, 그리고 삼각형의 넓이를 계산해서 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산한다.&lt;/p&gt;

&lt;p&gt;다만 논문의 처음에서는 모든 정점을 기준으로 전부 &lt;em&gt;similarity&lt;/em&gt; 를 계산하다는 늬앙스가 있었는데 그런식으로 계산하면 굉정히 오래걸린다고 논문에 쓰여져 있었다.(싱글 스레드 C++ 기준 30000 개의 정점을 가진 모델) 그래서 이 논문에서는 여러 방법을 제시했다. 가장 중점적인 것은 &lt;em&gt;bone weight&lt;/em&gt; 끼리의 거리를 직접 계산하여 &lt;em&gt;cluster&lt;/em&gt;(집단)을 구성하여 &lt;em&gt;center of rotation&lt;/em&gt; 을 계산할 때 계산하는 절대적인 데이터를 줄이는 방법이다. 또한 일정 &lt;em&gt;similarity&lt;/em&gt; 보다 값이 적으면 탐색을 중단하는 방법도 제시했다. 그리고 마지막으로 제시한 방법은 위에서도 말한 병렬 프로그래밍을 이용하는 것이다.&lt;/p&gt;

&lt;p&gt;직접 스키닝을 계산하는 방법도 간단하다. 회전 연산은 기존의 행렬로 계산하던 것을 사원수로 변환 후 회전 연사을 하는 사원수를 &lt;em&gt;blending&lt;/em&gt; 하면된다. 위치 이동 연산은 살짝 다른데, &lt;em&gt;linear blending skinning&lt;/em&gt; 에서 정점을 계산하는 식을 정점 대신 &lt;em&gt;center of rotation&lt;/em&gt; 으로 계산 후에 그 값에다가 &lt;em&gt;blending&lt;/em&gt; 된 사원수로 &lt;em&gt;center of rotation&lt;/em&gt; 값을 변환시켜 빼주면 위치 이동 값(translate)가 완성된다. 위치 이동 값(translate)는 정점을 회전 연산 후에 값을 더해주기만 하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;optimized center of rotation&lt;/em&gt; 을 계산하는 코드와 해당 skinning 방법을 Unity 로 구현해 놓았다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다. (&lt;em&gt;center of rotation&lt;/em&gt; 을 정확하게 논문에 나온대로 계산하는 코드를 짠것은 아닙니다. 그 부분은 이해 해주시고 참고해주길 바랍니다. 또한 자세한 방법을 아시는 분은 댓글 달아주시면 감사하겠습니다.)&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.disneyresearch.com/publication/skinning-with-optimized-cors/&quot;&gt;Disney Reasearch : Real-time Skeletal Skinning with Optimized Centers of Rotation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 dual quaternion skinning 글에서 dual quaternion skinning 에 대해서 설명해 보았다. 이전 글에서는 단순히 dual quaternion skinning 에 대해서 알아보고 장점에 대해서 알아보았다. 단점에 대해서는 언급을 하지않았는데 사실 단점도 존재하긴 한다. 새로 소개할 방법의 논문에서 dual quaternion skinning 의 단점에 대해서 언급했다. joint bulging artifact 라고 하는 것인데, 90도 정도 휜 부분의 바깥쪽이 튀어나오는 현상을 말한다. 아래 그림에서 볼 수 있다. 왼쪽은 dual quaternion skinning 을 표현한 그림이고, 오른쪽은 곧 소개할 optimized center of rotation 방법이 적용된 스키닝이다. 각 그림의 오른쪽의 90도 휜 부분을 관찰하면 dual quternion skinning 이 약간 아래가 부푼 모습을 볼 수 있다. 이를 joint bulging artifact 라고 한다. 그리고 오른쪽 위의 확대된 그림을 보면 dual quaternion skinning 은 약간 움푹 들어간 것을 볼 수 있다. 그래서 디즈니 리서치라는 연구소에서 새로운 방법을 2016 년 Siggraph 에서 소개했다. 논문의 이름은 Real-time Skeletal Skinning with Optimized Centers of Rotation 이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Dual Quaternion Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/" rel="alternate" type="text/html" title="Dual Quaternion Skinning" />
      <published>2017-07-20T00:00:00+00:00</published>
      <updated>2017-07-20T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/20/dual-quaternion-skinning/">&lt;p&gt;이전 &lt;a href=&quot;/2017/07/07/introduce-of-skinning/&quot;&gt;Introduce of skinning&lt;/a&gt; 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 은 정점을 변환시키기 위해 행렬을 사용한다. 위치나 벡터를 1x4, 4x1 행렬로 취급해 행렬곱으로 계산해 위치값을 변환시킨다. 즉 한개의 값을 이용해서 변환을 한다. 조금 불편한 점은 변환 행렬을 &lt;em&gt;Weight Blending&lt;/em&gt; 하기가 어렵다.(필자의 경우 행렬을 Blending 하는데 실패했습니다. 아마 행렬 데이터 정규화가 안되서 그런것 같습니다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample/issues/6&quot;&gt;링크&lt;/a&gt;에 증상이 있으니, 혹여나 방법을 아신다면 댓글 부탁드립니다.) 그래서 각 뼈를 기준으로 변환된 위치를 뼈의 가중치로 평균값을 내서 최종 변환된 정점을 구한다.&lt;/p&gt;

&lt;p&gt;행렬을 사용한 변환의 장점은 위치 변환(translate), 회전 변환(rotation), 크기 변환(scaling)을 포함한 세가지 변환들을 전부 합쳐서 정보를 가지고 있을 수 있다. 물론 분리해서도 가능하다. 단점은 행렬 곱을 아는 사람은 알겠지만 절대적인 곱셈, 덧셈의 량이 꽤 된다. 3개의 변환을 합친 변환 행렬은 일반적으로 4x4 행렬을 사용하고 아무리 최적화를 해도 4x3 행렬을 사용하는게 전부다. 가장 중요한 단점은 &lt;em&gt;Linear&lt;/em&gt; 하게 위치를 &lt;em&gt;Blending&lt;/em&gt; 시키니 전글에서도 언급한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 뽑을 수 있겠다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;a href=&quot;https://www.cs.utah.edu/~ladislav/&quot;&gt;Ladislav Kavan&lt;/a&gt; 이라는 사람이 꽤나 많은 연구를 통해 다양한 논문을 내었는데 그 중 주목할 것은 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 이다. 필자는 이 정보를 처음 접했을 때 조금 이해가 안되는 부분이 많이 있었다. 계산 방식 등 꽤나 이상한게 많았는데 &lt;em&gt;dual quaternion&lt;/em&gt; 이라는 개념이 우리가 알고 있는 일반적인 대수적인 개념에서 확장된 개념이였다. 게임 프로그래머라면 많이 들어봤을 법한 사원수(quaternion)과 &lt;em&gt;dual number&lt;/em&gt; 라는 이름만 들어도 생소한 개념의 단위를 합친 개념이다. 이를 수학적으로 알아보기 쉽게 자세히 설명하기엔 필자의 지식 수준이 매우 짧기에 정말 간단하게 설명하겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual number&lt;/em&gt; 라는건 두개의 숫자를 하나의 단위로 본다. 또한 여러 연산이 가능하도록 정의되어 있다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 사원수를 두개 가진 하나의 단위이다. 기본적으로 &lt;em&gt;dual number&lt;/em&gt; 의 연산을 따르지만 사원수(quaternion)의 개념에 의해 조금 바뀌는 부분이 꽤 있다. &lt;em&gt;dual&lt;/em&gt; 이니 두개의 개념이 있는데, 첫번째 개념은 &lt;em&gt;real&lt;/em&gt; 이라고 부른다. 두번째 개념은 &lt;em&gt;dual&lt;/em&gt; 이라고 부른다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;dual quaternion&lt;/em&gt; 은 변환을 위해 사용될 수 있고 우리가 사용할 목적과도 같다. 일반적으로 행렬은 위치, 회전, 크기 변환에 쓰인다고 했다. &lt;em&gt;dual quaternion&lt;/em&gt; 은 일반적으로 위치, 회전 변환을 포함하고 있다. 또한 크기 변환도 가능하긴 하다. 일단은 크기 변환은 넘어가도록 하겠다. 그러면 우리가 볼것은 위치, 회전 변환인데 두개의 사원수에 회전 변환과 위치 변환이 각각 나뉘어져 들어간다. 첫번째 &lt;em&gt;real&lt;/em&gt; 에 회전변환이 들어가고, 두번째 &lt;em&gt;dual&lt;/em&gt; 에 위치변환이 들어간다. 그렇게 &lt;em&gt;dual quaternion&lt;/em&gt; 이 구성된다. 또한 각자 &lt;em&gt;dual quaternion&lt;/em&gt; 과 &lt;em&gt;Weight blending&lt;/em&gt; 도 정상적으로 되고(&lt;em&gt;quaternion&lt;/em&gt; 자체가 &lt;em&gt;blending&lt;/em&gt; 이 가능하기 때문이다.) &lt;em&gt;dual quaternion&lt;/em&gt; 끼리 합칠 수도 있고, 정점 변환도 가능하다. 그래서 이 &lt;em&gt;dual quaternion&lt;/em&gt; 을 &lt;em&gt;matrix&lt;/em&gt; 변환과 치환해서 사용이 가능하다.&lt;/p&gt;

&lt;p&gt;또한 앞에서 강조한 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상도 어느정도 극복할 수 있다. 그냥 일반적으로 생각해 보았을 때 변환된 정점의 가중치를 곱해 평균값을 구한 것과는 다르게 변환 자체를 전부 합쳐서 한번의 변환으로 변환된 정점을 얻는 것은 조금 다르다고 생각된다. 필자는 Unity 를 사용하여 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 구현했다. &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;Github : CustomSkinningExample&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;간단하게 &lt;em&gt;“Candy Wrapper”&lt;/em&gt; 현상을 해결하기 위해선 이 &lt;em&gt;dual quaternion skinning&lt;/em&gt; 을 사용하면 된다. 하지만 필자는 약 10년전의 기술보다 더 나은 기술이 있을거라 생각해 여러가지 찾아보았다. 그 중 게임에서 쓸 수 있는 스키닝 기법을 하나 발견했다. 그 방법은 다음 글에서 확인해보자. &lt;a href=&quot;/2017/07/22/optimized-center-of-rotation/&quot;&gt;다음 글&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/other/dualQuaternion/&quot;&gt;EuclideanSpace : dual quaternion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://skinning.org/&quot;&gt;Skinning.org&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">이전 Introduce of skinning 글에서 Skinning 에 대한 설명과 LBS 에 관한 내용을 간단하게 다루어 보았다. 하지만 글 마지막에 해결되지 않은 문제가 하나 있었다. Linear Blend Skinning 의 “Candy Wrapper” 라는 현상이였는데, 이 글에서는 그 문제를 위해 2008년에 고안된 방법에 대해서 알아볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Introduce Of Skinning</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/" rel="alternate" type="text/html" title="Introduce Of Skinning" />
      <published>2017-07-07T00:00:00+00:00</published>
      <updated>2017-07-07T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/07/introduce-of-skinning/">&lt;p&gt;2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 &lt;a href=&quot;/2017/05/19/handling-rig-and-skinning/&quot;&gt;handling rig and skinning&lt;/a&gt; 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;일반적으로 3D 물체는 대부분 고정된 정점을 가지고 그대로 그려진다. 물체의 정점들이 한꺼번에 움직이는 방법은 흔하나 정점 하나하나 각자 움직이는 경우는 몇 없다. 모든 정점이 자기만의 기준을 가지고 움직이면 엄청난 계산량을 요구하기 때문이다. 하지만 게임을 만들려면 정점을 움직여서 표현하여 보다 실제적인 움직임을 연출할 수 있을 수도 있다. 극단적인 예를 들면 펄럭이는 옷가지라던가 부서지는 오브젝트가 있겠다. 하지만 방금전에 말한 두가지는 굉장히 극단적인 이야기이고 살아 움직이는 물체를 표현하기 위해 스키닝이라는 기술이 있다. 예를 들면 사람 혹은 동물이 있겠다.&lt;/p&gt;

&lt;p&gt;스키닝이라는 말은 직역하면 &lt;em&gt;“피부를 입히다.”&lt;/em&gt; 라는 뜻이다. 하지만 일반적인 3D 오브젝트는 정해진 정점들을 이어서 삼각형을 만들어 꽤 많은 갯수의 삼각형으로 외형을 표현한다. 이렇게 생각하면 바깥의 피부를 입힌다는 것은 조금 이해가 안될 것이다. 여태까지 엄청나게 많은 이론이 나왔지만 게임에서 쓰이는 3D 모델의 스키닝이라는 용어는 일반적으로 생각하는 뜻이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;정점의 집합으로 이루어진 3D 물체에서 특정한 위치를 가지고 있는 “뼈” 라는 개념이 있다.&lt;/li&gt;
  &lt;li&gt;“뼈” 는 일반적은 3D 오브젝트가 가질 수 있는 변환을 할 수 있다. (Translate, Rotation, Scale)&lt;/li&gt;
  &lt;li&gt;각 정점들은 특정한 “뼈” 를 기준으로 잡아 기준이 되는 “뼈” 의 변환 정보를 각 정점에 적용시켜 뼈가 움직이면 정점도 같이 움직이게 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위에서 설명한 세가지가 적용이 된것이 “스키닝” 이 적용된 3D 물체라고 할 수 있다. 이 간단한 개념이 확장되어 현 시대의 게임에서도 쓰이고 있다. 매우 간단한 이 방법은 약간의 문제가 있다. 관절같은 경우 두개이상의 “뼈” 변환을 참조해야 한다. 어떻게 두개 이상의 “뼈” 변환을 합칠 것인가? 이 문제는 아직까지도 완전히 해결되지 않았고 이 문제를 해결하기 위해 꽤 많은 논문들이 나왔다. 단순히 뼈를 이용하는 방식 뿐만아니라 다양한 방식으로도 말이다. 먼저 가장 널리 알려지고 가장 많이 쓰이는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라는 방법이 있다. 이 방법은 굉~장히 단순하다. 그만큼 많이 쓰이는 듯 싶다. 논문이 1988년에 나온 기술로.. 조금만 잔머리 굴리면 쓸만한 내용이다. 두개 이상의 뼈의 변환 행렬을 정점 위치를 계산하여 정해진 가중치에 비례해서 값을 섞는다. 이 방식은 보통 값과 값사이의 특정한 위치를 가져올때 쓰이는 방법이다. 이 방식은 수학적으로 생각해보면 울퉁불퉁한 곡선에 해당되는게 아니라 선형적으로 값을 보간하는 방법이므로 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 이라고 불리는 것이다. Unity 의 스키닝된 메쉬를 그리는 &lt;em&gt;Skinned Mesh Renderer&lt;/em&gt; 컴포넌트가 아직도 LBS 를 사용하고 있다. 하지만 이 방법은 흔히 알려진 문제가 하나 있다. &lt;em&gt;‘Candy Wrapper’&lt;/em&gt; - 한국어로 사탕 껍질 이라고 불리는 현상인데, 아래 그림의 사탕 껍질을 이야기 하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/candy_wrapper.jpg&quot; alt=&quot;사탕 껍질&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;주목할 것은 안의 사탕이 아니라 양 옆의 꼬여져서 엄청 가늘어진 상태의 껍질이다. LBS 를 사용하면 해당 오브젝트의 관절이 저렇게 표현될 수 있다. 해당 축으로 180도 돌리면 말이다. 아래 그림에 상세하게 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/umbra-ignite-2015-rulon-raymond-the-state-of-skinning-a-dive-into-modern-approaches-to-model-skinning-33-638.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하여튼 &lt;em&gt;Linear Based Blending&lt;/em&gt; 은 현 시대에서는 그다지 유용한 기술은 아니다. 하지만 많은 곳에서 채택되어 아직도 남아있다. 많은 사람들의 관심이 몰리는 분야는 아니기 때문에 기술 발전 자체는 그다지 빠른편이 아니다. 하지만 30년 전의 기술을 아직도 쓴다는건 그리 좋은 생각은 아닌 것 같다. 이를 위해 10년전에 괜찮은 수 체계를 도입했다. 이는 다음 글에서 설명하겠다. 다음 글 : &lt;a href=&quot;/2017/07/20/dual-quaternion-skinning/&quot;&gt;&lt;em&gt;dual quaternion skinning&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;혹시 &lt;em&gt;Linear Blend Skinning&lt;/em&gt; 의 Unity 구현을 보고 싶으면 &lt;a href=&quot;https://github.com/hrmrzizon/CustomSkinningExample&quot;&gt;GitHub : CustomSkinningExample&lt;/a&gt; 에서 보면 된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonschreibt.de/gat/renderhell-book1/&quot;&gt;RenderHell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fratarcangeli.net/wp-content/uploads/GRAPP.pdf&quot;&gt;Paper : State of the Art in Skinning Techniques for Articulated Deformable Characters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="skinning" />
      
        <category term="vertex deformation" />
      
        <category term="try" />
      

      

      
        <summary type="html">2달전 쯤에 스키닝에 대한 글을 본적이 있다. 그때는 스키닝이 뭔지도 정확히 모르던 시점이였다. Unity 에서는 LBS 라는 방법으로 스키닝을 지원하는데 이 방식보다 나은 방식이 있는데 어찌하여 옛날 방식을 지원하는지에 대한 불만글이였다. 그래서 공부할 것을 찾던 필자는 Unity 에서의 커스텀 스키닝을 구현을 목표로 잡았다. 정리를 위해 하나하나 글을 남겨보도록 하겠다. 이 글에서는 간단히 스키닝의 개념에 대해서 써보도록 하겠다. 이전에 쓴 handling rig and skinning 에서도 간략하게 다루었지만 기초 지식이 없는 상태에서 급하게 쓴 글이였고, 굉장히 Unity 스러운 글이기에 다시 처음부터 써보겠다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Translate Gamedev Structured Buffer Vs Constant Buffer</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/" rel="alternate" type="text/html" title="Translate Gamedev Structured Buffer Vs Constant Buffer" />
      <published>2017-07-06T00:00:00+00:00</published>
      <updated>2017-07-06T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/">&lt;p&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt;의 답변 해석 글이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;유저 tsus 의 답변.&lt;/h3&gt;

&lt;p&gt;첫번째로 메모리 액세스가 다르게 작동한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 모든 스레드(역자 : GPU 안의 각각의 코어에서 도는 스레드) 에서 동일한 값을 Warp하게(정확히 뜻을 모르겠다) 접근하면 엄청나게 빠르다. 하지만 스레드 각각 다른 지점(역자 : 장소? 배열의 인덱싱을 말하는 듯 하다)를 접근하면 데이터를 읽는 방식이 직렬화된다. 이 현상은 &lt;em&gt;Constant Waterfalling&lt;/em&gt; 이라고 불리며 읽는 속도를 굉장히 느리게한다. 이는 뼈 애니메이션(역자 : 스키닝)을 하려는 사람들에게 두통을 유발한다. 설명한 세가지 시나리오 중 마지막 시나리오를 빼고 전부 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 &lt;em&gt;cbuffer&lt;/em&gt; 와 다르게 &lt;em&gt;통합 캐시 구조&lt;/em&gt; 를 사용하여 최적화했다. &lt;em&gt;통합 캐시 구조&lt;/em&gt; 는 첫번째 읽는 속도는 느리지만 뒤에 같은 데이터를 다시 읽는 것은 빠르다는 것이다.(물론 캐싱된 경우를 뜻한다.)&lt;/p&gt;

&lt;p&gt;두번째로 사용이 제한되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 특수 레지스터에 존재하기 때문에 굉장히 빠르다. 하지만 레지스터의 크기는 64kb 로 굉장히 작다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 레지스터에 저장되지 않으므로 더 많은 공간을 사용할 수 있다. 즉 저장된 데이터가 많아지면 &lt;em&gt;StructedBuffer&lt;/em&gt; 를 사용해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 렌더링 파이프 라인 어느 지점에서도 바인딩 할 수 없다.(역자 : 바인딩의 뜻을 모름니다;) 이는 정점 버퍼처럼 취급되지 않는다는 것을 뜻한다. DirectX10 의 하드웨어는 임의의 접근을 통한 쓰기를 타입을 가진 리소스(텍스쳐, 정점 버퍼)에 지원하지 않기 때문에 DirectCompute 를 DirectX10 에서 지원했다. 그래서 모든 쉐이더 단계에서 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 읽을 수 있게 되었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 숨겨진 꿀(?) 기능이 있다.(역자 : 그다지 꿀인지는 모르겠는데..) 접근한 스레드의 갯수를 세서 다른 여러 스레드에서 접근하게 해주는 &lt;em&gt;“hidden counter”&lt;/em&gt; 라는 기능이다. 게다가 이 카운터는 &lt;em&gt;ByteAddressBuffer&lt;/em&gt; 에 &lt;em&gt;interlockedAdd&lt;/em&gt; 를 사용하는 것 보다 조금 빠르다. &lt;em&gt;ByteAddressBuffer&lt;/em&gt; 는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 와는 다르게 형식이 정해져 있지 않아 어디에든지 바인딩이 될 수 있는 버퍼다.&lt;/p&gt;

&lt;h3&gt;운영자 MJP 의 답변&lt;/h3&gt;

&lt;p&gt;“Constant” 라는 단어는 쉐이더 프로그램이 실행될 동안 값이 일정하다는 것을 나타내며 CPU 값을 변경할 수 없다는것은 아니다. 이 단어는 DX10 이전에 나온 단어로써 쉐이더에 정의된 소수의 상수를 &lt;em&gt;Shader Constants&lt;/em&gt; 라고 했을 때 나온 단어다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Constant Buffer&lt;/em&gt; 는 작은 양의 원하는(역자 : heterogeneous 라고 표기하는데 이해가 안됨.) 값들을 쉐이더에서 이름을 가지게 하여 직접 접근하게 하려는 목적을 가지고 있다. 그래서 첫번째 예의 &lt;em&gt;View Matrix&lt;/em&gt; 와 &lt;em&gt;Projection Natrix&lt;/em&gt; 를 가지는 예제는 &lt;em&gt;Constant Buffer&lt;/em&gt; 에 완벽하게 어울린다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 구조체 배열과 같이 원하는 구조체의 배열을 뜻한다. 그래서 인덱스로 여러개를 접근할만한 데이터가 있다면 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 사용하는 걸 원할 것이다. 3번째로 예를든 조명 리스트는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 사용하기 좋다.&lt;/p&gt;

&lt;p&gt;DOF 쉐이더는 둘다 사용가능하다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 를 쓰고 데이터를 반복해서 읽으면 조금 부담스럽지만 가능은 하다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 읽기 동작을 계속 반복하지만, 정적 &lt;em&gt;cbuffer&lt;/em&gt; 읽기 동작은 더 최적화 되어있다. 정적 &lt;em&gt;cbuffer&lt;/em&gt; 읽기는 반복문이(Loop) 없어야 한다. Loop 가 존재하면 다른 쉐이더의 순열(역자 : permutations 라고 적혀있음, 의역 불능)이 필요할 수도 있다.&lt;/p&gt;

&lt;p&gt;어쨋든 현대 GPU 하드웨어는 일반적으로 동작하며, API 에서 제공하는 추상화간에 큰 차이는 거의 없다. 하드웨어가 덜 유연한 DX9 포함 이전 버젼의 GPU 들과는 많이 다르다. 다만 적절한 성능을 찾고싶다면 프로파일링을 해야한다.&lt;/p&gt;

&lt;p&gt;보통 프로그래머의 관점에서는 &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 비슷하게 보인다. 하지만 두 버퍼는 꽤 중요한 차이점이 있다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="translate" />
      
        <category term="try" />
      

      

      
        <summary type="html">GameDev : structured buffer vs constant buffer의 답변 해석 글이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Structured Buffer Vs Constant Buffer</title>
      
      <link href="https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer/" rel="alternate" type="text/html" title="Structured Buffer Vs Constant Buffer" />
      <published>2017-07-06T00:00:00+00:00</published>
      <updated>2017-07-06T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/07/06/structured-buffer-vs-constant-buffer/">&lt;p&gt;CG 로 쉐이더 코딩을 하기 위해 여러 소스와 웹페이지를 뒤지던 도중 재미있는 글을 발견했다. HLSL 에서 사용하는 &lt;em&gt;StructuredBuffer&lt;/em&gt; 와 &lt;em&gt;Constant Buffer&lt;/em&gt; 의 차이에 대한 글이였다. Unity 메뉴얼을 따라가면서 몇번 보긴했지만 무슨 차이인지도 모르는 것들이였다. 하지만 알고나니 GPU Instancing 에 대한 기본적인 상식이기에 글을 쓴다. 우선 두가지를 먼저 간단하게 알아보고 두 개념의 차이에 대해서 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;&lt;em&gt;Constant Buffer&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;이름을 직역하면 상수 버퍼다. 직관적인 느낌은 단순한 고정값 참조를 위한 버퍼인 것 같다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509581%28v=vs.85%29.aspx&quot;&gt;MSDN : Shader Constants&lt;/a&gt; 페이지에서 자세한 정보를 확인할 수 있다. 문서의 내용은 &lt;em&gt;Shdaer Model 4&lt;/em&gt; (DirectX10 이 &lt;em&gt;Shdaer Model 4&lt;/em&gt; 를 지원함.) 부터 쉐이더에서 쓰이는 상수(쉐이더 코드에서 변화시키지 않는 변수, 이하  &lt;em&gt;Shader Constants&lt;/em&gt;) 전용 버퍼 리소스를 제공한다고 한다. &lt;em&gt;Shader Constants&lt;/em&gt; 의 장점은 변경되지 않는 특징을 사용해 CPU 로 부터 낮은 시간으로 더 많이 업데이트를 받을 수 있다는 장점이 있다. 단점은 빠른만큼 제약조건이 여러개 있다는 것이다. 데이터의 크기는 정해져 있어야 하며 일정 크기를 넘기지 못한다. 그리고 데이터의 레이아웃(데이터를 정의하는데에 한계가 있는 듯하다. 필자는 정확히 모름)과 데이터를 접근할 때 한 쉐이더에서만 접근이 가능하다. 정점 쉐이더면 정점 쉐이더 전용, 프래그먼트 쉐이더면 프래그먼트 전용 상수 버퍼를 쓸 수 있다는 말이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shader Constants&lt;/em&gt; 는 두가지의 데이터의 형태를 지원하는데 하나는 위에서 언급한 &lt;em&gt;Constant Buffer&lt;/em&gt;(&lt;em&gt;cbuffer&lt;/em&gt;) 이고 하나는 &lt;em&gt;Texture Buffer&lt;/em&gt;(&lt;em&gt;tbuffer&lt;/em&gt;) 라는 놈이다. &lt;em&gt;tbuffer&lt;/em&gt; 는 텍스쳐처럼 접근 가능하다고 한다. 이 말은 뒤에 쓰여진 말을 생각해보면 이해할 수 있다. 임의로 인덱싱된 데이터에 대해 더 잘 수행된다고 쓰여있는데 이 말은 배열처럼 인덱스 단위로 바로바로 접근이 가능해서 랜덤으로 인덱스를 정해서 접근해도 잘 접근이 되야된다는 소리다. &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;tbuffer&lt;/em&gt; 의 갯수 제한은 없다. 각각의 크기 제한만 있을 뿐이다. 이 두가지 버퍼를 선언하는 방법은 C 언어의 구조체를 선언하는 법과 매우 유사하다고 한다. 정말 그렇다. 또한 직접 레지스터에 데이터를 넣고 싶거나, 데이터의 패킹 오프셋(C 언어에서는 padding 이라는 단어로 알려져 있다.) 을 설정할 수도 있다. 다만 Shader 에서는 1바이트가 기본이 아닌 16바이트 패킹이 기본이다. 16바이트 중 4바이트 단위로 접근을 할 수 있다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 GPU Instancing 기본 예제를 DirectX 의 경우에는 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용하게 한다. 아래처럼 선언하게 되어 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;UNITY_INSTANCING_CBUFFER_START(_CBufferName)
  ...
UNITY_INSTANCING_CBUFFER_END
&lt;/code&gt;&lt;/pre&gt;
&lt;!--__ --&gt;
&lt;p&gt;전처리가 끝나서 HLSL 식으로 컨버팅되면 아래와 같이 된다. Unity 에서 제공하는 쉐이더 코드를 참조했다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;cbuffer _CBufferName {
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unity 에서 제공하는 예제는 단순하게 컬러값을 인스턴스별로 바꾸게 해주는 그리하여 여러개의 메터리얼을 사용하지 않아 쓸데없는 &lt;em&gt;SetPass&lt;/em&gt; 를 안하게 해주는 예제다. 이 값들은 쉐이더에서 변경할 필요가 없는 상수 값이므로 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용해도 문제가 없다.&lt;/p&gt;

&lt;p&gt;하지만 필자는 &lt;a href=&quot;/2017/06/08/performence-and-optimization/&quot;&gt;Appocrypha : GPU Instancing&lt;/a&gt; 글에서 &lt;em&gt;cbuffer&lt;/em&gt; 가 추구하는 방향과는 조금 다르게 사용했다. 저 글을 쓸때 한창 스키닝에 대해 관심이 많았기 때문에 &lt;em&gt;cbuffer&lt;/em&gt; 를 사용해서 각 뼈들의 위치와 회전 데이터들을 사용했다. 하지만 저 사용용도는 그다지 좋지 않은 생각이였다. 이유는 글의 끝에서 말하겠다.&lt;/p&gt;

&lt;h2&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;다음으로 알아볼 것은 &lt;em&gt;StructuredBuffer&lt;/em&gt; 다. 이 역시 맨 처음 등장한 것은 &lt;em&gt;Shader Model 4&lt;/em&gt; 부터 등장했다. 초기에는 사용 용도가 약간 한정되어 있는 것처럼 나온다. &lt;em&gt;Shader Model 4&lt;/em&gt; 에서는 읽기 전용의 버퍼만 지원하고, 버퍼의 종류가 적었다. 또한 사용 용도가 컴퓨터 쉐이더와 픽셀 쉐이더로 한정 되어 있었다고 한다. &lt;em&gt;Shader Model 5&lt;/em&gt; 부터는 다양한 변종의 버퍼들을 지원하고, 모든 쉐이더 코드에서 사용이 가능하게 되었다. 이는 쉐이더 코딩의 여러 가능성을 열어 주었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 는 &lt;em&gt;cbuffer&lt;/em&gt; 의 정의처럼 정적으로 명세를 지정했던 방식과는 다른 데이터를 접근하는 방식이다. &lt;em&gt;cbuffer&lt;/em&gt; 는 정해진 크기의 변수만 접근이 가능했다. 하지만 &lt;em&gt;StructuredBuffer&lt;/em&gt; 는 데이터를 쉐이더 코드에서 전역변수로 길이에 상관없는 리스트 형식으로 인덱스를 사용해 접근할 수 있는 데이터 형식이다. 사용하자면 아래와 같이 사용할 수 있겠다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;
struct vertex
{
  float3 position;
  float3 normal;
}

StructuredBuffer&amp;lt;vertex&amp;gt; perVertexDataBuffer;

v2f vert (uint vertexID : SV_VertexID)
{
  vertex v = perVertexDataBuffer[vertexID];

  ...

  return someData;
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Shader Model 5&lt;/em&gt; 에서는 쓰기도 가능한 &lt;em&gt;RWStructuredBuffer&lt;/em&gt; 와 단순한 데이터 한개씩 저장하는 &lt;em&gt;Buffer&lt;/em&gt;, &lt;em&gt;RWBuffer&lt;/em&gt; 등 특이한 다른 컨테이너도 지원해서 꽤나 재미있는 코딩이 가능할 듯 하다.&lt;/p&gt;

&lt;h2&gt;결론?&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;StructuredBuffer&lt;/em&gt; 의 장단점에 대해서는 말하지 않았다. MSDN 에서도 그다지 자세하게 쓰여있지는 않다. 사실 필자도 그다지 관심이 없었다. 그냥 있으면 있는대로 쓰는거지 라는 생각을 당분간 하다가 문득 의문이 들었다. 도대체 무슨 차이길래 다르게 지원하는 것인가에 대한 의문이였다. 그래서 &lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt; 을 찾아 읽었고 꽤나 흥미로운 사실이였다. &lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;원문 링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;질문글은 &lt;em&gt;cbuffer&lt;/em&gt; 와 &lt;em&gt;StructuredBuffer&lt;/em&gt; 의 차이점에 대한 데이터가 없어 무슨 차이 인지, 그리고 3가지의 예시를 들어 각각 어떤게 더 알맞는지에 대한 구체적인 글이였다. 글또한 꽤나 잘쓰여져 있지만 질문글 보다 더욱더 봐야할 것은 아래에 달린 답글 2개다. 일반적으로 알기 힘든 사실들을 다루고 있다. 하나의 글은 두 버퍼의 차이에 대하여 써놨으며 하나의 답글은 질문글의 핀트에 맞추어 답글을 써놓았다. 해당 글의 답변 해석은 블로그에 올려놓았다. &lt;a href=&quot;/2017/07/06/translate-gamedev-structured-buffer-vs-constant-buffer/&quot;&gt;글 링크&lt;/a&gt; 에서 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cbuffer&lt;/em&gt; 는 레지스터를 사용하여 작으나 빠르고, 배열을 각각 다른 스레드에서 전부 다른 인덱스로 접근하면 느려진다. &lt;em&gt;StructuredBuffer&lt;/em&gt; 조금은 느리나 내부적으로 thread-safe 하게 구현되어 있고, 데이터 캐싱을 한다. 또한 크기의 제한이 없어 자유롭게 쓰고, 크기가 입력에 따라서 달라져서 유동적인 데이터에 쓸만하다는 것이다. 위에서 스키닝을 &lt;em&gt;cbuffer&lt;/em&gt; 로 사용한게 문제라고 했었는데, 글을 보면 알겠지만 &lt;em&gt;cbuffer&lt;/em&gt; 에서 각각 다른 인덱스로 접근하면 느려지니 문제인 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb509581%28v=vs.85%29.aspx&quot;&gt;MSDN : Shader Constants&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff471514%28v=vs.85%29.aspx&quot;&gt;MSDN Reference : StructuredBuffer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ff476335%28v=vs.85%29.aspx&quot;&gt;MSDN : New Resource Types&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gamedev.net/forums/topic/624529-structured-buffers-vs-constant-buffers/&quot;&gt;GameDev : structured buffer vs constant buffer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="gpuinstancing" />
      
        <category term="try" />
      

      

      
        <summary type="html">CG 로 쉐이더 코딩을 하기 위해 여러 소스와 웹페이지를 뒤지던 도중 재미있는 글을 발견했다. HLSL 에서 사용하는 StructuredBuffer 와 Constant Buffer 의 차이에 대한 글이였다. Unity 메뉴얼을 따라가면서 몇번 보긴했지만 무슨 차이인지도 모르는 것들이였다. 하지만 알고나니 GPU Instancing 에 대한 기본적인 상식이기에 글을 쓴다. 우선 두가지를 먼저 간단하게 알아보고 두 개념의 차이에 대해서 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Gpu Instancing In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity/" rel="alternate" type="text/html" title="Using Gpu Instancing In Unity" />
      <published>2017-06-11T00:00:00+00:00</published>
      <updated>2017-06-11T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/11/using-gpu-instancing-in-unity/">&lt;p&gt;&lt;strong&gt;이 글은 Unity 5.6.1f 버젼에서 작성되었습니다. 다른 버젼에서는 에러가 날 수 있으니 참고 바랍니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/2017/06/04/using-texture2darray-in-unity/&quot;&gt;Using Texture2DArray in Unity&lt;/a&gt; 에 이어 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄이기 위한 방법에 대해서 소개하려한다. GPU Instancing 이라는 방법인데 &lt;em&gt;TextureArray&lt;/em&gt; 와 같이 응용해서 사용하면 획기적으로 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;일반적으로 알려진 &lt;em&gt;GPU Instancing&lt;/em&gt; 에 대해서 말하자면 컴퓨터의 RAM 에만 저장하던 데이터들을 GPU 메모리에 복사해놓고 GPGPU 나 쉐이더를 실행할 때 빠르게 데이터에 접근하는 것을 GPU Instancing 이라 한다. 만약 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용하지 않으면 매번 &lt;em&gt;DrawCall&lt;/em&gt; 에 데이터를 넣어줘야하기 때문에 수많은 &lt;em&gt;DrawCall&lt;/em&gt; 이 걸리게 되고 이는 CPU 의 시간을 뺏어먹게 되어 영 좋지 않은 일이 된다. 보통은 같은 동작을 하는 오브젝트들을 최적화할 때 쓰인다. 사용하게 되면 &lt;em&gt;DrawCall&lt;/em&gt; 이 &lt;em&gt;O(&lt;strong&gt;오브젝트 갯수&lt;/strong&gt;)&lt;/em&gt; 로 되던것이 O(1) 의 갯수로 줄어든다. 그래서 &lt;em&gt;TextureArray&lt;/em&gt; 와 같이 사용하게 되면 &lt;em&gt;DrawCall&lt;/em&gt; 이 &lt;em&gt;O(&lt;strong&gt;오브젝트 갯수&lt;/strong&gt; * &lt;strong&gt;텍스쳐 갯수&lt;/strong&gt;)&lt;/em&gt; 로 계산되던게 &lt;em&gt;O(&lt;strong&gt;1&lt;/strong&gt;)&lt;/em&gt; 로 바뀌어 버리니 CPU 시간을 엄청나게 많이벌 수 있다. 다만 GPU 메모리를 많이 잡아먹기 때문에 신경써서 데이터를 구성하지 않으면 무슨일이 일어날지 모른다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;기술을 써보기 전에 우선 구현 사항부터 생각해야 한다. 필자는 Unity 에서 지원하는 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 가 &lt;em&gt;DrawCall&lt;/em&gt; 배칭을 해주지 않아 간단한 스키닝을 직접 구현하였다. &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 가 많은 기능을 지원하긴 하지만 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 컴포넌트의 갯수가 절대적으로 많아지고 매터리얼이 늘어나게 되면 어쩔 수 없이 원하는 기능을 붙여 직접 구현해야 한다. &lt;a href=&quot;git@github.com:hrmrzizon/InstancedSkinningExmaple.git&quot;&gt;InstancedSkinning&lt;/a&gt;에서 참고할 수 있다.&lt;/p&gt;

&lt;p&gt;해야할 것은 두가지다. 쉐이더에서 데이터를 선언 후 직접 사용하는 코드를 짜주어야 하고, 스크립트에서는 필요한 데이터를 모아서 넣어주기만 하면 된다. 말로는 간단하지만 신경써주어야 할것이 많다. 필자 역시 간단하다고 생각하여 시작했으나 꽤 많은 삽질 끝에 성공했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GPU Instancing&lt;/em&gt; 의 핵심은 GPU 메모리에 어떤 데이터들을 어떻게 옮겨놓고 그 데이터들을 어떻게 사용하느냐가 제일 핵심이다. 스크립트에서는 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스를 통해 데이터를 한꺼번에 세팅하고 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드를 호출해 그린다. 보통은 매 프레임별로 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 호출하기 때문에 적당히 코딩이 되어있다면 필요할때마다 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스에 데이터를 갱신해주기만 하면 된다. &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 은 쉐이더에 들어가는 정보들을 취급하는 데이터 뭉치(chunk)다. &lt;strong&gt;Material&lt;/strong&gt; 은 쉐이더 정보와 필요한 데이터를 가지고 있는 인스턴스다. 쉐이더 정보를 가지고 있기 때문에 매터리얼의 갯수가 많으면 많을수록 &lt;em&gt;DrawCall&lt;/em&gt; 의 갯수가 늘어난다. 하지만 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 은 &lt;strong&gt;Material&lt;/strong&gt; 과는 다르게 정보만 가지고 있는 것이기 때문에 &lt;em&gt;DrawCall&lt;/em&gt; 의 갯수가 늘어나지 않는다. &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 관한 자세한 사용법은 &lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/MaterialPropertyBlock.html&quot;&gt;Unity Reference : MaterialPropertyBlock&lt;/a&gt; 을 참고하라.&lt;/p&gt;

&lt;p&gt;아 그러면 쉐이더는 어디서 정의하냐고? &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드는 &lt;strong&gt;Material&lt;/strong&gt; 과 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 둘다 필요하다. 적당히 데이터를 분리해서 취급하면 된다. 아래 그리는 코드를 살펴보자. &lt;a href=&quot;https://github.com/hrmrzizon/InstancedSkinningExmaple/blob/master/Assets/2%20-%20InstancedSkinning/CharacterSet.cs&quot;&gt;InstancedSkinning - CharacterSet&lt;/a&gt; 에서 간추려서 가져왔다.&lt;/p&gt;

&lt;div class=&quot;language-csharp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CharacterData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DrawData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drawDataDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drawDataDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;GetEnumerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;MoveNext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;DrawData&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;UpdateMatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;UpdateMaterialblcok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Graphics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;DrawMeshInstanced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;material&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mainMatrixList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;castShadow&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;UnityEngine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Rendering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ShadowCastingMode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;On&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;UnityEngine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Rendering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ShadowCastingMode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;receiveShadow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;drawLayerNumber&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;drawCamera&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Material&lt;/strong&gt; 인스턴스는 단 한개이며 &lt;strong&gt;Texture2DArray&lt;/strong&gt; 를 사용해 모든 텍스쳐를 하나로 합쳐 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄였다. &lt;strong&gt;DrawData&lt;/strong&gt; 는 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 메소드 호출을하기 위한 구조체 데이터다. 기본적으로 물체를 그릴때 필요한 &lt;strong&gt;Mesh&lt;/strong&gt; 인스턴스와 각 그려야할 인스턴스 별로 필요한 변환행렬들을 가지고 있는 &lt;em&gt;DrawData.mainMatrixList&lt;/em&gt;, 필요한 데이터를 저장하고 있는 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 인스턴스 &lt;em&gt;DrawData.block&lt;/em&gt; 을 가지고 있다. &lt;em&gt;DrawData.UpdateMaterialblcok&lt;/em&gt; 메소드는 필요한 데이터들을 &lt;em&gt;DrawData.block&lt;/em&gt; 에 넘겨주는 메소드다.&lt;/p&gt;

&lt;p&gt;여기까지 스크립트에서 해주어야할 것들에 대해 말했다. 필요한 데이터들을 준비하고 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 로 한꺼번에 그려주는게 핵심이다. 이제 쉐이더 코딩에 대해 알아보자. Unity 에서의 쉐이더 코딩은 굉장히 복잡하다. Unity 는 여러 플랫폼을 위한 엔진이기 때문에 여러 플랫폼, Graphics API 에 대한 세팅이 필요하며 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용할 때 약간의 애로사항이 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용할 때 결국 데이터는 전부 배열로 들어오게 된다. 각종 쉐이더 언어(HLSL, GLSL)에서 지원하는 &lt;em&gt;instanceID&lt;/em&gt; 라는 배열에 접근하기 위한 인덱스가 있다. 이 인덱스에 접근하는 기능을 여러 플랫폼과 Graphics API 지원을 위해 해당 기능을 전처리기 구문으로 감싸놓았는데 Unity 엔진 사용자는 접근을 할수가 없다. 즉 배열의 인덱스에 직접 접근이 불가능하다는 것이다. 이렇게 되면 깔끔하게 코딩이 안되서 굉장히 불편할 뿐만 아니라 데이터도 효율적으로 쓰지 못한다.&lt;/p&gt;

&lt;p&gt;또한 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용하려면 옵션을 하나 붙여주어야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#pragma exclude_renderers d3d9 gles d3d11_9x
#pragma only_renderers d3d11 glcore gles3 metal vulkan

#pragma multi_compile_instancing

#include &quot;UnityCG.cginc&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위와 같이 &lt;em&gt;UnityCG.cginc&lt;/em&gt; 파일을 포함하기 전에 전처리기 옵션 : &lt;em&gt;multi_compile_instancing&lt;/em&gt; 을 붙여주어야 한다. 저 옵션을 안붙이게 되면 컴포넌트 렌더러(&lt;strong&gt;MeshRenderer&lt;/strong&gt;, &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt;)에서 개별로 쓰이는 쉐이더만 컴파일하게 되는데 그 상태에서 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용하게 되면 아예 렌더링이 되지 않는다. 그래서 &lt;em&gt;GPU Instancing&lt;/em&gt; 에 필요한 쉐이더도 동시에 컴파일 하라는 옵션이 &lt;em&gt;multi_compile_instancing&lt;/em&gt; 옵션이다.&lt;/p&gt;

&lt;p&gt;해당 옵션위에 다른 옵션들이 쓰여져 있는데 directX9 버젼이나 OpenGL ES 2.X 버젼에서는 제대로된 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 사용하지 못하므로 &lt;em&gt;exclude_renderers&lt;/em&gt; 에 명시된 Graphics API 에서 돌아가는 쉐이더는 컴파일하지 말라는 옵션으로 생각하며 된다. 또한 동시에 &lt;em&gt;only_renderers&lt;/em&gt; 옵션도 사용했는데 이는 해당 Graphics API 를 위한 쉐이더만 컴파일하라는 옵션이다. 보통 두가지를 동시에 쓰지는 않지만 정확한 명시를 위해 적어놓았다. 이제 쉐이더 프로그램에서 인스턴싱된 버퍼들을 사용하는 방법과 편법에 대해서 알아보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;struct a2v
{
	float3 uv : TEXCOORD0;
	float4 vertex : POSITION;
	UNITY_VERTEX_INPUT_INSTANCE_ID
};

struct v2f
{
	float4 vertex : SV_POSITION;
	float2 uv : TEXCOORD0;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;여기서 주목할 것은 a2v 구조체에 있는 &lt;em&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/em&gt; 매크로다. 이는 각 쉐이더 별로 &lt;em&gt;instanceID&lt;/em&gt; 를 정의해주는 매크로 인데, 역시나 여러 플랫폼을 위해 전처리기로 처리 되어있다. 그리고 a2v 는 버텍스 쉐이더에 들어가는 인자를 구조체로 묶어놓은 것인데 만약 프래그먼트 쉐이더에서 &lt;em&gt;GPU Instancing&lt;/em&gt; 을 하려면 인자로 들어가는 v2f 구조체에 &lt;em&gt;UNITY_VERTEX_INPUT_INSTANCE_ID&lt;/em&gt; 매크로의 정의가 필요할 것이다. 이 쉐이더는 필요가 없어 넣지 않은 상태이다. 이제 버퍼들을 정의하고 사용하는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#define UNITY_MAX_INSTANCE_COUNT 100

UNITY_INSTANCING_CBUFFER_START(_BonePositions)
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition0);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition1);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition2);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition3);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition4);
	UNITY_DEFINE_INSTANCED_PROP(float4, _BonePosition5);
UNITY_INSTANCING_CBUFFER_END

float4 GetPosition(uint index)
{
	switch(index)
	{
		case 0:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition0);
		case 1:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition1);
		case 2:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition2);
		case 3:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition3);
		case 4:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition4);
		case 5:
			return UNITY_ACCESS_INSTANCED_PROP(_BonePosition5);
	}

	return float4(1, 1, 1, 1);
}

UNITY_INSTANCING_CBUFFER_START(_BoneMatrixs) /* 위 선언와 비슷함 */ UNITY_INSTANCING_CBUFFER_END

float4x4 GetMatrix(uint index) { /* 위 함수와 비슷함 */ }

v2f vert (a2v v)
{
	v2f o;

	UNITY_SETUP_INSTANCE_ID(v);

	uint boneIndex = v.uv[2];

	float4 pos = GetPosition(boneIndex);

	o.vertex = UnityObjectToClipPos(
					mul(
						GetMatrix(boneIndex),
						float4(v.vertex.xyz - pos.xyz,1)
					)
					+
					float4(pos.xyz, 0)
				);
	o.uv = v.uv.xy;

	return o;
}
&amp;lt;!-- __) --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;우선 데이터를 저장할 버퍼를 선언해야 한다. 이는 GPU 메모리에 저장되는 버퍼인데 DirectX 에서는 &lt;em&gt;constant buffer&lt;/em&gt; 라고 하고, OpenGL 에서는 &lt;em&gt;uniform buffer object&lt;/em&gt; 라고 한다. 하여튼 이렇게 선언되는 버퍼에 들어가는 정보는 &lt;strong&gt;Material&lt;/strong&gt; 이나 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 저장한 정보들에서 똑같은 변수이름을 가진 변수에게 저장된다. 보통은 쉐이더의 &lt;em&gt;Properties&lt;/em&gt; 에 선언된 변수들은 &lt;strong&gt;Material&lt;/strong&gt; 에 저장하고, 버퍼 오브젝트들은 &lt;strong&gt;MaterialPropertyBlock&lt;/strong&gt; 에 저장된 데이터와 맞춰준다. 둘의 사용용도가 거의 일치하기 때문이라고 보면된다.&lt;/p&gt;

&lt;p&gt;선언하는 방법은 간단하다. &lt;em&gt;UNITY_INSTANCING_CBUFFER_START&lt;/em&gt;, &lt;em&gt;UNITY_INSTANCING_CBUFFER_END&lt;/em&gt; 로 정의할 영역을 정해주고 그 안에 필요한 데이터들을 &lt;em&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/em&gt; 구문을 사용하여 정의해주면 된다. &lt;em&gt;UNITY_DEFINE_INSTANCED_PROP&lt;/em&gt; 구문에는 자료형과 이름을 써주면 알아서 정의가 된다. 이 역시 HLSL 과 GLSL 로 알아서 컨버팅 되도록 한것이다. 그리고 해당 변수에 접근할 때는 &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 를 사용하여 접근하면 된다.  이렇게 해주면 &lt;em&gt;multi_compile_instancing&lt;/em&gt; 때문에 일반적인 컴포넌트 렌더러에서 쓰는 쉐이더와 &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 에서 쓰는 쉐이더로 알아서 컴파일된다. &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 로 접근을 한 이유도 여기에 있다. &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 를 사용할때는 배열에 접근해야 하고, 컴포넌트 렌더러를 사용할때는 단순 인스턴스에 접근해야한다. 즉 배열의 인덱스로 접근하기위해 &lt;em&gt;UNITY_ACCESS_INSTANCED_PROP&lt;/em&gt; 를 사용한다고 보면된다.&lt;/p&gt;

&lt;p&gt;근데 위 코드처럼 인스턴싱을 많이하게 되면 아래와 같은 에러를 띄우면서 컴파일이 안될때가 있다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Can't continue validation - aborting. (on d3d11)
Index Dimension 2 out of range (12000 specified, max allowed is 4096) for operand #1 of opcode #5 (counts are 1-based). Aborting. (on d3d11)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그래서 위 코드에서 바꿔준 것이 맨 위에있는 전처리기 정의 구문이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#define UNITY_MAX_INSTANCE_COUNT 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이는 약간 HACK 한 방식으로 커스터마이징을 한것이다. &lt;em&gt;Graphics.DrawMeshInstanced&lt;/em&gt; 에서 쓰이는 쉐이더는 배열로 변수들을 선언하는데 기본 배열의 길이가 500 이다. 물론 모바일 같은 플랫폼에서는 4를 나누어줘서 125 이긴 하지만 PC 대상으로 컴파일하면 정의한 변수 한개당 500개씩 정의가 되서 변환 행렬덕분에 엄청난 메모리를 먹게된다. 그리고 배열 아이템의 갯수 4096 개를 초과해서 에러가 나는 것이다. 그래서 전처리기로 처리한 것에 약간의 편법을 써서 &lt;em&gt;UNITY_MAX_INSTANCE_COUNT&lt;/em&gt; 를 필요할때마다 정의해주면 배열의 크기를 맘대로 조정할 수 있다. 위의 코드는 에러를 막기위해 임시적으로 조절한 것이지만 참조한 인스턴스의 갯수가 적으면 직접 조정해주는 편이 낫다. 물론 인덱스를 벗어나지 않는 범위에서 말이다. 이 방법은 Unity 사이트에서 built-in 쉐이더를 받아 확인하여 코딩하였다.&lt;/p&gt;

&lt;p&gt;그리고 굳이 배열로 선언하고 싶지 않고 한번 실행하는 쉐이더당 한개의 변수만 필요한 경우 아래와 같이 단순하게 정의해주면 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;UNITY_INSTANCING_CBUFFER_START(_FragmentBuffer)
	float _TextureIndex;
UNITY_INSTANCING_CBUFFER_END

UNITY_DECLARE_TEX2DARRAY(_MainTexArray);

fixed4 frag (v2f i) : SV_Target
{
	fixed4 col = UNITY_SAMPLE_TEX2DARRAY(_MainTexArray, float3(i.uv, _TextureIndex));
	return col;
}

&lt;/code&gt;&lt;/pre&gt;
&lt;!-- ___)(____) --&gt;

&lt;p&gt;저렇게 하면 단순하게 사용할 수 있다. 물론 컴파일 에러는 안난다. 해당 코드는 &lt;a href=&quot;https://github.com/hrmrzizon/InstancedSkinningExmaple&quot;&gt;Github : InstancedSkinningExmaple&lt;/a&gt; 에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;자세한 방법은 &lt;a href=&quot;https://docs.unity3d.com/Manual/GPUInstancing.html&quot;&gt;Unity Manual : GPU Instancing&lt;/a&gt; 에 적혀있으니 참고하길 바란다. 글을 쓰는 현재 2017년 6월 12일에는 한글 문서는 존재하지도 않는다. 영어로 읽어야한다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/GPUInstancing.html&quot;&gt;Unity Manual : GPU Instancing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/CassEveritt/approaching-zero-driver-overhead&quot;&gt;Slideshare : Approach Zero Driver Overhead&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/ScriptReference/MaterialPropertyBlock.html&quot;&gt;Unity Reference : MaterialPropertyBlock&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">이 글은 Unity 5.6.1f 버젼에서 작성되었습니다. 다른 버젼에서는 에러가 날 수 있으니 참고 바랍니다. Using Texture2DArray in Unity 에 이어 DrawCall 을 줄이기 위한 방법에 대해서 소개하려한다. GPU Instancing 이라는 방법인데 TextureArray 와 같이 응용해서 사용하면 획기적으로 DrawCall 을 줄일 수 있다. 일반적으로 알려진 GPU Instancing 에 대해서 말하자면 컴퓨터의 RAM 에만 저장하던 데이터들을 GPU 메모리에 복사해놓고 GPGPU 나 쉐이더를 실행할 때 빠르게 데이터에 접근하는 것을 GPU Instancing 이라 한다. 만약 GPU Instancing 을 사용하지 않으면 매번 DrawCall 에 데이터를 넣어줘야하기 때문에 수많은 DrawCall 이 걸리게 되고 이는 CPU 의 시간을 뺏어먹게 되어 영 좋지 않은 일이 된다. 보통은 같은 동작을 하는 오브젝트들을 최적화할 때 쓰인다. 사용하게 되면 DrawCall 이 O(오브젝트 갯수) 로 되던것이 O(1) 의 갯수로 줄어든다. 그래서 TextureArray 와 같이 사용하게 되면 DrawCall 이 O(오브젝트 갯수 * 텍스쳐 갯수) 로 계산되던게 O(1) 로 바뀌어 버리니 CPU 시간을 엄청나게 많이벌 수 있다. 다만 GPU 메모리를 많이 잡아먹기 때문에 신경써서 데이터를 구성하지 않으면 무슨일이 일어날지 모른다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Performence And Optimization</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/08/performence-and-optimization/" rel="alternate" type="text/html" title="Performence And Optimization" />
      <published>2017-06-08T00:00:00+00:00</published>
      <updated>2017-06-08T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/08/performence-and-optimization</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/08/performence-and-optimization/">&lt;p&gt;일반적인 응용 프로그램들은 중간중간에 잠시 멈춰도 원하는 결과를 유저에게 보여주면 상관이 없다. 하지만 게임은 ‘게임중’ 에는 어떤 경우에도 렉을 허용하지 않는다. 그만큼 ‘게임중’ 상태에서 렉을 아예 발생시키지 않는 것이 게임 프로그래머의 중요한 능력중 하나다.&lt;/p&gt;

&lt;p&gt;게임은 일반적으로 1초에 60번 이상 업데이트하는 루틴을 유지해야 유저에게 원활한 환경을 제공한다. 여기서 급작스럽게 프레임수가 하락하면 그때 유저들은 순간적으로 끊기거나 부드럽지 않은 경험을 하게된다. 유저들은 그런 것들을 랙으로 통칭한다. 랙이 반복되면 유저들은 게이밍 환경에 불만을 느끼게 된다.&lt;/p&gt;

&lt;p&gt;일반적인 랙은 프로그래머의 실수인 경우가 많다. 런타임에서 많은 것을 한꺼번에 처리하는 경우가 대표적이다. 하지만 이는 여러 리팩토링을 거치면 충분히 해결할 수 있다. 경험이 적은 사람들에게 가장 문제가 되는 것은 엔진을 사용하는 방법이 문제가 되는 경우가 많다. 엔진의 자세한 구현 사항을 파악하지 못했기 때문에 한계를 생각하지 않고 코딩하는 경우 말이다. 몇가지 사항들만 주의하며 코딩한다면 꽤 많은 병목들을 피해갈 수 있다.&lt;/p&gt;

&lt;p&gt;이제 Unity 엔진을 사용할 때 퍼포먼스에 영향을 끼치는 것들과 해결 방안에 대해서 알아보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;만들어진 소프트웨어를 최대한 플랫폼의 자원을 덜 소모하고 빠르게 작업을 수행하게하는 것을 “최적화를 한다” 라고 한다. 게임이라는 소프트웨어의 최적화는 보통 게임 플레이 시간에 매 프레임 별로 최대한 시간을 덜 소모하게 하는 것을 일반적으로 여겨진다.&lt;/p&gt;

&lt;p&gt;그래서 Unity 는 게임 플레이 시간동안 걸리는 작업들의 시간을 측정하는 툴을 지원한다. 이름은 &lt;em&gt;Profiler&lt;/em&gt; 라고 한다. &lt;em&gt;Profiler&lt;/em&gt; 를 통해 시간이 많이 걸리는 부분을 찾을 수 있다. &lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/ProfilerWindow.html&quot;&gt;Unity 메뉴얼&lt;/a&gt;에서 자세한 사용법을 확인하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.unity3d.com/kr/current/uploads/Main/ProfilerTimeline.png&quot; alt=&quot;Unity Profiler&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 일반적인 CPU 시간을 잴 때 사용하는 모드로써 위에서 언급한 스크립트의 실행시간을 체크할 때 쓸 수 있는 모드 중 하나다. 직접 켜보면(Window -&amp;gt; Profiler) 알 수 있듯이 CPU 시간 말고도 다른 특수한 작업들의 디테일한 사항을 볼 수 있다. 실시간으로 렌더링 되는 것들을 체크할 수 있는 &lt;strong&gt;Rendering&lt;/strong&gt; 모드, 메모리를 얼마나 쓰는지 확인할 수 있는 &lt;strong&gt;Memory&lt;/strong&gt; 모드, Unity 에서 가져다 쓰는 물리엔진 &lt;em&gt;PhysX&lt;/em&gt; 에서 주로퍼포먼스에 영향을 끼치는 것들에 대하여 정보를 나타내주는 &lt;strong&gt;Physics&lt;/strong&gt; 모드 등 꽤 많은 것들이 있다. 실시간으로 대부분의 문제를 찾을 수 있기 때문에 꽤 많은 시간들을 줄여준다.&lt;/p&gt;

&lt;p&gt;게다가 더욱더 강력하다고 생각되는 사실은 &lt;strong&gt;Android&lt;/strong&gt; 플랫폼에서 이 &lt;em&gt;Profiler&lt;/em&gt; 를 사용가능 하다는 것이다. &lt;em&gt;ADB&lt;/em&gt; 라는 디버깅 유닛이 있는데, Unity 에서는 이 유닛을 직접 사용하여 연결만 잘 되어있다면 프로파일러를 돌려볼 수 있다.&lt;/p&gt;

&lt;p&gt;Unity 에서는 꽤나 좋은 &lt;em&gt;Profiler&lt;/em&gt; 를 지원한다. 시간이 난다면 게임을 처음부터 끝까지 몇번 돌려보길 바란다. 문제가 생겼을 때 돌려보는 것 보단 되도록 자주 체크하여 항상 문제가 있는지 없는지 체크해보는 것이 좋다. 시간이 없을 떄 처리하려면 골치아픈 문제가 되겠지만 시간이 여유로울 떄 발견하면 아주 큰 문제가 아닌 이상 처리하기는 편할 것이다. 또한 &lt;em&gt;Profiler&lt;/em&gt; 는 자신의 컴퓨터의 처리 속도를 체크하는 것이다. 그러므로 자신의 컴퓨터가 아주 좋은 플랫폼이라면 안좋은 플랫폼에서도 디버깅을 해보는 것도 좋을 것이다.&lt;/p&gt;

&lt;h2&gt;Hierachy and component based development&lt;/h2&gt;

&lt;p&gt;Unity 는 &lt;em&gt;Scene&lt;/em&gt; 이라 불리는 데이터 안에 여러 &lt;em&gt;GameObject&lt;/em&gt; 의 세팅을 넣어놓고 저장된 &lt;em&gt;GameObject&lt;/em&gt; 에 붙어있는 &lt;em&gt;Component&lt;/em&gt; 의 동작에 의해 게임이 돌아간다. 실제로 Unity 에서 동작하는 것들은 &lt;em&gt;Component&lt;/em&gt; 들인데 이렇게 여러 오브젝트들에 각자 &lt;em&gt;Component&lt;/em&gt; 를 붙여 동작하는 개발 방식을 CBD(Comnent based development) 라고 한다. Unity 는 CBD 를 근본적인 개념으로 차용해 정해져 있는 형식 없이 개발하도록 지원한다.&lt;/p&gt;

&lt;p&gt;Unity 는 CBD 를 밑바닥부터 구현하도록 지원하지만 이게 꼭 좋은 것은 아니다. 특히 성능상으로 따졌을 떄 컴포넌트가 많이 존재하면 존재할수록 컴포넌트들 안에 Unity 시스템에서 받는 메세지 메소드들이 많이 구현되어 있을수록 약간의 부하가 발생한다. (물론 절대적인 몇천개, 몇백개의 갯수를 뜻한다. CPU 의 성능에 따라 모바일에서는 간단한 수학 연산을 하는 몇십개의 메소드도 부담스러울수도 있다.) 제일 문제가 되는 부분은 &lt;em&gt;MonoBehaviour.Update&lt;/em&gt; 류의 메소드들이다.(&lt;em&gt;MonoBehaviour.LateUpdate&lt;/em&gt;, &lt;em&gt;MonoBehaviour.FixedUpdate&lt;/em&gt;) 이 메소드들은 매 프레임마다 호출되어야 하는 메소드들인데 이 메소드를 받는 컴포넌트들이 많으면 많을수록 부담되는 것은 사실이다.&lt;/p&gt;

&lt;p&gt;일반적인 상황에서는 한 메소드가 같은 프레임에 몇백번 이상 호출될 일은 없겠지만 그럴 일이 있다면 미리 합쳐주는 것을 추천한다.&lt;/p&gt;

&lt;h2&gt;PhysX&lt;/h2&gt;

&lt;p&gt;Unity 의 물리 기능은 서드파티 라이브러리인 &lt;em&gt;PhysX&lt;/em&gt; 를 탑재하여 기본으로 물리 기능을 지원한다. &lt;em&gt;PhysX&lt;/em&gt; 는 GameWorks 라는 게임 개발을 위한 미들웨어 제품 그룹에 있던 라이브러리 중 하나다. 그래서 우리는 About Unity 창을 열면 꽤 큼지막하게 자리를 차지하는 &lt;em&gt;PhysX&lt;/em&gt; 의 로고를 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/about_unity.png&quot; alt=&quot;About Unity&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unity 에서 PhsyX 는 물리 엔진으로서 자리 잡고 있는 것을 볼 수 있다. 하지만 PhsyX 는 자원이 한정되어 있는 플랫폼에서는 잘 사용해주어야 한다. 몇가지를 세팅해주어 한정적으로 돌아가게 해야되는데 해주어야 세팅들을 살펴보자.&lt;/p&gt;

&lt;h4&gt;Physics Setting : layer collision matrix&lt;/h4&gt;

&lt;p&gt;Unity 에서는 &lt;strong&gt;GameObject&lt;/strong&gt; 별로 &lt;em&gt;layer&lt;/em&gt; 를 설정해주어 여러가지 설정을 한다. 대표적인 예는 카메라에서 어떤 오브젝트를 그릴지 &lt;em&gt;layer&lt;/em&gt; 마스크를 통하는 것이다. 그리고 PhsyX 에서 돌아가는 물리 세팅도 &lt;em&gt;layer&lt;/em&gt; 기반으로 검사를 한다. 충돌 검사를 하는 연산이 많으면 많을수록 성능에 그다지 안좋은 영향을 끼치기에 &lt;em&gt;layer&lt;/em&gt; 별로 검사할 것들을 설정해 줄 수 있다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/physics_settings.png&quot; alt=&quot;Physics setting&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기는 Edit -&amp;gt; Project Settings -&amp;gt; Physics 으로 들어올 수 있는 프로젝트 별로 물리 관련된 옵션을 세팅해주는 곳이다. 여기서 Layer Collision Matrix 를 보면 된다. 이 이상하게 생긴 체크박스들은 해당 레이어와 충돌 체크를 하여 물리 연산을 하는지 안하는지에 대한 세팅 값이다. 이 부분만 체크해주어도 쓸데없는 연산을 없엘 수 있으니 신경써서 잘 체크해주길 바란다.&lt;/p&gt;

&lt;h4&gt;Time Setting : Fixed Timestamp&lt;/h4&gt;

&lt;p&gt;이제 언급하려는 부분은 상당히 게임에서 민감한 부분이다. 물리 기능을 하는 루프는 정확한 계산을 위해 일정 시간마다 체크를 하는데 이 체크를 하는 시간 주기를 Edit -&amp;gt; Project Settings -&amp;gt; Time 에서 변경할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/setting_timer.png&quot; alt=&quot;Timer Setting&quot; /&gt;&lt;/p&gt;

&lt;p&gt;맨 처음에 보이는 Fixed Timestep 을 직접 바꾸어줄 수 있다. 이 숫자를 늘리면 매 프레임별 부하는 줄어들지만 정확성이 줄어든다. 이 숫자를 줄이면 매 프레임별 부하는 커지지만 물리 계산 결과는 정확해진다. 하지만 한가지 명심할 것이 있다. 이 부분은 실제 체크하는 부분을 담당하기 때문에 이미 만들어진 게임에서 이 숫자를 바꾸면 무슨일이 일어날지 모른다. 반드시 만들어진 게임에서, 특히 Collider 를 많이 쓰는 게임에서는 이 숫자를 철저한 검사후에 바꿔주어야 한다. 물론 Unity 의 물리 계산을 아예 안쓸거라면 엄청 크게 해주면 된다.&lt;/p&gt;

&lt;h4&gt;절대적인 Collider 의 갯수&lt;/h4&gt;

&lt;p&gt;위에서 GameObject 의 갯수에 대해서 말했었다. 이와 같이 Collider 의 갯수는 많으면 많을 수록 다른 레이어의 오브젝트들과 비교하는 대상이 많아지므로 더욱더 부하가 커진다. 즉 적절한 Collider 의 갯수도 중요하다.&lt;/p&gt;

&lt;h2&gt;Garbage Collection&lt;/h2&gt;

&lt;p&gt;Unity 는 개발 언어와 여러 환경을 위해 &lt;strong&gt;Mono&lt;/strong&gt; 프레임워크를 사용한다. 그리고 &lt;strong&gt;Mono&lt;/strong&gt; 프레임워크에서는 메모리 관리를 위해 &lt;strong&gt;Garbage Collector&lt;/strong&gt; 를 사용한다. GC 를 사용하게 되면 가끔씩 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 이 발생하는데 이 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 은 게이밍 환경에서는 정말 최악의 행동이다. 대부분 &lt;strong&gt;Garbage Collection&lt;/strong&gt; 은 꽤나 시간이 걸리기 때문에 잠깐 끊기는 현상이 발생할 수 밖에 없다. 결국 게임 중에는 절~~대로 쓰레기(Garbage) 메모리를 만들면 안된다. 게임 시간이 얼마나 길어질지 모르고 플랫폼의 특성도 모르기 때문에 게임 중에는 쓰레기 메모리를 절대 안 만드는게 가장 안전하다. 위에서 언급한 &lt;em&gt;Profiler&lt;/em&gt; 를 통해 쓰레기 메모리들이 얼마나 발생하는지 GC Alloc 탭에서 체크할 수 있다.  &lt;strong&gt;Deep Profile&lt;/strong&gt; 기능까지 사용하면 메소드 단위로 알 수 있기 때문에 쓰레기 메모리를 만드는 부분을 하나하나 체크하여 없에는 것이 중요하다. 쓰레기를 발생시키는 코드의 유형은 꽤나 많기 때문에 여기서는 언급하지 않겠다.&lt;/p&gt;

&lt;h2&gt;Drawcall and Batching&lt;/h2&gt;

&lt;p&gt;Graphics API 에서는 물체를 그릴려면 여러 준비를 해야한다. 이 준비는 어느 정도의 시간이 걸리기 때문에 많으면 많을수록 상당히 부담스럽다. 준비를 마치면 GPU 에 그려달라는 명령을 한다. 이 명령을 &lt;em&gt;Draw Call&lt;/em&gt; 이라고 한다. &lt;em&gt;Draw Call&lt;/em&gt; 의 숫자는 모바일 게임의 경우 아무리 많아도 몇십개로 유지해야하며 고사양 PC 게임은 몇백단위로 유지해야 한다고 한다. 왜냐하면 &lt;em&gt;Draw Call&lt;/em&gt; 의 횟수가 많으면 많을수록 CPU 에서 부담하는 것들이 많아지기 때문에 결국 FPS 하락으로 이어질 수밖에 없다. 그런데 Unity 에서는 &lt;em&gt;Draw Call&lt;/em&gt; 이라는 단어는 엔진을 사용할 때 볼일이 하나도 없다. 이렇게 중요한데 왜 없냐하면 Unity 는 이 &lt;em&gt;Draw Call&lt;/em&gt; 을 줄이기 위해 엔진 내부에서 처리를 하는데 이를 &lt;em&gt;Batching&lt;/em&gt; 이라고 한다. 결국 &lt;em&gt;Draw Call&lt;/em&gt; 과 같은 단어지만 일정한 조건만 지키면 알아서 &lt;em&gt;Batching&lt;/em&gt; 카운트를 줄여준다. Unity 에서 최대한 &lt;em&gt;Batching&lt;/em&gt; 카운트를 줄이는 방법에 대하여 알아보자. 우선은 엔진에서 지원하는 것들에 대하여 알아보자.&lt;/p&gt;

&lt;p&gt;Unity 에서는 &lt;em&gt;Draw Call&lt;/em&gt; 을 줄이기 위해 &lt;em&gt;Static Batching&lt;/em&gt; 과 &lt;em&gt;Dynamic Batching&lt;/em&gt; 이 두가지 기능을 지원한다.  &lt;em&gt;Static Batching&lt;/em&gt; 은 움직이지 않는 오브젝트들을 세팅할 때 한꺼번에 그리는 기능이다. 만약 움직이는 오브젝트라면 항상 위치를 갱신해주어야 하기 때문에 준비를 다시해야 하지만 움직이지 않는 오브젝트라면 미리 움직이지 않는다고 체크를 하고 그대로 위치를 가지고 GPU 에서 그려주면 되기 때문이다.&lt;/p&gt;

&lt;p&gt;또한 전제조건으로 메터리얼을 공유해야 한다는 조건이 있다. 메터리얼에는 여러 인자와 쉐이더가 세팅되어 있는데 이 메터리얼을 공유해야 한다는 조건은 같은 쉐이더를 사용해야 &lt;em&gt;Batching&lt;/em&gt; 카운트를 합칠 수 있다는 이야기다.&lt;/p&gt;

&lt;p&gt;아래는 &lt;em&gt;Static Batching&lt;/em&gt; 을 에디터에서 세팅해주는 사진이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://docs.unity3d.com/kr/current/uploads/Main/StaticTagInspector.png&quot; alt=&quot;Static Tag Inspector&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Dynamic Batching&lt;/em&gt; 움직이는 오브젝트들이 같은 메터리얼을 공유하면 한꺼번에 그려주는 기능이다. 하지만 &lt;em&gt;Dynamic Batching&lt;/em&gt; 은 약간의 기능상의 한계가 있다. 아래 레퍼런스 링크로 들어가서 확인해보면 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.unity3d.com/kr/current/Manual/DrawCallBatching.html&quot;&gt;DrawCallBatching&lt;/a&gt; 에서 자세한 내용을 확인할 수 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/AlexanderDolbilov/google-i-o-2014&quot;&gt;Google IO 2014 : Optimizing unity games&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://shimans.tistory.com/41&quot;&gt;Optimize shader&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/PhysX&quot;&gt;Wikipedia : PhysX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="try" />
      

      

      
        <summary type="html">일반적인 응용 프로그램들은 중간중간에 잠시 멈춰도 원하는 결과를 유저에게 보여주면 상관이 없다. 하지만 게임은 ‘게임중’ 에는 어떤 경우에도 렉을 허용하지 않는다. 그만큼 ‘게임중’ 상태에서 렉을 아예 발생시키지 않는 것이 게임 프로그래머의 중요한 능력중 하나다. 게임은 일반적으로 1초에 60번 이상 업데이트하는 루틴을 유지해야 유저에게 원활한 환경을 제공한다. 여기서 급작스럽게 프레임수가 하락하면 그때 유저들은 순간적으로 끊기거나 부드럽지 않은 경험을 하게된다. 유저들은 그런 것들을 랙으로 통칭한다. 랙이 반복되면 유저들은 게이밍 환경에 불만을 느끼게 된다. 일반적인 랙은 프로그래머의 실수인 경우가 많다. 런타임에서 많은 것을 한꺼번에 처리하는 경우가 대표적이다. 하지만 이는 여러 리팩토링을 거치면 충분히 해결할 수 있다. 경험이 적은 사람들에게 가장 문제가 되는 것은 엔진을 사용하는 방법이 문제가 되는 경우가 많다. 엔진의 자세한 구현 사항을 파악하지 못했기 때문에 한계를 생각하지 않고 코딩하는 경우 말이다. 몇가지 사항들만 주의하며 코딩한다면 꽤 많은 병목들을 피해갈 수 있다. 이제 Unity 엔진을 사용할 때 퍼포먼스에 영향을 끼치는 것들과 해결 방안에 대해서 알아보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Using Texture2darray In Unity</title>
      
      <link href="https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity/" rel="alternate" type="text/html" title="Using Texture2darray In Unity" />
      <published>2017-06-04T00:00:00+00:00</published>
      <updated>2017-06-04T00:00:00+00:00</updated>
      <id>https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity</id>
      <content type="html" xml:base="https://hrmrzizon.github.io/2017/06/04/using-texture2darray-in-unity/">&lt;p&gt;Unity 에서 렌더링에 관련된 최적화를 할때는 &lt;em&gt;TextureArray&lt;/em&gt; 를 사용할 수 밖에 없다. 이는 Unity 에서 &lt;em&gt;DrawCall&lt;/em&gt; 을 줄이기 위해 써먹는 &lt;em&gt;Batching&lt;/em&gt; 이라는 개념 때문인데 단순하게 말하면 그리는 새로운 매터리얼과 메쉬의 종류가 많으면 많을 수록 &lt;em&gt;DrawCall&lt;/em&gt; 을 많이 하게 된다. 하지만 이 &lt;em&gt;DrawCall&lt;/em&gt; 의 비용은 싼편이 아니기 때문에 CPU 의 성능을 꽤나 잡아먹게 된다. 그래서 Unity 는 자동으로 &lt;em&gt;Batching&lt;/em&gt; 을 해주게 된다. 같은 메터리얼을 쓰면 자동으로 묶어주고, 같은 메쉬를 쓰면 또 자동으로 묶어준다. 결국 &lt;em&gt;Batching&lt;/em&gt; 이 &lt;em&gt;DrawCall&lt;/em&gt; 의 횟수와 같은 개념이 되는 것이다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;em&gt;Batching&lt;/em&gt; 의 횟수를 줄이기 위해 매터리얼을 줄이는 방법에 대한 것이 &lt;em&gt;TextureArray&lt;/em&gt; 다. 이것보다 일반적으로 알려진 기법은 &lt;em&gt;TexutreAtlas&lt;/em&gt; 인데, 이 방법은 상당히 단순하다. 그냥 텍스쳐 한장에 모든 그림을 때려박고 UV 를 수정해주는 작업을 할때 쓰인다. 보통은 UI 이미지에서 스프라이트를 설정할 때 쓰이며, Unity 는 UGUI 기능에 &lt;em&gt;Sprite&lt;/em&gt; 들을 합쳐서 &lt;em&gt;TextureAtlas&lt;/em&gt; 로 만들어주는 기능이 있다. 하지만 3D 오브젝트의 UV 에서는 말이 조금 달라진다. UV 좌표는 0과 1사이의 값으로 이루어지는데 텍스쳐 여러장과 세팅되어 있던 UV 좌표들을 한장으로 통합해 다시 세팅하려면 굉장히 귀찮아진다. 그리고 합쳐지기전의 텍스쳐의 갯수가 합쳐진 후에 추가된다면 그것또한 굉장히 귀찮아질 것이다. 결국 생산성의 문제가 된다.  그래서 다른 방법을 쓸 수 있는데, 이 방법이 바로 &lt;em&gt;TextureArray&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;TextureArray&lt;/em&gt; 의 개념은 단순하게 텍스쳐를 배열로 묶은 것으로, 인덱스만 있으면 그냥 하나하나 참조하여 사용가능하다. 즉 UV 의 2차원 좌표와 함께 인덱스 한개만 더 있으면 된다. 그리고 &lt;em&gt;TextureArray&lt;/em&gt; 의 장점은 &lt;em&gt;TextureAtlas&lt;/em&gt; 마냥 합쳐주고 UV 를 수정할 일이 없고, 메쉬별로 인덱스를 따로 설정해주는 작업만 해주면 상당히 편하게 할 수 있다. 또한 텍스쳐 갯수가 몇개가 되던간에 메터리얼을 한개로 유지할 수 있기 때문에 굉장히 편하다. 근데 Unity 에서 사용하려면 몇가지 단점이 있다. Asset 생성을 지원하지 않기 때문에 굉장히 불편하고, 보여주는 GUI 또한 Unity 내부에서 지원하지 않는다. 편하게 사용하기 위해선 에디터 코드를 직접 만져야 한다. 물론 직접 생성해주는 것도 상관없지만 생산성 자체만 놓고보면 그다지 좋은 편은 아니다. 또한 &lt;em&gt;Shader&lt;/em&gt; 코드들도 직접 바꿔주어야 하기 때문에 이것저것 세팅해줘야 할것이 많다. 즉 사용하기에 비용이 많이 든다.&lt;/p&gt;

&lt;p&gt;이제 직접 Unity 에서 적용시켜보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;할것들은 세가지다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mesh 안의 단순한 2차원 UV 좌표를 (UV + 텍스쳐 인덱스)를 좌표로 가진 3차원 좌표로 바꾸기&lt;/li&gt;
  &lt;li&gt;TextureArray 생성 및 적용하기&lt;/li&gt;
  &lt;li&gt;Shader 코드에서 TextureArray 를 사용하고 UV 좌표를 3차원 좌표로 바꾸기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/hrmrzizon/TextureArrayExample&quot;&gt;예제&lt;/a&gt;를 짜놓았으니 볼사람들은 참조하길 바란다.&lt;/p&gt;

&lt;p&gt;UV 좌표를 바꾸는 것은 경우에 따라 다르다. 보통은 2차원 UV 좌표로 설정해놓았으니 프로그래머가 합치는 것만 생각하면 &lt;em&gt;Mesh&lt;/em&gt; 별로 텍스쳐 인덱스를 심어주는 컴포넌트를 넣어주는게 편할 것이다. 시작시에만 UV 정보를 수정해주면 되니 로딩시간이 길어지는 것과 GPU 메모리를 조금 더 먹는 것 외에는 문제 될것은 없다. 초기 로드 시간이 걱정된다면 에디터에서 넣어주면 된다. 예제에서는 처음에 전부 생성하기 때문에 Vector2 로 저장하던 UV좌표를 Vector3 로 바꾸고 텍스쳐 인덱스만 끼워 넣었다.&lt;/p&gt;

&lt;p&gt;TextureArray 부분을 작업하는게 제일 귀찮다. 그냥 컴포넌트에서 동적으로 생성해주면 장땡이긴 하지만 그런식이면 매번 컴포넌트를 건드려야하니 여간 귀찮은게 아니다. 그래서 예제를 보면 알겠지만 간단하게 래핑한 에셋을 만들었다. 근데 귀찮은 점이 하나 있다. 생성후에 에디터에서 텍스쳐 갯수나 여러것들을 수정하는게 안되서 몇가지 조건 중 하나가 문제면 다시 생성한다. 그러면 매터리얼과 연결이 끊기는데.. 혐오스럽지만 여기까지만 해놓았다. 혹시 이 방법 해결책을 아시면 댓글 부탁드립니다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;strong&gt;Texture2D&lt;/strong&gt; 클래스와 &lt;strong&gt;Texture2DArray&lt;/strong&gt; 에 &lt;em&gt;SetPixel&lt;/em&gt; 류 함수들은 픽셀별로 접근하기 때문에 여러 텍스쳐 압축포맷이 먹힌 텍스쳐 복사는 안된다. &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/Graphics.CopyTexture.html&quot;&gt;&lt;em&gt;Graphics.CopyTexture&lt;/em&gt;&lt;/a&gt; 로 하라고 여러 포럼들에 적혀있었다. 조건에 맞아야 사용이 가능하니 레퍼런스에 있는 상세한 설명을 참고바란다. 근데 우리가 사용하려는 간단한 전체복사는 전부 된다.&lt;/p&gt;

&lt;p&gt;쉐이더 코드에서 TextureArray 를 사용하는건 굉장히 간단하다. &lt;a href=&quot;https://docs.unity3d.com/Manual/SL-TextureArrays.html&quot;&gt;Unity Manual : TextureArray&lt;/a&gt;를 참조하면 된다. 크게 어려울 것 없이 예제에 나온대로만 하면 된다.&lt;/p&gt;

&lt;p&gt;전체적으로 사용하기에는 어렵지않다. 하지만 그에 비해 얻는 이득은 많으니 어떤 게임이든 당연히 쓰는게 좋을 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/Manual/SL-TextureArrays.html&quot;&gt;Unity Manual : TextureArray&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="shader" />
      
        <category term="rendering" />
      
        <category term="try" />
      

      

      
        <summary type="html">Unity 에서 렌더링에 관련된 최적화를 할때는 TextureArray 를 사용할 수 밖에 없다. 이는 Unity 에서 DrawCall 을 줄이기 위해 써먹는 Batching 이라는 개념 때문인데 단순하게 말하면 그리는 새로운 매터리얼과 메쉬의 종류가 많으면 많을 수록 DrawCall 을 많이 하게 된다. 하지만 이 DrawCall 의 비용은 싼편이 아니기 때문에 CPU 의 성능을 꽤나 잡아먹게 된다. 그래서 Unity 는 자동으로 Batching 을 해주게 된다. 같은 메터리얼을 쓰면 자동으로 묶어주고, 같은 메쉬를 쓰면 또 자동으로 묶어준다. 결국 Batching 이 DrawCall 의 횟수와 같은 개념이 되는 것이다. 그래서 Batching 의 횟수를 줄이기 위해 매터리얼을 줄이는 방법에 대한 것이 TextureArray 다. 이것보다 일반적으로 알려진 기법은 TexutreAtlas 인데, 이 방법은 상당히 단순하다. 그냥 텍스쳐 한장에 모든 그림을 때려박고 UV 를 수정해주는 작업을 할때 쓰인다. 보통은 UI 이미지에서 스프라이트를 설정할 때 쓰이며, Unity 는 UGUI 기능에 Sprite 들을 합쳐서 TextureAtlas 로 만들어주는 기능이 있다. 하지만 3D 오브젝트의 UV 에서는 말이 조금 달라진다. UV 좌표는 0과 1사이의 값으로 이루어지는데 텍스쳐 여러장과 세팅되어 있던 UV 좌표들을 한장으로 통합해 다시 세팅하려면 굉장히 귀찮아진다. 그리고 합쳐지기전의 텍스쳐의 갯수가 합쳐진 후에 추가된다면 그것또한 굉장히 귀찮아질 것이다. 결국 생산성의 문제가 된다. 그래서 다른 방법을 쓸 수 있는데, 이 방법이 바로 TextureArray 다. TextureArray 의 개념은 단순하게 텍스쳐를 배열로 묶은 것으로, 인덱스만 있으면 그냥 하나하나 참조하여 사용가능하다. 즉 UV 의 2차원 좌표와 함께 인덱스 한개만 더 있으면 된다. 그리고 TextureArray 의 장점은 TextureAtlas 마냥 합쳐주고 UV 를 수정할 일이 없고, 메쉬별로 인덱스를 따로 설정해주는 작업만 해주면 상당히 편하게 할 수 있다. 또한 텍스쳐 갯수가 몇개가 되던간에 메터리얼을 한개로 유지할 수 있기 때문에 굉장히 편하다. 근데 Unity 에서 사용하려면 몇가지 단점이 있다. Asset 생성을 지원하지 않기 때문에 굉장히 불편하고, 보여주는 GUI 또한 Unity 내부에서 지원하지 않는다. 편하게 사용하기 위해선 에디터 코드를 직접 만져야 한다. 물론 직접 생성해주는 것도 상관없지만 생산성 자체만 놓고보면 그다지 좋은 편은 아니다. 또한 Shader 코드들도 직접 바꿔주어야 하기 때문에 이것저것 세팅해줘야 할것이 많다. 즉 사용하기에 비용이 많이 든다. 이제 직접 Unity 에서 적용시켜보자.</summary>
      

      
      
    </entry>
  
  
</feed>
